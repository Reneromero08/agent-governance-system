# Capacity Analysis of Vector Symbolic Architectures

Kenneth L. Clarkson
IBM Research
â€ƒâ€ƒ
Shashanka Ubaru
IBM Research
â€ƒâ€ƒ
Elizabeth Yang
University of California, Berkeley; part of this work was done at IBM Research

###### Abstract

Hyperdimensional computing (HDC) is a biologically-inspired framework which represents symbols with high-dimensional vectors, and uses vector operations to manipulate them.
The ensemble of a particular vector space and a prescribed set of vector operations (including one addition-like for â€œbundlingâ€ and one outer-product-like for â€œbindingâ€) form a *vector symbolic architecture* (VSA).
While VSAs have been employed in numerous applications and have been studied empirically, many theoretical questions about VSAs remain open.

We analyze the *representation capacities* of four common VSAs: MAP-I, MAP-B, and two VSAs based on sparse binary vectors.
â€œRepresentation capacityâ€ here refers to bounds on the dimensions of the VSA vectors required to perform certain symbolic tasks, such as testing for set membership iâˆˆSğ‘–ğ‘†i\in S and estimating set intersection sizes |Xâˆ©Y|ğ‘‹ğ‘Œ|X\cap Y| for two sets of symbols Xğ‘‹X and Yğ‘ŒY, to a given degree of accuracy.
We also analyze the ability of a novel variant of a Hopfield network (a simple model of associative memory) to perform some of the same tasks that are typically asked of VSAs.

In addition to providing new bounds on VSA capacities, our analyses establish and leverage connections between VSAs, â€œsketchingâ€ (dimensionality reduction) algorithms, and Bloom filters.

## 1 Introduction

*Hyperdimensional computing* (HDC) is a biologically inspired framework for representing symbolic information.
In this framework, we represent different symbols using high-dimensional vectors (hypervectors), called *atomic vectors*, sampled from a natural vector distribution, such as random signed vectors, or sparse binary vectors.
We then use standard arithmetic or bit-wise operations on these vectors to perform symbolic operations, like associating or grouping symbols.
The distribution over atomic vectors, together with their corresponding operations, form a *vector-symbolic architecture* (VSA).

Many features of VSAs are inspired by aspects of the human brain and memory.
They are robust to noise, and the fact that all entries of the vectors are symmetric (i.e. donâ€™t correspond to specific features) allows VSA computations to be highly parallelizable.
Most VSA vector entries are either 00 or Â±1plus-or-minus1\pm 1, so there is no need for floating point arithmetic, and they admit energy-efficient and low-latency hardware implementations.

In VSA systems, the atomic vectors are typically chosen randomly, with a distribution such that they are highly likely to be pairwise *near-orthogonal*.

While we encounter â€œthe curse of dimensionalityâ€ in many algorithmic and machine learning problems, the ability to fit many near-orthogonal vectors into dğ‘‘d-dimensional space is a kind of â€œblessing of dimensionality.â€

While VSAs sometimes do not achieve the same performance as neural networks do on certain classification tasks, VSA-based classifiers require much less time and space to train and store.
There is also much research at the intersection of VSAs and deep learning; for instance, VSA vector representations could be good neural network inputs, and since all vector representations have the same size, this could be a better way to support inputs with different numbers of features ([kleyko2019distributed, alonso2021hyperembed]).
In addition, VSAs have found numerous applications outside of learning, including the modeling of sensory-motor systems in smaller organisms ([kleyko2015fly, kleyko2015imitation]), combining word embeddings to form context embeddings ([kanerva2000random, sahlgren2005introduction, jones2007representing]), and the processing of heart rate respiratory data and other biological times series data ([kleyko2018vector, kleyko2019hyperdimensional, burrello2019hyperdimensional]).
They are also promising tools for bridging the gap between symbolic data, such as word relationships, and numerical data, such as trained word embeddings ([quiroz2020semantic]).

In addition to exploring the performance of VSAs in such applications, there have also been several works that study the *representation capacity* of many VSAs.
The representation capacity refers to lower bounds on the VSA dimension, needed so that we can reliably perform certain symbolic tasks, such as computing set intersection sizes |Xâˆ©Y|ğ‘‹ğ‘Œ|X\cap Y| for two sets of symbols Xğ‘‹X and Yğ‘ŒY (with possibly different cardinalities).
These lower bounds then translate into a design choice (minimum required dimension) for VSA applications.
Here we understand reliability in the setting of generating the atomic vectors at random, and asking for good-enough accuracy with high-enough probability.
Similarly, another way to quantify representation capacity is the following: if we tolerate a failure probability of Î´ğ›¿\delta, can we bound the number of sets or objects we can encode?

The goal of this paper is to provide theoretical analyses of the representation capacities of four particular VSA models.
In general, there are far more models that are employed in practice; see [schlegel2022comparison, kleyko\_survey\_2021-1] for a longer catalog of VSAs.
We also assemble a set of tools and frameworks (common to computer scientists) for any future computations and high-probability bounds on VSA capacity.

### 1.1 Background on VSAs

To define a VSA, we need to first choose a distribution for sampling the atomic vectors.
For every individual symbol we want to introduce (that is, excluding associations between multiple symbols), we will independently sample a random mğ‘šm-dimensional vector from a distribution, such as the uniform one over {Â±1}msuperscriptplus-or-minus1ğ‘š\{\pm 1\}^{m} (i.e. sign vectors), or a random kğ‘˜k-sparse binary ({0,1}msuperscript01ğ‘š\{0,1\}^{m}) vector.
VSAs are equipped with the following operations; permutation is not always required.

* â€¢

  Similarity Measurement (âŸ¨â‹…,â‹…âŸ©
  â‹…â‹…\langle\cdot,\cdot\rangle):
  In almost all VSAs in this paper, we use cosine similarity (i.e. dot product âŸ¨u,vâŸ©
  ğ‘¢ğ‘£\langle u,v\rangle) to measure the similarity between the symbols that uğ‘¢u and vğ‘£v represent.
* â€¢

  Bundling (âŠ•direct-sum\oplus): We use bundling to represent a â€œunionâ€ of several symbols. The goal is for uâŠ•vdirect-sumğ‘¢ğ‘£u\oplus v to be similar to both uğ‘¢u and vğ‘£v.
* â€¢

  Binding (âŠ—tensor-product\otimes): Binding is often used to associate symbols as (key, value) pairs.
  Here, we want uâŠ—vtensor-productğ‘¢ğ‘£u\otimes v to be nearly orthogonal to both uğ‘¢u and vğ‘£v.
* â€¢

  Permutation (Ï€ğœ‹\pi): If Ï€ğœ‹\pi is a permutation, let Ï€â€‹(v)ğœ‹ğ‘£\pi(v) be the vector whose iğ‘–i-th entry is vÏ€âˆ’1â€‹(i)subscriptğ‘£superscriptğœ‹1ğ‘–v\_{\pi^{-1}(i)}.
  We use [v1;Ï€â€‹(v2);Ï€2â€‹(v3);â€¦;Ï€Lâˆ’1â€‹(vL)]
  subscriptğ‘£1ğœ‹subscriptğ‘£2superscriptğœ‹2subscriptğ‘£3â€¦superscriptğœ‹ğ¿1subscriptğ‘£ğ¿[v\_{1};\;\pi(v\_{2});\;\pi^{2}(v\_{3});\;\ldots;\pi^{L-1}(v\_{L})] to encode an *ordered sequence* of symbols or sets.
* â€¢

  Cleanup: Let vector xğ‘¥x represent a set XâŠ†ğ’³ğ‘‹ğ’³X\subseteq\mathcal{X}, where ğ’³ğ’³\mathcal{X} is the universe of all symbols.
  Given a dictionary of symbols SâŠ†ğ’³ğ‘†ğ’³S\subseteq\mathcal{X}, we want to compute the elements in Xâˆ©Sğ‘‹ğ‘†X\cap S.

  ###### Remark 1.

  Cleanup will not be a focus of our paper.
  If we have access to the individual vector representations of elements in Sğ‘†S, we can simply execute cleanup as a set of (parallel) membership tests, which use similarity measurement.

###### Example 1.

We can represent categorical data using the following bundle of bindings:

|  |  |  |
| --- | --- | --- |
|  | yâ†’=â¨iâˆˆÂ featuresfâ†’iâŠ—vâ†’iâ†’ğ‘¦subscriptdirect-sumğ‘–Â featurestensor-productsubscriptâ†’ğ‘“ğ‘–subscriptâ†’ğ‘£ğ‘–\vec{y}=\bigoplus\_{i\in\text{ features}}\vec{f}\_{i}\otimes\vec{v}\_{i} |  |

Here, fâ†’isubscriptâ†’ğ‘“ğ‘–\vec{f}\_{i} is a VSA vector encoding the concept â€œfeature iğ‘–i,â€ while vâ†’isubscriptâ†’ğ‘£ğ‘–\vec{v}\_{i} is a VSA vector encoding the value of feature iğ‘–i.
To train a classifier on the VSA representations {yâ†’}â†’ğ‘¦\{\vec{y}\}, we can average the training vectors over each class to get an exemplar for the class.

|  |  |  |
| --- | --- | --- |
|  | câ†’i=1#â€‹{z:Â labelâ€‹(z)=i}â€‹âˆ‘z:Â labelâ€‹(z)=izsubscriptâ†’ğ‘ğ‘–1#conditional-setğ‘§Â labelğ‘§ğ‘–subscript:ğ‘§Â labelğ‘§ğ‘–ğ‘§\vec{c}\_{i}=\frac{1}{\#\{z:\text{ label}(z)=i\}}\sum\_{z:\text{ label}(z)=i}z |  |

To classify a new input, we first compute its VSA encoding.
We then return the class whose representative vector cisubscriptğ‘ğ‘–c\_{i} is closest to it (using similarity measurement).

We will study a few basic predicates on VSAs; one is *membership testing*: given a vector xğ‘¥x representing a bundle of atomic vectors, and an atomic vector yğ‘¦y, determine if yğ‘¦y is in the set represented by xğ‘¥x.
Another predicate is *set intersection*: if yğ‘¦y also represents a set, estimate the size of the intersection of the sets represented by xğ‘¥x and yğ‘¦y.
Here these sets might be sets of vectors bound together, or permuted.
Estimation of intersection size is a natural extension of membership testing, and is helpful in applications where VSA represent, for example, sets of properties, where intersection and difference size are rough measure of relatedness.

### 1.2 Overview of Contributions and Related Work

We focus on four popular VSA families, plus a novel variant of Hopfield networks.
The atomic vector initializations of the four, as well as their bundling and binding operators, are shown in TableÂ [1](#S1.T1 "Table 1 â€£ 1.2 Overview of Contributions and Related Work â€£ 1 Introduction â€£ Capacity Analysis of Vector Symbolic Architectures").
As surveyed by [schlegel2022comparison], â€œMAPâ€ stands for â€œMultiply-Add-Permute,â€ while â€œIâ€ and â€œBâ€ reference the values that non-atomic vectors take (â€œintegerâ€ and â€œbinary,â€ respectively).

| VSA | Atomic Vector | Bundling | Binding |
| --- | --- | --- | --- |
| MAP-I | {Â±1}msuperscriptplus-or-minus1ğ‘š\{\pm 1\}^{m} | Elem.-wise addition | Elem.-wise mult. |
| MAP-B | {Â±1}msuperscriptplus-or-minus1ğ‘š\{\pm 1\}^{m} | Elem.-wise add., round to Â±1plus-or-minus1\pm 1 | Elem.-wise mult |
| Bloom filters | kğ‘˜k-sparse, {0,1}msuperscript01ğ‘š\{0,1\}^{m} | Elem.-wise addition, cap at 1 | (Out of scope) |
| Counting Bloom filters | kğ‘˜k-sparse, {0,1}msuperscript01ğ‘š\{0,1\}^{m} | Elem.-wise addition | (Out of scope) |

Table 1: 
A summary of MAP-I, MAP-B, and Binary Sparse VSAs (which generalize SBDR VSAs). While several binding operators have been proposed for the Binary Sparse VSAs, the study of these operators is outside of the scope of this paper.

A key aspect of our analyses is that we translate several VSA operations of interest into the language of sketching matrices (used for dimensionality reduction) or of hashing-based data structures (like Bloom Filters), which are all well-studied objects in computer science.
These connections have not been made explicit, or leveraged previously in VSA analysis, though we remark that Sparse-JL was briefly mentioned by [thomas\_streaming\_2022].

#### 1.2.1 Connections to the Broader Computer Science Literature

In several of our analyses, we rely on the Johnson-Lindenstrauss (JL) property, which is foundational to algorithmic matrix sketching, the study of techniques for compressing matrices while approximately preserving key properties, such as least-squares solutions.
See [woodruff\_computational\_2014] for a more detailed treatment of sketching.
From the perspective of sketching, our results on permutations, bundles of kğ‘˜k-bindings, and Hopfield networks can be regarded as extensions of sketching theory using structured matrices with less randomness than the most direct approaches.

The bundling operator for MAP-B is per-coordinate the *Majority function* in the setting of the analysis of Boolean functions, and is a simple *linear threshold function*. The analysis of the membership test for MAP-B that we give is close to that for analyzing the *influence* of variables for the majority function (cf. [o2014analysis], Exer. 2.2).
Here the influence of a variable on a function is the probability for a random input that the function return value changes when the variable is negated. In comparison, in the analysis of MAP-B bundling, we are interested in the probability that the return value changes when the variable is set to +11+1.
Our analysis of MAP-B extends to other operations, including a bundling of bindings, which are related to *polynomial threshold functions* of degreeÂ kğ‘˜k, where kğ‘˜k depends on the maximum number of symbols that are bound together.

Two of the VSAs we analyze are based on Bloom filters, which are space-efficient data structures for testing set membership.
They have seen extensive study since their introduction fifty years ago by [bloom\_spacetime\_1970], but we have not found rigorous analyses of their performance in the setting of set intersection (vs membership testing).
Our results are novel contributions in this regard.

#### 1.2.2 Other Analyses of VSA Capacity

Some recent works in the VSA literature that have inspired our own work also study the capacity problem, but they analyze more restricted VSA systems and/or use different analysis approaches.
To our knowledge, we are the first to formally analyze VSAs in terms of sketching, using tools like the JL property, though [thomas\_streaming\_2022] does mention the sparse JL transform.

[thomas\_theoretical\_2021] provides a theoretical analysis of VSAs in terms of a measure called â€œincoherence,â€ which quantifies the size of the â€œcross-talkâ€ (dot product) between two independently initialized VSA vectors.
They prove results on membership testing and set intersection of bundles, membership testing in key-value pairs (bindings of two symbols, keys and values, where the set of keys and the set of values are restricted to be disjoint), and show pairwise near-orthogonality of vectors and their coordinate permutations in terms of incoherence. Their work is in the linear setting (which pertains to MAP-I), and extends, as does ours via known results, from sign matrices to matrices of independent sub-Gaussians.
We add new bounds that include set intersections for bundles of kğ‘˜k-bindings (not restricted to disjoint keys and values), and sequences of sets encoded with rotations (cyclic permutations).
Our view of sketching is potentially simpler for understanding capacity bounds on MAP-I, and our hypergraph framework for binding in Â§[4.3](#S4.SS3 "4.3 Binding â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures") also allows us to extend our analysis for bundlings of bindings beyond only key-value pairs.

Another related work is that of [kleyko\_classification\_2018], which studies bundling in binary VSA systems, where atomic vectors are controlled by a sparsity parameter.
Their model is slightly different from the Bloom-filter inspired binary VSAs that we analyze, and their bundling operator includes a â€œthinningâ€ step, where the support of the bundle gets reduced to the size of a typical atomic vector.
Their analysis of VSA capacity uses Gaussian approximations holding in the limit, and some heuristics to get around the thinning step.
We formally analyze the capacity of bundling without thinning, using concentration inequalities.
The authors in [kleyko\_classification\_2018] also conduct several empirical analyses and simulations of sparse binary VSAs, which may be of independent interest.

## 2 Technical Overview and Statements of Results

In the remainder of the paper, we will present concrete statements of our results, and highlight some of the proof ideas, with an emphasis again on connections to sketching and data structures.
Each subsection here (roughly organized by each different VSA we analyze) will have a full section in the appendix where we give their proofs.

##### Notation and Terminology.

We summarize some notation in the following list, for reference.

* â€¢

  âŒŠaâŒ‰delimited-âŒŠâŒ‰ğ‘\lfloor a\rceil is the nearest integer to aâˆˆIâ€‹Rğ‘IRa\in\operatorname{{\mathrm{I\!R}}};
* â€¢

  signâ¡(a)signğ‘\operatorname{{\text{sign}}}(a) for aâˆˆIâ€‹Rğ‘IRa\in\operatorname{{\mathrm{I\!R}}} is 111 if a>0ğ‘0a>0, âˆ’11-1 if a<0ğ‘0a<0 and Â±1plus-or-minus1\pm 1 with equal probability if a=0ğ‘0a=0;
* â€¢

  signâ‰¥â¡(a)subscriptsignğ‘\operatorname{{\text{sign}\_{\geq}}}(a) for aâˆˆIâ€‹Rğ‘IRa\in\operatorname{{\mathrm{I\!R}}} is 111 if aâ‰¥0ğ‘0a\geq 0, and âˆ’11-1 otherwise
* â€¢

  For a,bâˆˆIâ€‹R
  ğ‘ğ‘IRa,b\in\operatorname{{\mathrm{I\!R}}}, a=bÂ±Îµğ‘plus-or-minusğ‘ğœ€a=b\pm{\varepsilon} means that |aâˆ’b|â‰¤Îµğ‘ğ‘ğœ€|a-b|\leq{\varepsilon}, so that a=bâ€‹(1Â±Îµ)ğ‘ğ‘plus-or-minus1ğœ€a=b(1\pm{\varepsilon}) means that |aâˆ’b|â‰¤bâ€‹Îµğ‘ğ‘ğ‘ğœ€|a-b|\leq b{\varepsilon};
* â€¢

  vâˆ˜wğ‘£ğ‘¤v\circ w denotes the Hadamard (elementwise) product of two vectors, (vâˆ˜w)i=viâ€‹wisubscriptğ‘£ğ‘¤ğ‘–subscriptğ‘£ğ‘–subscriptğ‘¤ğ‘–(v\circ w)\_{i}=v\_{i}w\_{i};
* â€¢

  vâˆ§wğ‘£ğ‘¤v\wedge w denotes the elementwise minimum of two vectors vğ‘£v and wğ‘¤w, (vâˆ§w)i=minâ¡{vi,wi}subscriptğ‘£ğ‘¤ğ‘–subscriptğ‘£ğ‘–subscriptğ‘¤ğ‘–(v\wedge w)\_{i}=\min\{v\_{i},w\_{i}\}; for scalar ağ‘a and vector vğ‘£v, aâˆ§vğ‘ğ‘£a\wedge v is the vector with (aâˆ§v)i=minâ¡{a,vi}subscriptğ‘ğ‘£ğ‘–ğ‘subscriptğ‘£ğ‘–(a\wedge v)\_{i}=\min\{a,v\_{i}\};
* â€¢

  vâˆ§â‹…wfragmentsfragmentsâ‹…ğ‘£ğ‘¤v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w denotes âˆ‘iminâ¡{vi,wi}subscriptğ‘–subscriptğ‘£ğ‘–subscriptğ‘¤ğ‘–\sum\_{i}\min\{v\_{i},w\_{i}\};
* â€¢

  suppâ¡(v)={iâˆˆ[d]âˆ£viâ‰ 0}suppğ‘£conditional-setğ‘–delimited-[]ğ‘‘subscriptğ‘£ğ‘–0\operatorname{{\text{supp}}}(v)=\{i\in[d]\mid v\_{i}\neq 0\}, for vâˆˆâ„dğ‘£superscriptâ„ğ‘‘v\in{\mathbb{R}}^{d}. For diagonal Vâˆˆâ„dÃ—dğ‘‰superscriptâ„ğ‘‘ğ‘‘V\in{\mathbb{R}}^{d\times d}, let suppâ¡(V)={iâˆˆ[d]âˆ£Viâ€‹iâ‰ 0}suppğ‘‰conditional-setğ‘–delimited-[]ğ‘‘subscriptğ‘‰ğ‘–ğ‘–0\operatorname{{\text{supp}}}(V)=\{i\in[d]\mid V\_{ii}\neq 0\};

### 2.1 Bundling as the output of a linear map.

Our central approach is to cast VSA vectors as the outputs of linear transformations, followed by nonlinear maps for some of the VSAs.
Via the linear maps, we can translate between a very simple vector representation for symbols (described below) and the more robust, fault-tolerant, and (in some settings) lower-dimensional ones used in VSAs.

A simple vector representation of elements in a universe ğ’³ğ’³\mathcal{X} is their one-hot encoding as unit binary vectors eiâˆˆ{0,1}dsubscriptğ‘’ğ‘–superscript01ğ‘‘e\_{i}\in\{0,1\}^{d}, where dâ‰¡|ğ’³|ğ‘‘ğ’³d\equiv|\mathcal{X}|.
Then, set union corresponds to adding vectors: a set XâŠ‚ğ’³ğ‘‹ğ’³X\subset\mathcal{X} is a characteristic vector vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d} with v=âˆ‘iâˆˆXeiğ‘£subscriptğ‘–ğ‘‹subscriptğ‘’ğ‘–v=\sum\_{i\in X}e\_{i}.
The size of |X|ğ‘‹|X| corresponds to the squared Euclidean norm â€–vâ€–2superscriptnormğ‘£2\|v\|^{2}.
For two sets X,YâŠ†ğ’³

ğ‘‹ğ‘Œ
ğ’³X,Y\subseteq\mathcal{X} with corresponding characteristic vectors vğ‘£v and wğ‘¤w, respectively, |Xâˆ©Y|ğ‘‹ğ‘Œ|X\cap Y| is simply vâŠ¤â€‹wsuperscriptğ‘£topğ‘¤v^{\top}w; similarly, their symmetric difference |Xâ€‹Î”â€‹Y|ğ‘‹Î”ğ‘Œ|X\Delta Y| is â€–vâˆ’wâ€–2superscriptnormğ‘£ğ‘¤2\|v-w\|^{2}.

Thus an embedding of these one-hot encodings, linear or non-linear, that approximately preserves distances and/or dot products of vectors (which is particularly challenging for binary vectors), can be used to maintain sets and the sizes of their intersections and symmetric differences.
With this in mind, we can regard the atomic vectors of a VSA as the columns of a random matrix Pğ‘ƒP (so the embedding of vector xğ‘¥x is Pâ€‹xğ‘ƒğ‘¥Px, possibly with a non-linearity applied), and for appropriate random Pğ‘ƒP, we will obtain such embeddings.

A correspondence between the VSAs we study and their choice of matrix Pğ‘ƒP is found in TableÂ [2](#S2.T2 "Table 2 â€£ 2.1 Bundling as the output of a linear map. â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
From this perspective, VSAs perform dimensionality reduction from characteristic vectors in {0,1}dsuperscript01ğ‘‘\{0,1\}^{d}
to an mğ‘šm-dimensional space, for mâ‰ªdmuch-less-thanğ‘šğ‘‘m\ll d.

| VSA | Atomic Vector | Bundling |
| --- | --- | --- |
| MAP-I | SÂ¯â€‹eiÂ¯ğ‘†subscriptğ‘’ğ‘–{\bar{S}}e\_{i} | SÂ¯â€‹vÂ¯ğ‘†ğ‘£{\bar{S}}v |
| MAP-B | Sâ€‹eiğ‘†subscriptğ‘’ğ‘–Se\_{i} | signâ¡(Sâ€‹v)signğ‘†ğ‘£\operatorname{{\text{sign}}}(Sv) |
| Bloom filter | Bâ€‹eiğµsubscriptğ‘’ğ‘–Be\_{i} | 1âˆ§Bâ€‹v1ğµğ‘£1\wedge Bv |
| Counting Bloom | Bâ€‹eiğµsubscriptğ‘’ğ‘–Be\_{i} | Bâ€‹vğµğ‘£Bv |

Table 2: 
Equivalent to TableÂ [1](#S1.T1 "Table 1 â€£ 1.2 Overview of Contributions and Related Work â€£ 1 Introduction â€£ Capacity Analysis of Vector Symbolic Architectures"). Here eiâˆˆ{0,1}dsubscriptğ‘’ğ‘–superscript01ğ‘‘e\_{i}\in\{0,1\}^{d} for iâˆˆ[d]ğ‘–delimited-[]ğ‘‘i\in[d] has ei=1subscriptğ‘’ğ‘–1e\_{i}=1, all other coordinates zero, and vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d} represents the set suppâ¡(v)âŠ‚[d]suppğ‘£delimited-[]ğ‘‘\operatorname{{\text{supp}}}(v)\subset[d]. The matrices Sğ‘†S, SÂ¯Â¯ğ‘†{\bar{S}}, and BğµB are sign (also called bipolar or Rademacher), scaled sign, and sparse binary, as in Def.Â [2](#Thmtheorem2 "Definition 2. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") andÂ [21](#Thmtheorem21 "Definition 21. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

##### Overview of Tools and Techniques

Our analysis of MAP-I establishes the JL property for a variety of random sign matrices, some with dependent entries, that are used to encode bundles, sequences, and bundles of bindings.
In the case of sequences and bindings, the entries of the sign matrices we analyze will not be independent, which complicates our analysis; we get around this using standard concentration results like McDiarmidâ€™s inequality (TheoremÂ [25](#Thmtheorem25 "Theorem 25. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")) and a version for when the bounded differences hold with high probability (CorollaryÂ [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")).
Our analysis of MAP-B also uses these concentration techniques and also borrows some ideas from Boolean Fourier analysis.
For Hopfield nets and our variation HopfieldÂ±plus-or-minus\pm, we also use standard concentration results like the Hanson-Wright inequality.
A Bernstein-like variation of McDiarmid, TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), is key to our analysis of Bloom filters.

### 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss

##### Bundling and Set Intersection

For MAP-I, we choose Pğ‘ƒP as a scaled sign matrix SÂ¯Â¯ğ‘†{\bar{S}}.

###### Definition 2.

A *sign vector* yâˆˆ{Â±1}mğ‘¦superscriptplus-or-minus1ğ‘šy\in\{\pm 1\}^{m} (also called a Rademacher vector) is a vector with independent entries, each chosen uniformly from {Â±1}plus-or-minus1\{\pm 1\}.
A *sign matrix* Sâˆˆ{Â±1}mÃ—dğ‘†superscriptplus-or-minus1ğ‘šğ‘‘S\in\{\pm 1\}^{m\times d} has columns that are independent sign vectors, and a *scaled* sign matrix SÂ¯=1mâ€‹SÂ¯ğ‘†1ğ‘šğ‘†{\bar{S}}=\frac{1}{\sqrt{m}}S where Sğ‘†S is sign matrix.

Thus, Sâ€‹eiğ‘†subscriptğ‘’ğ‘–Se\_{i} is a random sign vector.
For MAP-I, the bundling operator is addition, so a set Xğ‘‹X can be represented as SÂ¯â€‹vÂ¯ğ‘†ğ‘£{\bar{S}}v, with v=âˆ‘iâˆˆXeiğ‘£subscriptğ‘–ğ‘‹subscriptğ‘’ğ‘–v=\sum\_{i\in X}e\_{i}.
(More typically, MAP-I would use the unscaled sign matrix Sğ‘†S, but SÂ¯Â¯ğ‘†{\bar{S}} is convenient for analysis and discussion.)
It is known that with high probability, for mğ‘šm sufficiently large, that SÂ¯Â¯ğ‘†{\bar{S}} satisfies the *Johnson-Lindenstrauss (JL) property*, which is the norm-preserving condition in the lemma below.

###### Lemma 3 ([johnson\_extensions\_1984, achlioptas\_database-friendly\_2003], [JL](https://en.wikipedia.org/wiki/Johnson-Lindenstrauss_lemma)).

Suppose SÂ¯âˆˆ1mâ€‹{âˆ’1,1}mÃ—dÂ¯ğ‘†1ğ‘šsuperscript11ğ‘šğ‘‘{\bar{S}}\in\frac{1}{\sqrt{m}}\{-1,1\}^{m\times d} is a scaled sign matrix (described in Def.Â [2](#Thmtheorem2 "Definition 2. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).
Then for given Î´,Ïµ>0

ğ›¿italic-Ïµ
0\delta,\epsilon>0 there is m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(1/Î´))ğ‘šğ‘‚superscriptitalic-Ïµ21ğ›¿m=O(\epsilon^{-2}\log(1/\delta)) such that for given vector vâˆˆIâ€‹Rdğ‘£superscriptIRğ‘‘v\in\operatorname{{\mathrm{I\!R}}}^{d}, it holds that â€–SÂ¯â€‹vâ€–=â€–vâ€–â€‹(1Â±Ïµ)normÂ¯ğ‘†ğ‘£normğ‘£plus-or-minus1italic-Ïµ\|{\bar{S}}v\|=\|v\|(1\pm\epsilon), with failure probability at most Î´ğ›¿\delta.

This immediately tells us the dimension mğ‘šm required to estimate set sizes up to a multiplicative factor of Îµğœ€{\varepsilon}, with failure probability Î´ğ›¿\delta.

For X,YâŠ†ğ’³

ğ‘‹ğ‘Œ
ğ’³X,Y\subseteq\mathcal{X}, let vğ‘£v and wğ‘¤w denote their characteristic vectors.
An immediate consequence of the JL lemma is that the symmetric difference size |Xâ€‹Î”â€‹Y|=â€–vâˆ’wâ€–2ğ‘‹Î”ğ‘Œsuperscriptnormğ‘£ğ‘¤2|X\Delta Y|=\|v-w\|^{2} can be estimated with small relative error as well.

###### Corollary 4.

If random matrix Pğ‘ƒP satisfies the JL property (LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")),
then for given Î´,Ïµ>0

ğ›¿italic-Ïµ
0\delta,\epsilon>0, and a set ğ’±âŠ‚Iâ€‹Rdğ’±superscriptIRğ‘‘\mathcal{V}\subset\operatorname{{\mathrm{I\!R}}}^{d} of cardinality nğ‘›n,
there is m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(n/Î´))ğ‘šğ‘‚superscriptitalic-Ïµ2ğ‘›ğ›¿m=O(\epsilon^{-2}\log(n/\delta)) such that
with failure probability Î´ğ›¿\delta, for all pairs v,wâˆˆğ’±

ğ‘£ğ‘¤
ğ’±v,w\in\mathcal{V},
â€–Pâ€‹(vâˆ’w)â€–2âˆˆâ€–vâˆ’wâ€–2â€‹(1Â±Ïµ)superscriptnormğ‘ƒğ‘£ğ‘¤2superscriptnormğ‘£ğ‘¤2plus-or-minus1italic-Ïµ\|P(v-w)\|^{2}\in\|v-w\|^{2}(1\pm\epsilon).

The JL lemma also implies that (Pâ€‹v)âŠ¤â€‹(Pâ€‹w)=vâŠ¤â€‹PâŠ¤â€‹Pâ€‹wsuperscriptğ‘ƒğ‘£topğ‘ƒğ‘¤superscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤(Pv)^{\top}(Pw)=v^{\top}P^{\top}Pw concentrates around |Xâˆ©Y|=vâŠ¤â€‹wğ‘‹ğ‘Œsuperscriptğ‘£topğ‘¤|X\cap Y|=v^{\top}w.

###### Corollary 5.

Suppose the random matrix Pğ‘ƒP satisfies the JL property (LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).
Then for v,wâˆˆIâ€‹Rd

ğ‘£ğ‘¤
superscriptIRğ‘‘v,w\in\operatorname{{\mathrm{I\!R}}}^{d}, there is m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(1/Î´))ğ‘šğ‘‚superscriptitalic-Ïµ21ğ›¿m=O(\epsilon^{-2}\log(1/\delta)) so that
vâŠ¤â€‹PâŠ¤â€‹Pâ€‹w=vâŠ¤â€‹wÂ±Ïµâ€‹â€–vâ€–â€‹â€–wâ€–superscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤plus-or-minussuperscriptğ‘£topğ‘¤italic-Ïµnormğ‘£normğ‘¤v^{\top}P^{\top}Pw=v^{\top}w\pm\epsilon\|v\|\|w\|
with failure probabilityÂ Î´ğ›¿\delta.

Estimation of the cosine of the angle between vğ‘£v and wğ‘¤w, which is |Xâˆ©Y|/|X|â‹…|Y|ğ‘‹ğ‘Œâ‹…ğ‘‹ğ‘Œ|X\cap Y|/\sqrt{|X|\cdot|Y|}, up to additive error Ïµitalic-Ïµ\epsilon , is also now immediate.

The goal of our MAP-I bundling section is to use the above lemmas and corollaries to prove the following theorem.

###### Theorem 6.

Suppose random matrix Pğ‘ƒP satisfies the JL property (LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).
Given Mğ‘€M pairs of characteristic vectors v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d} such that for every pair v,w

ğ‘£ğ‘¤v,w, â€–vâ€–1â€‹â€–wâ€–1â‰¤Nsubscriptnormğ‘£1subscriptnormğ‘¤1ğ‘\|v\|\_{1}\|w\|\_{1}\leq N, then there is m=Oâ€‹(Nâ€‹logâ¡(M/Î´))ğ‘šğ‘‚ğ‘ğ‘€ğ›¿m=O(N\log(M/\delta)) such that âŒŠvâŠ¤PâŠ¤PwâŒ‰=vâŠ¤w\lfloor v^{\top}P^{\top}Pw\rceil=v^{\top}w for all Mğ‘€M pairs with probability â‰¥1âˆ’Î´absent1ğ›¿\geq 1-\delta.

In short, we inherit much of our capacity analysis of bundling in MAP-I through known results about the JL property.

##### Rotations via JL property.

One operation used in VSAs to expand on the number of nearly orthogonal vectors available for use is via permutations of the entries; this is the â€œPâ€ in the MAP VSA systems introduced by [gayler1998multiplicative].
These can be encoded in permutation matrices Râˆˆ{0,1}mÃ—mğ‘…superscript01ğ‘šğ‘šR\in\{0,1\}^{m\times m}. We will focus on cyclic permutations.

###### Definition 7.

Let RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m} denote the permutation matrix implementing a rotation, so that Rm,1=1subscriptğ‘…

ğ‘š11R\_{m,1}=1 and for iâˆˆ[mâˆ’1]ğ‘–delimited-[]ğ‘š1i\in[m-1], Ri,i+1=1subscriptğ‘…

ğ‘–ğ‘–11R\_{i,i+1}=1, with all other entries equal to zero.

For a random sign vector yğ‘¦y, and such a rotation matrix Rğ‘…R (or indeed for any permutation matrix with few fixed points), Râ€‹yğ‘…ğ‘¦Ry is nearly orthogonal to yğ‘¦y, and the vectors Râ„“â€‹ysuperscriptğ‘…â„“ğ‘¦R^{\ell}y for â„“=0,1â€‹â€¦â€‹Lâ„“

01â€¦ğ¿\ell=0,1\ldots L are pairwise mutually orthogonal with high probability, if Lğ¿L is not too large.
However, the entries of these vectors are not independent, so additional care is needed in analyzing them.

Permutations (and specifically, rotations) can be used to encode a *sequence* of atomic vectors xâ„“superscriptğ‘¥â„“x^{\ell} as a sum âˆ‘â„“Râ„“â€‹xâ„“subscriptâ„“superscriptğ‘…â„“superscriptğ‘¥â„“\sum\_{\ell}R^{\ell}x^{\ell}.
We can also encode a *sequence of sets* with characteristic vectors v(â„“)subscriptğ‘£â„“v\_{(\ell)}.

###### Definition 8.

For Râˆˆâ„mÃ—mğ‘…superscriptâ„ğ‘šğ‘šR\in{\mathbb{R}}^{m\times m}, SâˆˆIâ€‹RmÃ—dğ‘†superscriptIRğ‘šğ‘‘S\in\operatorname{{\mathrm{I\!R}}}^{m\times d} and integer Lâ‰¥0ğ¿0L\geq 0, let SR,Lâˆˆâ„mÃ—Lâ€‹dsubscriptğ‘†

ğ‘…ğ¿superscriptâ„ğ‘šğ¿ğ‘‘S\_{R,L}\in{\mathbb{R}}^{m\times Ld} denote

|  |  |  |
| --- | --- | --- |
|  | [Sâ€‹Râ€‹Sâ€‹R2â€‹Sâ€‹â€¦â€‹RLâˆ’1â€‹S].delimited-[]ğ‘†ğ‘…ğ‘†superscriptğ‘…2ğ‘†â€¦superscriptğ‘…ğ¿1ğ‘†[S\;RS\;R^{2}S\;\ldots\;R^{L-1}S]. |  |

For a sequence of v(0),v(1),â€¦â€‹v(Lâˆ’1)âˆˆâ„d

subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1
superscriptâ„ğ‘‘v\_{(0)},v\_{(1)},\ldots v\_{(L-1)}\in\mathbb{R}^{d}, let vâˆˆâ„Lâ€‹dğ‘£superscriptâ„ğ¿ğ‘‘v\in\mathbb{R}^{Ld} denote vâ‰¡[v(0)â€‹v(1)â€‹â€¦â€‹v(Lâˆ’1)]ğ‘£delimited-[]subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1v\equiv[v\_{(0)}\;v\_{(1)}\;\ldots\;v\_{(L-1)}].

The sequence given by vğ‘£v in the definition can be represented in MAP-I as a single vector SÂ¯R,Lâ€‹vsubscriptÂ¯ğ‘†

ğ‘…ğ¿ğ‘£{\bar{S}}\_{R,L}v.
We first find mğ‘šm such that SÂ¯R,LsubscriptÂ¯ğ‘†

ğ‘…ğ¿{\bar{S}}\_{R,L} satisfies the JL property for general vâˆˆâ„Lâ€‹dğ‘£superscriptâ„ğ¿ğ‘‘v\in\mathbb{R}^{Ld}.

###### Theorem 9.

Given scaled sign matrix SÂ¯âˆˆIâ€‹RmÃ—dÂ¯ğ‘†superscriptIRğ‘šğ‘‘{\bar{S}}\in\operatorname{{\mathrm{I\!R}}}^{m\times d}, rotation matrix RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m} as in Def.Â [7](#Thmtheorem7 "Definition 7. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), integer L>0ğ¿0L>0, and SÂ¯R,LsubscriptÂ¯ğ‘†

ğ‘…ğ¿{\bar{S}}\_{R,L} as in Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Then for vâˆˆIâ€‹RLâ€‹dğ‘£superscriptIRğ¿ğ‘‘v\in\operatorname{{\mathrm{I\!R}}}^{Ld} as defined above,

|  |  |  |
| --- | --- | --- |
|  | |â€–SÂ¯R,Lâ€‹vâ€–2âˆ’â€–vâ€–2|â‰¤3â€‹Ïµâ€‹â€–vâ€–L,12â‰¤3â€‹Lâ€‹Ïµâ€‹â€–vâ€–2,superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2superscriptnormğ‘£23italic-Ïµsuperscriptsubscriptnormğ‘£  ğ¿123ğ¿italic-Ïµsuperscriptnormğ‘£2|\|{\bar{S}}\_{R,L}v\|^{2}-\|v\|^{2}|\leq 3\epsilon\|v\|\_{L,1}^{2}\leq 3L\epsilon\|v\|^{2}, |  |

with failure probability 6â€‹L2â€‹Î´6superscriptğ¿2ğ›¿6L^{2}\delta.
It follows that there is m=Oâ€‹((L/Îµ)2â€‹logâ¡(L/Î´))ğ‘šğ‘‚superscriptğ¿ğœ€2ğ¿ğ›¿m=O((L/{\varepsilon})^{2}\log(L/\delta)) such that with failure probability at most Î´ğ›¿\delta,
â€–SÂ¯R,Lâ€‹vâ€–2=(1Â±Îµ)â€‹â€–vâ€–2superscriptnormsubscriptÂ¯ğ‘†

ğ‘…ğ¿ğ‘£2plus-or-minus1ğœ€superscriptnormğ‘£2\|{\bar{S}}\_{R,L}v\|^{2}=(1\pm{\varepsilon})\|v\|^{2}.

The proof of Theorem [9](#Thmtheorem9 "Theorem 9. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") relies on partitioning the rows of SÂ¯Â¯ğ‘†{\bar{S}} so that within the rows of a single partition subset, the corresponding rows of SÂ¯Â¯ğ‘†{\bar{S}} and Riâ€‹SÂ¯superscriptğ‘…ğ‘–Â¯ğ‘†R^{i}{\bar{S}} can be treated independently.

We get tighter bound on mğ‘šm when the v(i)subscriptğ‘£ğ‘–v\_{(i)} are characteristic vectors: our bound on mğ‘šm depends on Kğ¾K, the maximum number of times that a given symbol appears inÂ vğ‘£v.

###### Theorem 10.

Given scaled sign matrix SÂ¯âˆˆIâ€‹RmÃ—dÂ¯ğ‘†superscriptIRğ‘šğ‘‘{\bar{S}}\in\operatorname{{\mathrm{I\!R}}}^{m\times d}, rotation matrix RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m} (Def.Â [7](#Thmtheorem7 "Definition 7. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")), integer L>0ğ¿0L>0, and SÂ¯R,LsubscriptÂ¯ğ‘†

ğ‘…ğ¿{\bar{S}}\_{R,L} as in Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
For a sequence of vectors v(0),v(1),â€¦â€‹v(Lâˆ’1)âˆˆ{0,1}d

subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1
superscript01ğ‘‘v\_{(0)},v\_{(1)},\ldots v\_{(L-1)}\in\{0,1\}^{d}, let
Kâ‰¡â€–âˆ‘0â‰¤j<Lv(j)â€–âˆğ¾subscriptnormsubscript0ğ‘—ğ¿subscriptğ‘£ğ‘—K\equiv\|\sum\_{0\leq j<L}v\_{(j)}\|\_{\infty}.
There is m=Oâ€‹(K2â€‹Îµâˆ’2â€‹logâ¡(K/(Îµâ€‹Î´)))ğ‘šğ‘‚superscriptğ¾2superscriptğœ€2ğ¾ğœ€ğ›¿m=O\left(K^{2}{\varepsilon}^{-2}\log(K/({\varepsilon}\delta))\right) such that with failure probabilityÂ Î´ğ›¿\delta,

|  |  |  |
| --- | --- | --- |
|  | |â€–SÂ¯R,Lâ€‹vâ€–2âˆ’â€–vâ€–2|â‰¤Ïµâ€‹â€–vâ€–2superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2superscriptnormğ‘£2italic-Ïµsuperscriptnormğ‘£2|\|{\bar{S}}\_{R,L}v\|^{2}-\|v\|^{2}|\leq\epsilon\|v\|^{2} |  |

We handle dependences between rows of Sğ‘†S using a version of McDiarmidâ€™s inequality (Corollary [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")).
As noted by Corollary [4](#Thmtheorem4 "Corollary 4. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and Corollary [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), satisfying the JL property allows us to find mğ‘šm so we can perform set intersection (dot product) and symmetric difference (subtraction) operations on vectors of form [v(0)â€‹v(1)â€‹â€¦â€‹v(Lâˆ’1)]delimited-[]subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1[v\_{(0)}\,v\_{(1)}\ldots v\_{(L-1)}] up to a multiplicative factor of Îµğœ€{\varepsilon} and failure probability Î´ğ›¿\delta.

##### Bundles of bindings the JL property.

In MAP-I, we implement binding using the Hadamard (element-wise) products of atomic vectors.
In this setting, we can compactly represent a bundling of kğ‘˜k-wise atomic bindings using the matrix SÂ¯âŠ™ksuperscriptÂ¯ğ‘†direct-productabsentğ‘˜{\bar{S}}^{\odot k}.

###### Definition 11.

For sign matrix Sğ‘†S, let SâŠ™kâˆˆ1mâ€‹Iâ€‹RmÃ—(dk)superscriptğ‘†direct-productabsentğ‘˜1ğ‘šsuperscriptIRğ‘šbinomialğ‘‘ğ‘˜S^{\odot k}\in\frac{1}{\sqrt{m}}\operatorname{{\mathrm{I\!R}}}^{m\times\binom{d}{k}}, where each column of SâŠ™ksuperscriptğ‘†direct-productabsentğ‘˜S^{\odot k} is the Hadamard (element-wise) product of kğ‘˜k different columns of Sğ‘†S. The scaled version SÂ¯âŠ™ksuperscriptÂ¯ğ‘†direct-productabsentğ‘˜{\bar{S}}^{\odot k} is 1mâ€‹SâŠ™k1ğ‘šsuperscriptğ‘†direct-productabsentğ‘˜\frac{1}{\sqrt{m}}S^{\odot k}. We clarify that PâŠ™kâŠ¤superscriptğ‘ƒdirect-productabsentlimit-fromğ‘˜topP^{\odot k\top} denotes (PâŠ™k)âŠ¤superscriptsuperscriptğ‘ƒdirect-productabsentğ‘˜top(P^{\odot k})^{\top}.

With this notation, a bundling of kğ‘˜k-wise atomic bindings is SÂ¯âŠ™kâ€‹vsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£{\bar{S}}^{\odot k}v, for vâˆˆ{0,1}(dk)ğ‘£superscript01binomialğ‘‘ğ‘˜v\in\{0,1\}^{\binom{d}{k}}.
Note that
ğ”¼â€‹[SÂ¯âŠ™kâ€‹SÂ¯âŠ™kâŠ¤]=(dk)mâ€‹Imğ”¼delimited-[]superscriptÂ¯ğ‘†direct-productabsentğ‘˜superscriptÂ¯ğ‘†direct-productabsentlimit-fromğ‘˜topbinomialğ‘‘ğ‘˜ğ‘šsubscriptğ¼ğ‘š{\mathbb{E}}[{\bar{S}}^{\odot k}{\bar{S}}^{\odot k\top}]=\frac{\binom{d}{k}}{m}I\_{m}, while ğ”¼â€‹[SÂ¯âŠ™kâŠ¤â€‹SÂ¯âŠ™k]=I(dk)ğ”¼delimited-[]superscriptÂ¯ğ‘†direct-productabsentlimit-fromğ‘˜topsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜subscriptğ¼binomialğ‘‘ğ‘˜{\mathbb{E}}[{\bar{S}}^{\odot k\top}{\bar{S}}^{\odot k}]=I\_{\binom{d}{k}}.
In order to reason about intersections over bundles of kğ‘˜k-bindings, or about the symmetric difference between the bundles of kğ‘˜k-bindings, we again establish the JL property, this time for SÂ¯âŠ™kâ€‹vsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£{\bar{S}}^{\odot k}v.
We first present the result for the k=2ğ‘˜2k=2 case, which captures bundles of key-value bindings.

###### Theorem 12.

For vâˆˆ{0,1}(d2)ğ‘£superscript01binomialğ‘‘2v\in\{0,1\}^{\binom{d}{2}}, there is m=Oâ€‹(Îµâˆ’2â€‹log3â¡(â€–vâ€–1/Îµâ€‹Î´))ğ‘šğ‘‚superscriptğœ€2superscript3subscriptnormğ‘£1ğœ€ğ›¿m=O({\varepsilon}^{-2}\log^{3}(\|v\|\_{1}/{\varepsilon}\delta)) so that
for SÂ¯âŠ™2âˆˆ{Â±1m}(d2)superscriptÂ¯ğ‘†direct-productabsent2superscriptplus-or-minus1ğ‘šbinomialğ‘‘2{\bar{S}}^{\odot 2}\in\{\pm\frac{1}{\sqrt{m}}\}^{\binom{d}{2}},

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|â€–SÂ¯âŠ™2â€‹vâ€–2âˆ’â€–vâ€–2|>Îµâ€‹â€–vâ€–2]â‰¤Î´.PrsuperscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2superscriptnormğ‘£2ğœ€superscriptnormğ‘£2ğ›¿\Pr[|\|{\bar{S}}^{\odot 2}v\|^{2}-\|v\|^{2}|>{\varepsilon}\|v\|^{2}]\leq\delta. |  |

We have a generalized result for all kğ‘˜k as well.

###### Corollary 13.

For scaled sign SÂ¯âŠ™kâˆˆ{Â±1m}(dk)superscriptÂ¯ğ‘†direct-productabsentğ‘˜superscriptplus-or-minus1ğ‘šbinomialğ‘‘ğ‘˜{\bar{S}}^{\odot k}\in\{\pm\frac{1}{\sqrt{m}}\}^{\binom{d}{k}}, vâˆˆ{0,1}(dk)ğ‘£superscript01binomialğ‘‘ğ‘˜v\in\{0,1\}^{\binom{d}{k}}, and iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m],
there is C>0ğ¶0C>0 and m=Oâ€‹(Îµâˆ’2â€‹Ckâ€‹logâ¡kâ€‹logk+1â¡(kâ€‹â€–vâ€–1/(Îµâ€‹Î´)))ğ‘šğ‘‚superscriptğœ€2superscriptğ¶ğ‘˜ğ‘˜superscriptğ‘˜1ğ‘˜subscriptnormğ‘£1ğœ€ğ›¿m=O(\varepsilon^{-2}C^{k\log k}\log^{k+1}(k\|v\|\_{1}/(\varepsilon\delta))) such that

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|â€–SÂ¯âŠ™kâ€‹vâ€–2âˆ’â€–vâ€–2|>Îµâ€‹â€–vâ€–2]â‰¤Î´.PrsuperscriptnormsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£2superscriptnormğ‘£2ğœ€superscriptnormğ‘£2ğ›¿\Pr[|\|{\bar{S}}^{\odot k}v\|^{2}-\|v\|^{2}|>{\varepsilon}\|v\|^{2}]\leq\delta. |  |

The key challenge of establishing the JL property for bundles of bindings is the fact that the columns of SÂ¯âŠ™ksuperscriptÂ¯ğ‘†direct-productabsentğ‘˜{\bar{S}}^{\odot k} are not independent; for instance, when k=2ğ‘˜2k=2, the columns corresponding to iâŠ—jtensor-productğ‘–ğ‘—i\otimes j, jâŠ—ktensor-productğ‘—ğ‘˜j\otimes k, and iâŠ—ktensor-productğ‘–ğ‘˜i\otimes k are dependent.
To track these dependencies, we can represent SÂ¯âŠ™kâ€‹vsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£{\bar{S}}^{\odot k}v as a hypergraph when vâˆˆ{0,1}(dk)ğ‘£superscript01binomialğ‘‘ğ‘˜v\in\{0,1\}^{\binom{d}{k}}.
Then, if we apply McDiarmidâ€™s inequality to the bundling of bindings, we can obtain the constants used in the bounded differences in terms of the degrees in the hypergraph.

##### Roadmap for Proofs

In Â§[4.1](#S4.SS1 "4.1 Bundling and Set Intersection â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures"), we prove Theorem [6](#Thmtheorem6 "Theorem 6. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and discuss how the JL frame extends to the sparse JL and Subsampled Randomized Hadamard Transforms (SRHTs).
In Â§[4.2](#S4.SS2 "4.2 Rotations for Encoding Sequences â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures"), we prove Theorems [9](#Thmtheorem9 "Theorem 9. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and [10](#Thmtheorem10 "Theorem 10. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Finally, in Â§[4.3](#S4.SS3 "4.3 Binding â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures"), we prove Theorem [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and Corollary [13](#Thmtheorem13 "Corollary 13. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

### 2.3 Hopfield Nets and HopfieldÂ±plus-or-minus\pm

In the early seventies, a simple model of associative memory, based on autocorrelation, was introduced in [nakano\_associatron-model\_1972, kohonen\_correlation\_1972, anderson\_simple\_1972].
In a paper that might be regarded as ushering in the â€œsecond age of neural networks,â€ [hopfield\_neural\_1982] reformulated that model, and described a dynamic process for memory retrieval.

We analyze the *capacity* of Hopfieldâ€™s model, where a collection of vectors constituting the memories is stored.
(A survey of autoasssociative memories is given in [gritsenko\_neural\_2017].)
The capacity problem is to determine the maximum number of such vectors a network can effectively represent in a model described below, and it is assumed that the vectors to be stored are sign vectors.
In our setting, the memories are simply columns of a sign matrixÂ Sâˆˆ{Â±1}mÃ—nğ‘†superscriptplus-or-minus1ğ‘šğ‘›S\in\{\pm 1\}^{m\times n}.

Much of our description of the model paraphrases that of [nakano\_associatron-model\_1972, kohonen\_correlation\_1972, anderson\_simple\_1972].
The neural network in Hopfieldâ€™s model comprises a recurrent collection of neurons with pairwise synaptic connections, with an associated weight matrix Wâˆˆâ„mÃ—mğ‘Šsuperscriptâ„ğ‘šğ‘šW\in{\mathbb{R}}^{m\times m}, such that given input xâˆˆ{Â±1}mğ‘¥superscriptplus-or-minus1ğ‘šx\in\{\pm 1\}^{m}, a dynamic process ensues with vectors xâ€‹[â„“]ğ‘¥delimited-[]â„“x[\ell], where xâ€‹[0]=xğ‘¥delimited-[]0ğ‘¥x[0]=x, and xâ€‹[â„“+1]=signâ‰¥â¡(Wâ€‹xâ€‹[â„“])ğ‘¥delimited-[]â„“1subscriptsignğ‘Šğ‘¥delimited-[]â„“x[\ell+1]=\operatorname{{\text{sign}\_{\geq}}}(Wx[\ell]).
Here, signâ‰¥â¡(z)=1subscriptsignğ‘§1\operatorname{{\text{sign}\_{\geq}}}(z)=1 if zâ‰¥0ğ‘§0z\geq 0, and âˆ’11-1 otherwise.
When we reach a fixed point, i.e. xâ€‹[â„“+1]=xâ€‹[â„“]ğ‘¥delimited-[]â„“1ğ‘¥delimited-[]â„“x[\ell+1]=x[\ell], the process stops, and xâ€‹[â„“]ğ‘¥delimited-[]â„“x[\ell] is output.
If a vector xğ‘¥x is a fixed point of the network, the network is said to â€œrepresentâ€Â xğ‘¥x.
Typically, the goal is to not only show the fixed-point property for some xğ‘¥x, but also show that for yâˆˆ{0,Â±1}mğ‘¦superscript0plus-or-minus1ğ‘šy\in\{0,\pm 1\}^{m} close to xğ‘¥x (i.e. yâŠ¤â€‹xsuperscriptğ‘¦topğ‘¥y^{\top}x is large), the network output isÂ xğ‘¥x given inputÂ yğ‘¦y, with high probability.
The capacity problem is to determine how many vectors are represented by a network, as a function of mğ‘šm and a given lower bound on yâŠ¤â€‹xsuperscriptğ‘¦topğ‘¥y^{\top}x.

The weight matrix Wğ‘ŠW in a Hopfield network is Sâ€‹SâŠ¤âˆ’nâ€‹Imğ‘†superscriptğ‘†topğ‘›subscriptğ¼ğ‘šSS^{\top}-nI\_{m}, the sum of the outer products of the input vectors with themselves, with the diagonal set to zero.
One motivation for this setup is that such a weight matrix can be learned by an appropriately connected neural network via a Hebbian learning process.

In TheoremÂ [14](#Thmtheorem14 "Theorem 14. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") below, we give a bound on mğ‘šm and yâŠ¤â€‹Sâˆ—jsuperscriptğ‘¦topsubscriptğ‘†absentğ‘—y^{\top}S\_{\*j} so that signâ‰¥â¡((Sâ€‹SâŠ¤âˆ’nâ€‹I)â€‹y)=Sâˆ—jsubscriptsignğ‘†superscriptğ‘†topğ‘›ğ¼ğ‘¦subscriptğ‘†absentğ‘—\operatorname{{\text{sign}\_{\geq}}}((SS^{\top}-nI)y)=S\_{\*j} with bounded failure probability.

###### Theorem 14.

Given matrix Sâˆˆ{Â±1}mÃ—nğ‘†superscriptplus-or-minus1ğ‘šğ‘›S\in\{\pm 1\}^{m\times n} with uniform independent entries, jâˆˆ[n]ğ‘—delimited-[]ğ‘›j\in[n], and Î´âˆˆ(0,1]ğ›¿01\delta\in(0,1].
If yâˆˆ{0,Â±1}mğ‘¦superscript0plus-or-minus1ğ‘šy\in\{0,\pm 1\}^{m} with
yâŠ¤â€‹Sâˆ—j/â€–yâ€–â‰¥2â€‹nâ€‹logâ¡(2â€‹m/Î´)superscriptğ‘¦topsubscriptğ‘†absentğ‘—normğ‘¦2ğ‘›2ğ‘šğ›¿y^{\top}S\_{\*j}/\|y\|\geq 2\sqrt{n\log(2m/\delta)}, then with failure probability at mostÂ Î´ğ›¿\delta, signâ‰¥â¡((Sâ€‹SâŠ¤âˆ’nâ€‹Im)â€‹y)=Sâˆ—jsubscriptsignğ‘†superscriptğ‘†topğ‘›subscriptğ¼ğ‘šğ‘¦subscriptğ‘†absentğ‘—\operatorname{{\text{sign}\_{\geq}}}((SS^{\top}-nI\_{m})y)=S\_{\*j}.
Here it is assumed that the coordinates iğ‘–i at which yiâ‰ Siâ€‹jsubscriptğ‘¦ğ‘–subscriptğ‘†ğ‘–ğ‘—y\_{i}\neq S\_{ij} are chosen beforeÂ Sğ‘†S, or without knowledge of it.

The yâŠ¤â€‹Sâˆ—j/â€–yâ€–=yâŠ¤â€‹Sâˆ—j/â€–yâ€–1superscriptğ‘¦topsubscriptğ‘†absentğ‘—normğ‘¦superscriptğ‘¦topsubscriptğ‘†absentğ‘—subscriptnormğ‘¦1y^{\top}S\_{\*j}/\|y\|=y^{\top}S\_{\*j}/\sqrt{\|y\|\_{1}} term may seem mysterious.
mâˆ’â€–yâ€–1ğ‘šsubscriptnormğ‘¦1m-\|y\|\_{1} is the number of erasures in yğ‘¦y, that is, the number of zero coordinates, and mâˆ’|yâŠ¤â€‹Sâˆ—j|ğ‘šsuperscriptğ‘¦topsubscriptğ‘†absentğ‘—m-|y^{\top}S\_{\*j}| is the number of erasures plus twice the number of error coordinates iğ‘–i where yiâ‰ Siâ€‹jsubscriptğ‘¦ğ‘–subscriptğ‘†ğ‘–ğ‘—y\_{i}\neq S\_{ij}.
When there are only erasures, and y=Sâˆ—jğ‘¦subscriptğ‘†absentğ‘—y=S\_{\*j} except for errors, â€–yâ€–1=yâŠ¤â€‹Sâˆ—jsubscriptnormğ‘¦1superscriptğ‘¦topsubscriptğ‘†absentğ‘—\|y\|\_{1}=y^{\top}S\_{\*j}, and â€–yâ€–1â‰¥2â€‹nâ€‹logâ¡(2â€‹m/Î´)subscriptnormğ‘¦12ğ‘›2ğ‘šğ›¿\|y\|\_{1}\geq 2n\log(2m/\delta) suffices.

In Â§[5.1](#S5.SS1 "5.1 Analysis of Hopfield Networks via Concentration Bounds â€£ 5 Autocorrelation Associative Memories as Bundles of Robust Bindings â€£ Capacity Analysis of Vector Symbolic Architectures"), we discuss the implications of this result for mğ‘šm in various cases.
If the coordinates of Sâˆ—jsubscriptğ‘†absentğ‘—S\_{\*j} are split into two blocks, one block can be retrieved given the other.
This is an alternative sometimes proposed for VSA cleanup, which otherwise involves multiple membership tests.
We also note in the section that the data of a MAP-I bundle of bindings is contained in the Hopfield network, and that robustness under erasures can be used to reduce the size of net.

We also introduce a variant of Hopfield nets, which we call HopfieldÂ±plus-or-minus\pm, in which the vector outer products yielding Wğ‘ŠW are each multiplied by a random Â±1plus-or-minus1\pm 1value before summing.111The name HopfieldÂ±plus-or-minus\pmÂ references the Rademacher values, and is in homage to the many variants of X called X++.
As described in TheoremÂ [15](#Thmtheorem15 "Theorem 15. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") below, which establishes a JL-like property for HopfieldÂ±plus-or-minus\pm, this system can store and recover m2superscriptğ‘š2m^{2} (up to log factors) vectors.
Considering that it uses Oâ€‹(m2)ğ‘‚superscriptğ‘š2O(m^{2}) space, its storage efficiency for bundling is not far from that of MAP-I.

###### Theorem 15.

Given Îµ,Î´âˆˆ(0,1]

ğœ€ğ›¿
01{\varepsilon},\delta\in(0,1], scaled sign matrix SÂ¯âˆˆ1mâ€‹{Â±1}mÃ—dÂ¯ğ‘†1ğ‘šsuperscriptplus-or-minus1ğ‘šğ‘‘{\bar{S}}\in\frac{1}{\sqrt{m}}\{\pm 1\}^{m\times d} with uniform independent entries, diagonal matrix Vâˆˆâ„dÃ—dğ‘‰superscriptâ„ğ‘‘ğ‘‘V\in{\mathbb{R}}^{d\times d}, and diagonal matrix Dâˆˆ{0,Â±1}dÃ—dğ·superscript0plus-or-minus1ğ‘‘ğ‘‘D\in\{0,\pm 1\}^{d\times d} with uniform independent Â±1plus-or-minus1\pm 1 diagonal entries.
There is m=O(Îµâˆ’1log(d/Î´)2)m=O({\varepsilon}^{-1}\log(d/\delta)^{2}) such that with failure probability Î´ğ›¿\delta,
â€–SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤â€–F2=(1Â±Îµ)â€‹â€–Vâ€–F2superscriptsubscriptnormÂ¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†topğ¹2plus-or-minus1ğœ€superscriptsubscriptnormğ‘‰ğ¹2\|{\bar{S}}VD{\bar{S}}^{\top}\|\_{F}^{2}=(1\pm{\varepsilon})\|V\|\_{F}^{2}.

##### Roadmap for Proofs

Theorem [14](#Thmtheorem14 "Theorem 14. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") is proven in Â§[5.1](#S5.SS1 "5.1 Analysis of Hopfield Networks via Concentration Bounds â€£ 5 Autocorrelation Associative Memories as Bundles of Robust Bindings â€£ Capacity Analysis of Vector Symbolic Architectures"). Theorem [15](#Thmtheorem15 "Theorem 15. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") is discussed in Â§[5.2](#S5.SS2 "5.2 HopfieldÂ±: Autocorrelation Associative Memories as VSAs â€£ 5 Autocorrelation Associative Memories as Bundles of Robust Bindings â€£ Capacity Analysis of Vector Symbolic Architectures").

### 2.4 Analysis of MAP-B

For MAP-B, we write our VSA atomic vectors as Sâ€‹eiğ‘†subscriptğ‘’ğ‘–Se\_{i}, where Sğ‘†S is a random sign matrix (Def.Â [2](#Thmtheorem2 "Definition 2. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).
However, we require here that even composite (non-atomic) VSA vectors be sign vectors, so a bundle of atomic vectors is represented as signâ¡(Sâ€‹v)signğ‘†ğ‘£\operatorname{{\text{sign}}}(Sv) for a characteristic vector vğ‘£v.

The nonlinearity of bundling makes analysis more difficult.
While we were able to reason about set intersection readily via the JL framework when analyzing MAP-I, our results for MAP-B only hold for testing set membership, which is a specific instance of set intersection.
We are able to show that membership testing, to determine if iâˆˆ[d]ğ‘–delimited-[]ğ‘‘i\in[d] is in suppâ¡(v)suppğ‘£\operatorname{{\text{supp}}}(v), as represented by the bundle x=signâ¡(Sâ€‹v)ğ‘¥signğ‘†ğ‘£x=\operatorname{{\text{sign}}}(Sv), can be done by checking if xâŠ¤â€‹Sâˆ—iâ‰¥Ï„superscriptğ‘¥topsubscriptğ‘†absentğ‘–ğœx^{\top}S\_{\*i}\geq\tau, with threshold Ï„ğœ\tau specified below.

###### Theorem 16.

For vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d},
let x=signâ¡(Sâ€‹v)ğ‘¥signğ‘†ğ‘£x=\operatorname{{\text{sign}}}(Sv) be the MAP-B bundling of n=â€–vâ€–1ğ‘›subscriptnormğ‘£1n=\|v\|\_{1} atomic vectors.
Then for all iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m] and jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v), Prâ¡[xiâ€‹Siâ€‹j=+1]=1/2+Î˜â€‹(1/n)Prsubscriptğ‘¥ğ‘–subscriptğ‘†ğ‘–ğ‘—112Î˜1ğ‘›\Pr[x\_{i}S\_{ij}=+1]=1/2+\Theta(1/\sqrt{n}), as nâ†’âˆâ†’ğ‘›n\rightarrow\infty, and there is m=Oâ€‹(nâ€‹logâ¡(d/Î´))ğ‘šğ‘‚ğ‘›ğ‘‘ğ›¿m=O(n\log(d/\delta)) such that with failure probability Î´ğ›¿\delta,
jâˆˆ[d]ğ‘—delimited-[]ğ‘‘j\in[d] has jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) if and only if xâŠ¤â€‹Sâˆ—j=ejâŠ¤â€‹Sâ€‹signâ¡(Sâ€‹v)superscriptğ‘¥topsubscriptğ‘†absentğ‘—superscriptsubscriptğ‘’ğ‘—topğ‘†signğ‘†ğ‘£x^{\top}S\_{\*j}=e\_{j}^{\top}S\operatorname{{\text{sign}}}(Sv) has xâŠ¤â€‹Sâˆ—jâ‰¥2â€‹mâ€‹logâ¡(2â€‹d/Î´)superscriptğ‘¥topsubscriptğ‘†absentğ‘—2ğ‘š2ğ‘‘ğ›¿x^{\top}S\_{\*j}\geq\sqrt{2m\log(2d/\delta)}.

The proof borrows (simple) ideas from Boolean Fourier analysis, namely the analysis of the majority function.
See [o2014analysis] for a thorough guide on this topic.
In Â§[6.1.3](#S6.SS1.SSS3 "6.1.3 Testing for Empty Intersection â€£ 6.1 Bundling â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures"), we also provide a simple extension of Theorem [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") to testing for whether the set intersection between two sets Xğ‘‹X, Yğ‘ŒY is empty or not.

We also remark that the bundling operator for MAP-B is *not* associative; while signâ¡(Sâ€‹v)signğ‘†ğ‘£\operatorname{{\text{sign}}}(Sv) is one way that MAP-B might compute a bundle, in a more general setting, there could be a sequence of bundling operations.
This would result in a tree of bundle operations of some depth greater than one, in contrast to signâ¡(Sâ€‹v)signğ‘†ğ‘£\operatorname{{\text{sign}}}(Sv), whose tree has depth one.
We prove that the reliability of the bundling operation decays exponentially with the depth.

###### Lemma 17.

Given independent sign vectors x(i)âˆˆ{Â±1}m,iâˆˆ[r]formulae-sequencesuperscriptğ‘¥ğ‘–superscriptplus-or-minus1ğ‘šğ‘–delimited-[]ğ‘Ÿx^{(i)}\in\{\pm 1\}^{m},i\in[r], construct vectorÂ xğ‘¥x by setting xâ†x(1)â†ğ‘¥superscriptğ‘¥1x\leftarrow x^{(1)}, and for j=2,â€¦,rğ‘—

2â€¦ğ‘Ÿj=2,\ldots,r, setting xâ†signâ¡(x+x(j))â†ğ‘¥signğ‘¥superscriptğ‘¥ğ‘—x\leftarrow\operatorname{{\text{sign}}}(x+x^{(j)}).
Then, for â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m],

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[xâ„“(1)â€‹xâ„“=1]=1/2+1/2rPrsubscriptsuperscriptğ‘¥1â„“subscriptğ‘¥â„“1121superscript2ğ‘Ÿ\Pr[x^{(1)}\_{\ell}x\_{\ell}=1]=1/2+1/2^{r} |  |

As a result, great care must be exercised in defining MAP-B bundles for application use.

##### Rotations and Bundles of Bindings

We analyze rotations in the same setting described in Definition [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and Theorem [9](#Thmtheorem9 "Theorem 9. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), and bundles of bindings in the setting of Definition [11](#Thmtheorem11 "Definition 11. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and Theorem [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

Our results for MAP-B rotations and bundles of bindings are more limited than what we are able to prove for MAP-I, again due to the nonlinearities present in the binding operation.
As noted before, we only consider single element membership testing.
For sequences, this means checking if a single element iğ‘–i is present in the jğ‘—j-th set in a sequence.

###### Theorem 18.

Given a sign matrix SâˆˆIâ€‹RmÃ—dğ‘†superscriptIRğ‘šğ‘‘S\in\operatorname{{\mathrm{I\!R}}}^{m\times d} and rotation matrix RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m}, and integer length Lğ¿L.
Recall (Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")) that SR,Lâ‰¡[Sâ€‹Râ€‹Sâ€‹R2â€‹Sâ€‹â€¦â€‹RLâˆ’1â€‹S]subscriptğ‘†

ğ‘…ğ¿delimited-[]ğ‘†ğ‘…ğ‘†superscriptğ‘…2ğ‘†â€¦superscriptğ‘…ğ¿1ğ‘†S\_{R,L}\equiv[S\;RS\;R^{2}S\;\ldots R^{L-1}S].
For a sequence of dğ‘‘d-vectors v(0),v(1),â€¦â€‹v(Lâˆ’1)âˆˆ{0,1}d

subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1
superscript01ğ‘‘v\_{(0)},v\_{(1)},\ldots v\_{(L-1)}\in\{0,1\}^{d},
let vâ‰¡[v(0)â€‹v(1)â€‹â€¦â€‹v(Lâˆ’1)]ğ‘£delimited-[]subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1v\equiv[v\_{(0)}\;v\_{(1)}\;\ldots v\_{(L-1)}], let x=signâ¡(SR,Lâ€‹v)ğ‘¥signsubscriptğ‘†

ğ‘…ğ¿ğ‘£x=\operatorname{{\text{sign}}}(S\_{R,L}v), and let n=â€–vâ€–1ğ‘›subscriptnormğ‘£1n=\|v\|\_{1}.
Then there is m=Oâ€‹(Lâ€‹nâ€‹logâ¡(Lâ€‹d/Î´))ğ‘šğ‘‚ğ¿ğ‘›ğ¿ğ‘‘ğ›¿m=O(Ln\log(Ld/\delta)) such that with failure probability at most Î´ğ›¿\delta,
jâˆˆ[Lâ€‹d]ğ‘—delimited-[]ğ¿ğ‘‘j\in[Ld] has jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) if and only if xâŠ¤â€‹Sâˆ—,j%dâ‰¥2â€‹mâ€‹logâ¡(Lâ€‹d/Î´)x^{\top}S\_{\*,j\_{{\scriptscriptstyle\%}d}}\geq 2\sqrt{m\log(Ld/\delta)},
where j%dâ‰¡1+(jâˆ’1)moddj\_{{\scriptscriptstyle\%}d}\equiv 1+(j-1)\mod d.

The proof of Theorem [10](#Thmtheorem10 "Theorem 10. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") relies on the MAP-B membership result (Theorem [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")) and the same trick of partitioning the rows of SR,Lsubscriptğ‘†

ğ‘…ğ¿S\_{R,L} used to prove Theorem [9](#Thmtheorem9 "Theorem 9. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

We will analyze MAP-B bundles of bindings in the restricted setting of key-value pairs.
We can test whether a single keyâŠ—valuetensor-productkeyvalue\text{key}\otimes\text{value} belongs to such a bundle.

###### Definition 19.

A bundle of *key-value pairs* is here a bundling of bindings SâŠ™2â€‹vsuperscriptğ‘†direct-productabsent2ğ‘£S^{\odot 2}v, where Sâˆ—jâŠ™2subscriptsuperscriptğ‘†direct-productabsent2absentğ‘—S^{\odot 2}\_{\*j} for jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) is Sâˆ—,qâˆ˜Sâˆ—,wsubscriptğ‘†

ğ‘subscriptğ‘†

ğ‘¤S\_{\*,q}\circ S\_{\*,w} with qâˆˆğ’¬,wâˆˆğ’²formulae-sequenceğ‘ğ’¬ğ‘¤ğ’²q\in\mathcal{Q},w\in\mathcal{W}, where ğ’¬,ğ’²âŠ‚[d],ğ’¬âˆ©ğ’²={}formulae-sequence

ğ’¬ğ’²
delimited-[]ğ‘‘ğ’¬ğ’²

\mathcal{Q},\mathcal{W}\subset[d],\mathcal{Q}\cap\mathcal{W}=\{\}, and a given qğ‘q appears in only one binding in such a representation.
That is, each Sâˆ—,qsubscriptğ‘†

ğ‘S\_{\*,q} is bound to only one Sâˆ—,wsubscriptğ‘†

ğ‘¤S\_{\*,w}, noting that two q,qâ€²

ğ‘superscriptğ‘â€²q,q^{\prime} may bind to the sameÂ Sâˆ—,wsubscriptğ‘†

ğ‘¤S\_{\*,w}.

###### Theorem 20.

Let vâˆˆ{0,1}(d2)ğ‘£superscript01binomialğ‘‘2v\in\{0,1\}^{\binom{d}{2}} be such that x=signâ¡(SâŠ™2â€‹v)ğ‘¥signsuperscriptğ‘†direct-productabsent2ğ‘£x=\operatorname{{\text{sign}}}(S^{\odot 2}v) is a bundle of key-value pairs, as in Def.Â [19](#Thmtheorem19 "Definition 19. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Let n=â€–vâ€–1ğ‘›subscriptnormğ‘£1n=\|v\|\_{1}.
Then there is m=Oâ€‹(nâ€‹logâ¡(d/Î´))ğ‘šğ‘‚ğ‘›ğ‘‘ğ›¿m=O(n\log(d/\delta)) such that with failure probability at most Î´ğ›¿\delta, jâˆˆ[(dk)]ğ‘—delimited-[]binomialğ‘‘ğ‘˜j\in[\binom{d}{k}] has jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) if and only if xâŠ¤â€‹Sâˆ—jâŠ™2â‰¥2â€‹mâ€‹logâ¡(d/Î´)superscriptğ‘¥topsubscriptsuperscriptğ‘†direct-productabsent2absentğ‘—2ğ‘šğ‘‘ğ›¿x^{\top}S^{\odot 2}\_{\*j}\geq 2\sqrt{m\log(d/\delta)}.

The proof of this theorem again leverages Theorem [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

##### Roadmap for Proofs

In Â§[6.1](#S6.SS1 "6.1 Bundling â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures"), we prove TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
In Â§[6.1.2](#S6.SS1.SSS2 "6.1.2 Dependence on Depth â€£ 6.1 Bundling â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures"), we prove LemmaÂ [17](#Thmtheorem17 "Lemma 17. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Finally the proofs of Theorems [18](#Thmtheorem18 "Theorem 18. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and [20](#Thmtheorem20 "Theorem 20. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") can be found in Â§[6.2](#S6.SS2 "6.2 Rotations â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures") and Â§[6.3](#S6.SS3 "6.3 Binding â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures"), respectively.

### 2.5 Sparse Binary Bundling and Bloom Filter Analysis

If we use VSA vectors Bâ€‹xğµğ‘¥Bx with BğµB chosen as a sparse binary matrix (defined below), we obtain two new families of VSAs, which we refer to as *Bloom filters* and *Counting Bloom filters*, from their names in the data structures literature.

###### Definition 21.

For given mğ‘šm and kâ‰¤mğ‘˜ğ‘šk\leq m, a *kğ‘˜k-sparse binary vector* yâˆˆ{0,1}mğ‘¦superscript01ğ‘šy\in\{0,1\}^{m} has â€–yâ€–0â‰¤ksubscriptnormğ‘¦0ğ‘˜\|y\|\_{0}\leq k, chosen by adding kğ‘˜k random natural basis vectors eiâˆˆ{0,1}m,subscriptğ‘’ğ‘–superscript01ğ‘še\_{i}\in\{0,1\}^{m}, with each iğ‘–i chosen independently and uniformly from [m]delimited-[]ğ‘š[m].
A *kğ‘˜k-sparse binary matrix* Bâˆˆ{0,1}mÃ—dğµsuperscript01ğ‘šğ‘‘B\in\{0,1\}^{m\times d} has columns that are independent sparse binary vectors, and a *scaled* kğ‘˜k-sparse binary matrix has the form BÂ¯=1kâ€‹BÂ¯ğµ1ğ‘˜ğµ{\bar{B}}=\frac{1}{k}B, where BğµB is a sparse binary matrix.
These may be called just *sparse*, leaving the kğ‘˜k implicit.

The Bloom and Counting Bloom filters slightly generalize BSDC-CDT, described in [schlegel2022comparison].
For more on Bloom filters [bloom\_spacetime\_1970], see e.g. [broder\_network\_2004].
A Bloom filter represents the set suppâ¡(v)suppğ‘£\operatorname{{\text{supp}}}(v) for vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d} as 1âˆ§Bâ€‹v1ğµğ‘£1\wedge Bv, recalling that 1âˆ§Bâ€‹v1ğµğ‘£1\wedge Bv denotes the vector xğ‘¥x with xi=minâ¡{1,(Bâ€‹v)i}subscriptğ‘¥ğ‘–1subscriptğµğ‘£ğ‘–x\_{i}=\min\{1,(Bv)\_{i}\}.

We give VSA dimension bounds enabling reliable estimation of set intersections; a rigorous version of such an estimator appears to be novel for Bloom filters.
We define a function hm,kâ€‹(â‹…)subscriptâ„

ğ‘šğ‘˜â‹…h\_{m,k}(\cdot) that maps the expected dot product of the VSA bundles to the dot product of the original vectors.

###### Theorem 22.

Let v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d} represent sets X,Y

ğ‘‹ğ‘ŒX,Y respectively, and define the following counts:

|  |  |  |
| --- | --- | --- |
|  | nâ‰¡|Xâˆ©Y|=vâ‹…w,nvâ‰¡|Xâˆ–Y|=â€–vâ€–0âˆ’n,nwâ‰¡|Yâˆ–X|=â€–wâ€–0âˆ’nformulae-sequenceğ‘›ğ‘‹ğ‘Œâ‹…ğ‘£ğ‘¤subscriptğ‘›ğ‘£ğ‘‹ğ‘Œsubscriptnormğ‘£0ğ‘›subscriptğ‘›ğ‘¤ğ‘Œğ‘‹subscriptnormğ‘¤0ğ‘›n\equiv|X\cap Y|=v\cdot w,\;\;\;\;\;\;n\_{v}\equiv|X\setminus Y|=\|v\|\_{0}-n,\;\;\;\;\;\;n\_{w}\equiv|Y\setminus X|=\|w\|\_{0}-n |  |

Let x=1âˆ§Bâ€‹vğ‘¥1ğµğ‘£x=1\wedge Bv and y=1âˆ§Bâ€‹wğ‘¦1ğµğ‘¤y=1\wedge Bw, where Bâˆˆ{0,1}mÃ—dğµsuperscript01ğ‘šğ‘‘B\in\{0,1\}^{m\times d} is a sparse binary matrix.

Assume WLOG nwâ‰¥nvsubscriptğ‘›ğ‘¤subscriptğ‘›ğ‘£n\_{w}\geq n\_{v}.
Then for Î´âˆˆ(0,1)ğ›¿01\delta\in(0,1) and Îµ>0ğœ€0{\varepsilon}>0, there are k=Oâ€‹(Îµâˆ’1â€‹logâ¡(1/Î´))ğ‘˜ğ‘‚superscriptğœ€11ğ›¿k=O({\varepsilon}^{-1}\log(1/\delta))
and m=Oâ€‹(kâ€‹Îµâˆ’1â€‹(nvâ€‹nw+n2+Îµâ€‹(n+nw)))ğ‘šğ‘‚ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤superscriptğ‘›2ğœ€ğ‘›subscriptğ‘›ğ‘¤m=O(k{\varepsilon}^{-1}(n\_{v}n\_{w}+n^{2}+{\varepsilon}(n+n\_{w}))) such that hm,kâ€‹(xâ‹…y)=nÂ±Ïµsubscriptâ„

ğ‘šğ‘˜â‹…ğ‘¥ğ‘¦plus-or-minusğ‘›italic-Ïµh\_{m,k}(x\cdot y)=n\pm\epsilon with failure probability Î´ğ›¿\delta. Here, hm,kâ€‹(z)subscriptâ„

ğ‘šğ‘˜ğ‘§h\_{m,k}(z) (see LemmaÂ [42](#Thmtheorem42 "Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) maps the Bloom filter output 1âˆ§Bâ€‹z1ğµğ‘§1\wedge Bz to an estimate of â€–zâ€–0subscriptnormğ‘§0\|z\|\_{0}.

We remark that hm,kâ€‹(xâ‹…y)subscriptâ„

ğ‘šğ‘˜â‹…ğ‘¥ğ‘¦h\_{m,k}(x\cdot y) is not an unbiased estimator of vâ‹…wâ‹…ğ‘£ğ‘¤v\cdot w; we use a â€œBernstein versionâ€ of McDiarmid (Theorem [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")) to establish concentration of xâ‹…yâ‹…ğ‘¥ğ‘¦x\cdot y first, and conclude the success of the estimator hm,kâ€‹(xâ‹…y)subscriptâ„

ğ‘šğ‘˜â‹…ğ‘¥ğ‘¦h\_{m,k}(x\cdot y) from there.
In our analysis, we also divide xâ‹…yâ‹…ğ‘¥ğ‘¦x\cdot y into two parts: the 111s contributed by suppâ¡(v)âˆ©suppâ¡(w)suppğ‘£suppğ‘¤\operatorname{{\text{supp}}}(v)\cap\operatorname{{\text{supp}}}(w) after applying BğµB and the min operation, and the 111s contributed by suppâ¡(v)â€‹Î”â€‹suppâ¡(w)suppğ‘£Î”suppğ‘¤\operatorname{{\text{supp}}}(v)\Delta\operatorname{{\text{supp}}}(w), which may increment the same index after applyingÂ BğµB.

In the *Counting Bloom filter*, the bundle is simply BÂ¯â€‹vÂ¯ğµğ‘£{\bar{B}}v.
Here, we want to compute the *generalized* set intersection of two vectors v,w

ğ‘£ğ‘¤v,w, which refers to the coordinate-wise minimum vâˆ§wğ‘£ğ‘¤v\wedge w.
The generalized set intersection size is vâˆ§â‹…w=â€–vâˆ§wâ€–1fragmentsfragmentsâ‹…ğ‘£ğ‘¤subscriptnormğ‘£ğ‘¤1v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w=\|v\wedge w\|\_{1}.
Even though the bundle is a linear map, as was the case with MAP-I, we ultimately analyze a non-linear function for set similarity.

###### Theorem 23.

Let v,wâˆˆâ„â‰¥0d

ğ‘£ğ‘¤
superscriptsubscriptâ„absent0ğ‘‘v,w\in{\mathbb{R}}\_{\geq 0}^{d}. Let Kbâ‰¡â€–vâˆ’wâ€–âˆâ‰¤maxâ¡{â€–vâ€–âˆ,â€–wâ€–âˆ}subscriptğ¾ğ‘subscriptnormğ‘£ğ‘¤subscriptnormğ‘£subscriptnormğ‘¤K\_{b}\equiv\|v-w\|\_{\infty}\leq\max\{\|v\|\_{\infty},\|w\|\_{\infty}\}, and define:

|  |  |  |
| --- | --- | --- |
|  | nâ‰¡vâˆ§â‹…w,nvâ‰¡â€–vâ€–1âˆ’n,nwâ‰¡â€–wâ€–1âˆ’n,formulae-sequenceğ‘›fragmentsfragmentsâ‹…ğ‘£ğ‘¤formulae-sequencesubscriptğ‘›ğ‘£subscriptnormğ‘£1ğ‘›subscriptğ‘›ğ‘¤subscriptnormğ‘¤1ğ‘›n\equiv v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w,\;\;\;\;\;\;n\_{v}\equiv\|v\|\_{1}-n,\;\;\;\;\;\;n\_{w}\equiv\|w\|\_{1}-n, |  |

Let x=Bâ€‹vğ‘¥ğµğ‘£x=Bv and y=Bâ€‹wğ‘¦ğµğ‘¤y=Bw, where Bâˆˆ{0,1}mÃ—dğµsuperscript01ğ‘šğ‘‘B\in\{0,1\}^{m\times d} is a sparse binary matrix.
Then, for Î´âˆˆ(0,1)ğ›¿01\delta\in(0,1) and Îµ>0ğœ€0{\varepsilon}>0, there are
k=Oâ€‹(Kbâ€‹Îµâˆ’1â€‹logâ¡(1/Î´))ğ‘˜ğ‘‚subscriptğ¾ğ‘superscriptğœ€11ğ›¿k=O(K\_{b}{\varepsilon}^{-1}\log(1/\delta)) and m=12â€‹Ï€2â€‹kâ€‹Îµâˆ’1â€‹nvâ€‹nw=Oâ€‹(Kbâ€‹Îµâˆ’2â€‹nvâ€‹nwâ€‹logâ¡(1/Î´))ğ‘š12superscriptğœ‹2ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘‚subscriptğ¾ğ‘superscriptğœ€2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤1ğ›¿m=12\pi^{2}k{\varepsilon}^{-1}n\_{v}n\_{w}=O(K\_{b}{\varepsilon}^{-2}n\_{v}n\_{w}\log(1/\delta)) such that

|  |  |  |
| --- | --- | --- |
|  | 1kâ€‹(xâˆ§â‹…y)âˆ’(vâˆ§â‹…w)âˆˆ[0,Ïµ)1ğ‘˜fragmentsfragmentsâ‹…ğ‘¥ğ‘¦fragmentsfragmentsâ‹…ğ‘£ğ‘¤0italic-Ïµ\frac{1}{k}(x\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}y)-(v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w)\in[0,\epsilon) |  |

with failure probability at mostÂ Î´ğ›¿\delta.
Since nv+nw=â€–vâˆ’wâ€–1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤subscriptnormğ‘£ğ‘¤1n\_{v}+n\_{w}=\|v-w\|\_{1}, m=Oâ€‹(Kbâ€‹Îµâˆ’2â€‹â€–vâˆ’wâ€–12â€‹logâ¡(1/Î´))ğ‘šğ‘‚subscriptğ¾ğ‘superscriptğœ€2superscriptsubscriptnormğ‘£ğ‘¤121ğ›¿m=O(K\_{b}{\varepsilon}^{-2}\|v-w\|\_{1}^{2}\log(1/\delta)) also suffices (using the AM-GM inequality on nvâ€‹nwsubscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤n\_{v}n\_{w}).
If â€–vâ€–1,â€–wâ€–1

subscriptnormğ‘£1subscriptnormğ‘¤1\|v\|\_{1},\|w\|\_{1} are stored, then â€–vâˆ’wâ€–1subscriptnormğ‘£ğ‘¤1\|v-w\|\_{1} can be estimated up to additive Îµğœ€{\varepsilon} with the sameÂ mğ‘šm.

Our theorem helps analyze weighted sets, represented as v,wâˆˆâ„¤â‰¥0d

ğ‘£ğ‘¤
superscriptsubscriptâ„¤absent0ğ‘‘v,w\in\mathbb{Z}\_{\geq 0}^{d}, where â„¤â‰¥0subscriptâ„¤absent0\mathbb{Z}\_{\geq 0} denotes the nonnegative integers.
This also translates to a bound for estimating the â„“1subscriptâ„“1\ell\_{1} distance between vğ‘£v and wğ‘¤w, via â€–vâˆ’wâ€–1=â€–vâ€–1+â€–wâ€–1âˆ’2â€‹(vâˆ§â‹…w)subscriptnormğ‘£ğ‘¤1subscriptnormğ‘£1subscriptnormğ‘¤12fragmentsfragmentsâ‹…ğ‘£ğ‘¤\|v-w\|\_{1}=\|v\|\_{1}+\|w\|\_{1}-2(v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w).

Similarly to our proof of Theorem [22](#Thmtheorem22 "Theorem 22. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), we split 1kâ€‹(xâˆ§â‹…y)1ğ‘˜fragmentsfragmentsâ‹…ğ‘¥ğ‘¦\frac{1}{k}(x\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}y) into a contribution related to vâˆ§â‹…wfragmentsfragmentsâ‹…ğ‘£ğ‘¤v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w, which is supp(v)âˆ©supp(w)|\operatorname{{\text{supp}}}(v)\cap\operatorname{{\text{supp}}}(w)| for v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d}, and a contribution from vâˆ’(vâˆ§w)ğ‘£ğ‘£ğ‘¤v-(v\wedge w) and wâˆ’(vâˆ§w)ğ‘¤ğ‘£ğ‘¤w-(v\wedge w), which are the characteristic vectors of suppâ¡(v)âˆ–suppâ¡(w)suppğ‘£suppğ‘¤\operatorname{{\text{supp}}}(v)\setminus\operatorname{{\text{supp}}}(w) and suppâ¡(w)âˆ–suppâ¡(v)suppğ‘¤suppğ‘£\operatorname{{\text{supp}}}(w)\setminus\operatorname{{\text{supp}}}(v) for v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d}.
The proof of Theorem [23](#Thmtheorem23 "Theorem 23. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") also relies on the â€œBernstein versionâ€ of McDiarmidâ€™s inequality (TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")).

##### Roadmap for Proofs

In Â§[7.1](#S7.SS1 "7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures"), we prove TheoremÂ [22](#Thmtheorem22 "Theorem 22. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), and in Â§[7.2](#S7.SS2 "7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures"), we prove TheoremÂ [23](#Thmtheorem23 "Theorem 23. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

### 2.6 Summary of Contributions

Almost all of our results are summarized in TableÂ [3](#S2.T3 "Table 3 â€£ 2.6 Summary of Contributions â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
A few notable results *not* in the table: an analysis of Hopfield nets using standard concentration results, in Â§[5.1](#S5.SS1 "5.1 Analysis of Hopfield Networks via Concentration Bounds â€£ 5 Autocorrelation Associative Memories as Bundles of Robust Bindings â€£ Capacity Analysis of Vector Symbolic Architectures"); and an analysis of the decay in â€œsignalâ€ in MAP-B when bundling operation trees have nontrivial depth in Â§[6.1.2](#S6.SS1.SSS2 "6.1.2 Dependence on Depth â€£ 6.1 Bundling â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures").

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
| VSA | Op | Expression | Dimension mğ‘šm | Thm. or Section |
| MAP-I | S | â€–SÂ¯â€‹vâ€–2superscriptnormÂ¯ğ‘†ğ‘£2\|{\bar{S}}v\|^{2} | Oâ€‹(Îµâˆ’2â€‹logâ¡(1/Î´))ğ‘‚superscriptğœ€21ğ›¿O({\varepsilon}^{-2}\log(1/\delta)) | LemÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| Sparse JL | S | â€–Pğš‚ğ™¹ğ™»â€‹vâ€–2superscriptnormsubscriptğ‘ƒğš‚ğ™¹ğ™»ğ‘£2\|P\_{\mathtt{SJL}}v\|^{2} | Oâ€‹(Îµâˆ’2â€‹logâ¡(1/Î´))ğ‘‚superscriptğœ€21ğ›¿O({\varepsilon}^{-2}\log(1/\delta)) | Â§[4.1.1](#S4.SS1.SSS1 "4.1.1 Variations Using Alternative Sketching Matrices â€£ 4.1 Bundling and Set Intersection â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures") |
| SRHT | S | â€–Pğš‚ğšğ™·ğšƒâ€‹vâ€–2superscriptnormsubscriptğ‘ƒğš‚ğšğ™·ğšƒğ‘£2\|P\_{\mathtt{SRHT}}v\|^{2} | Oâ€‹(Îµâˆ’2â€‹logâ¡(1/Î´)â€‹log4â¡d)ğ‘‚superscriptğœ€21ğ›¿superscript4ğ‘‘O({\varepsilon}^{-2}\log(1/\delta)\log^{4}d) | Â§[4.1.1](#S4.SS1.SSS1 "4.1.1 Variations Using Alternative Sketching Matrices â€£ 4.1 Bundling and Set Intersection â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures") |
| MAP-I | SS | â€–SÂ¯R,Lâ€‹vâ€–2superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2\|{\bar{S}}\_{R,L}v\|^{2} | Oâ€‹(Îµâˆ’2â€‹L2â€‹logâ¡(L/Î´))ğ‘‚superscriptğœ€2superscriptğ¿2ğ¿ğ›¿O({\varepsilon}^{-2}L^{2}\log(L/\delta)) | ThmÂ [9](#Thmtheorem9 "Theorem 9. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| MAP-I | SS | â€–SÂ¯R,Lâ€‹vâ€–2superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2\|{\bar{S}}\_{R,L}v\|^{2} | Oâ€‹(Îµâˆ’2â€‹K2â€‹logâ¡(K/(Îµâ€‹Î´)))ğ‘‚superscriptğœ€2superscriptğ¾2ğ¾ğœ€ğ›¿O\left({\varepsilon}^{-2}K^{2}\log(K/({\varepsilon}\delta))\right) | ThmÂ [10](#Thmtheorem10 "Theorem 10. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| MAP-I | BB | â€–SÂ¯âŠ™2â€‹vâ€–2superscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2\|{\bar{S}}^{\odot 2}v\|^{2} | O(Îµâˆ’2log(âˆ¥vâˆ¥1/ÎµÎ´)3)O({\varepsilon}^{-2}\log(\|v\|\_{1}/{\varepsilon}\delta)^{3}) | ThmÂ [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| MAP-I | BB | â€–SÂ¯âŠ™kâ€‹vâ€–2superscriptnormsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£2\|{\bar{S}}^{\odot k}v\|^{2} | Oâ€‹(Îµâˆ’2â€‹Ckâ€‹logâ¡kâ€‹logk+1â¡(kâ€‹â€–vâ€–1/(Îµâ€‹Î´)))ğ‘‚superscriptğœ€2superscriptğ¶ğ‘˜ğ‘˜superscriptğ‘˜1ğ‘˜subscriptnormğ‘£1ğœ€ğ›¿O(\varepsilon^{-2}C^{k\log k}\log^{k+1}(k\|v\|\_{1}/(\varepsilon\delta))) | CorÂ [13](#Thmtheorem13 "Corollary 13. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| HopfieldÂ±plus-or-minus\pm | S | trâ¡(SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤)trÂ¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†top\operatorname{tr}({\bar{S}}VD{\bar{S}}^{\top}) | O(Îµâˆ’1log(d/Î´)2)O({\varepsilon}^{-1}\log(d/\delta)^{2}) (space is m2superscriptğ‘š2m^{2}) | ThmÂ [15](#Thmtheorem15 "Theorem 15. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| MAP-B | MS | sign(Sv)âŠ¤Sâˆ—jâ‰¥Ï„b\operatorname{{\text{sign}}}(Sv)^{\top}S\_{\*j}\geq\tau\_{b} | Oâ€‹(â€–vâ€–1â€‹logâ¡(d/Î´))ğ‘‚subscriptnormğ‘£1ğ‘‘ğ›¿O(\|v\|\_{1}\log(d/\delta)) | ThmÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| MAP-B | MSS | sign(SR,Lv)âŠ¤Sâˆ—,j%dâ‰¥Ï„b\operatorname{{\text{sign}}}(S\_{R,L}v)^{\top}S\_{\*,j\_{{\scriptscriptstyle\%}d}}\geq\tau\_{b} | Oâ€‹(â€–vâ€–1â€‹Lâ€‹logâ¡(Lâ€‹d/Î´))ğ‘‚subscriptnormğ‘£1ğ¿ğ¿ğ‘‘ğ›¿O(\|v\|\_{1}L\log(Ld/\delta)) | Thm.Â [18](#Thmtheorem18 "Theorem 18. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| MAP-B | MKV | sign(SâŠ™2v)âŠ¤Sâˆ—jâŠ™2â‰¥2Ï„b\operatorname{{\text{sign}}}(S^{\odot 2}v)^{\top}S^{\odot 2}\_{\*j}\geq\sqrt{2}\tau\_{b} | Oâ€‹(â€–vâ€–1â€‹logâ¡(d/Î´))ğ‘‚subscriptnormğ‘£1ğ‘‘ğ›¿O(\|v\|\_{1}\log(d/\delta)) | ThmÂ [20](#Thmtheorem20 "Theorem 20. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| Bloom | SI | hm,kâ€‹(Bâ€‹vâ‹…Bâ€‹w)subscriptâ„  ğ‘šğ‘˜â‹…ğµğ‘£ğµğ‘¤h\_{m,k}(Bv\cdot Bw) | Oâ€‹(kâ€‹Îµâˆ’1â€‹(nvâ€‹nw+n2+Îµâ€‹(n+nw)))ğ‘‚ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤superscriptğ‘›2ğœ€ğ‘›subscriptğ‘›ğ‘¤O(k{\varepsilon}^{-1}(n\_{v}n\_{w}+n^{2}+{\varepsilon}(n+n\_{w}))) k=Oâ€‹(Îµâˆ’1â€‹logâ¡(1/Î´))ğ‘˜ğ‘‚superscriptğœ€11ğ›¿k=O({\varepsilon}^{-1}\log(1/\delta)) | ThmÂ [22](#Thmtheorem22 "Theorem 22. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |
| Counting Bloom | GSI | Bâ€‹vâˆ§â‹…Bâ€‹wfragmentsfragmentsâ‹…ğµğ‘£ğµğ‘¤Bv\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}Bw | Oâ€‹(kâ€‹Îµâˆ’1â€‹nvâ€‹nw)ğ‘‚ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤O(k{\varepsilon}^{-1}n\_{v}n\_{w}) k=Oâ€‹(Kbâ€‹Îµâˆ’1â€‹logâ¡(1/Î´))ğ‘˜ğ‘‚subscriptğ¾ğ‘superscriptğœ€11ğ›¿k=O(K\_{b}{\varepsilon}^{-1}\log(1/\delta)) | ThmÂ [23](#Thmtheorem23 "Theorem 23. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") |

Table 3: We compile the bounds in this paper for various architectures and operations.
Here
Î´ğ›¿\delta is a bound on the failure probability;
mğ‘šm is the VSA dimension;
dğ‘‘d is the size of the groundset of symbols;
S,SÂ¯

ğ‘†Â¯ğ‘†S,{\bar{S}} are defined in Def.Â [2](#Thmtheorem2 "Definition 2. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures");
Lğ¿L is the sequence length;
SÂ¯R,LsubscriptÂ¯ğ‘†

ğ‘…ğ¿{\bar{S}}\_{R,L} denotes a sequence, Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures");
SÂ¯âŠ™ksuperscriptÂ¯ğ‘†direct-productabsentğ‘˜{\bar{S}}^{\odot k} denotes a bundle of bindings, Def.Â [11](#Thmtheorem11 "Definition 11. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures");
and
vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d} for sets of singletons, vâˆˆ{0,1}Lâ€‹dğ‘£superscript01ğ¿ğ‘‘v\in\{0,1\}^{Ld} for sequences, vâˆˆ{0,1}(dk)ğ‘£superscript01binomialğ‘‘ğ‘˜v\in\{0,1\}^{\binom{d}{k}} for bundles of kğ‘˜k bindings.
  
The first block of rows are bounds for norm-preserving *linear* operators, so that relative error Îµğœ€{\varepsilon} bound for each in estimating â€–vâ€–normğ‘£\|v\| translates to an error bound for estimating â€–uâˆ’vâ€–normğ‘¢ğ‘£\|u-v\| for many pairs of vectors u,v

ğ‘¢ğ‘£u,v, as in Cor.Â [4](#Thmtheorem4 "Corollary 4. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"); dot products, as in Cor.Â [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"); and in computing set intersection sizes under a variety of conditions on the set sizes, Thm.Â [6](#Thmtheorem6 "Theorem 6. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
  
First block notation:
operation *S* is estimation of size of a set;
*SS* is size of sequence of sets;
*BB* is size of a Bundle of Bindings (set of bound key-value pairs);
matrices Pğš‚ğ™¹ğ™»,Pğš‚ğšğ™·ğšƒ

subscriptğ‘ƒğš‚ğ™¹ğ™»subscriptğ‘ƒğš‚ğšğ™·ğšƒP\_{\mathtt{SJL}},P\_{\mathtt{SRHT}} are sparse JL matrix and SRHT matrix, as discussed in Â§[4.1.1](#S4.SS1.SSS1 "4.1.1 Variations Using Alternative Sketching Matrices â€£ 4.1 Bundling and Set Intersection â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures");
Kğ¾K the maximum number of times a symbol appears in a sequence;
Vğ‘‰V is a diagonal matrix version of vğ‘£v;
Dğ·D is a diagonal sign matrix.
  
The second block are operations with non-linear steps. Îµğœ€{\varepsilon} is the *additive* estimation error.
  
Second block notation:
operation *MS* is set membership test;
*MSS* is membership in a sequence of sets;
*MKV* is membership in a bundle of bindings, where the bindings are key-value pairs;
*GSI* is generalized set intersection (estimation of vâˆ§â‹…w=âˆ‘iminâ¡{vi,wi}fragmentsfragmentsâ‹…ğ‘£ğ‘¤subscriptğ‘–subscriptğ‘£ğ‘–subscriptğ‘¤ğ‘–v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w=\sum\_{i}\min\{v\_{i},w\_{i}\});
matrix BğµB is a sparse binary matrix, Def.Â [21](#Thmtheorem21 "Definition 21. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures");
Ï„b=2â€‹mâ€‹logâ¡(2â€‹d/Î´)subscriptğœğ‘2ğ‘š2ğ‘‘ğ›¿\tau\_{b}=\sqrt{2m\log(2d/\delta)};
kğ‘˜k is the number of nonzeros per column ofÂ BğµB;
hm,kâ€‹(z)=1kâ€‹log1âˆ’1/mâ¡(1âˆ’z/m)subscriptâ„

ğ‘šğ‘˜ğ‘§1ğ‘˜subscript11ğ‘š1ğ‘§ğ‘šh\_{m,k}(z)=\frac{1}{k}\log\_{1-1/m}(1-z/m), defined in Lem.Â [42](#Thmtheorem42 "Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures");
v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d} for Bloom filters;
v,wâˆˆâ„¤â‰¥0d

ğ‘£ğ‘¤
superscriptsubscriptâ„¤absent0ğ‘‘v,w\in{\mathbb{Z}}\_{\geq 0}^{d} for Counting Bloom filters;
Kb=â€–vâˆ’wâ€–âˆâ‰¤maxâ¡{â€–vâ€–âˆ,â€–wâ€–âˆ}subscriptğ¾ğ‘subscriptnormğ‘£ğ‘¤subscriptnormğ‘£subscriptnormğ‘¤K\_{b}=\|v-w\|\_{\infty}\leq\max\{\|v\|\_{\infty},\|w\|\_{\infty}\}; finally,
n=vâˆ§â‹…wğ‘›fragmentsfragmentsâ‹…ğ‘£ğ‘¤n=v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w, nv=â€–vâ€–1âˆ’nsubscriptğ‘›ğ‘£subscriptnormğ‘£1ğ‘›n\_{v}=\|v\|\_{1}-n, and nw=â€–wâ€–1âˆ’nsubscriptğ‘›ğ‘¤subscriptnormğ‘¤1ğ‘›n\_{w}=\|w\|\_{1}-n, so nv+nw=â€–vâˆ’wâ€–1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤subscriptnormğ‘£ğ‘¤1n\_{v}+n\_{w}=\|v-w\|\_{1}.

{toappendix}

## 3 Preliminaries and Concentration Inequalities

In this section, we include a few useful concentration inequalities for functions of random variables that are used throughout our VSA analysis.

Let f:Î©1Ã—â€¦Ã—Î©nâ†’â„:ğ‘“â†’subscriptÎ©1â€¦subscriptÎ©ğ‘›â„f:\Omega\_{1}\times\ldots\times\Omega\_{n}\to\mathbb{R} be an arbitrary function on nğ‘›n variables.

###### Definition 24.

A function f:Î©1Ã—â€¦Ã—Î©nâ†’â„:ğ‘“â†’subscriptÎ©1â€¦subscriptÎ©ğ‘›â„f:\Omega\_{1}\times\ldots\times\Omega\_{n}\to\mathbb{R} has *bounded differences with constants {ci}iâˆˆ[n]subscriptsubscriptğ‘ğ‘–ğ‘–delimited-[]ğ‘›\{c\_{i}\}\_{i\in[n]}* if for all x1âˆˆÎ©1,â€¦,xnâˆˆÎ©nformulae-sequencesubscriptğ‘¥1

subscriptÎ©1â€¦subscriptğ‘¥ğ‘›subscriptÎ©ğ‘›x\_{1}\in\Omega\_{1},\ldots,x\_{n}\in\Omega\_{n} and all iâˆˆ[n]ğ‘–delimited-[]ğ‘›i\in[n],

|  |  |  |
| --- | --- | --- |
|  | supyâˆˆÎ©i|fâ€‹(x1,â€¦,xiâˆ’1,xi,xi+1,â€¦,xn)âˆ’fâ€‹(x1,â€¦,xiâˆ’1,y,xi+1,â€¦,xn)|â‰¤cisubscriptsupremumğ‘¦subscriptÎ©ğ‘–ğ‘“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘–1subscriptğ‘¥ğ‘–subscriptğ‘¥ğ‘–1â€¦subscriptğ‘¥ğ‘›ğ‘“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘–1ğ‘¦subscriptğ‘¥ğ‘–1â€¦subscriptğ‘¥ğ‘›subscriptğ‘ğ‘–\sup\_{y\in\Omega\_{i}}\left|f(x\_{1},\ldots,x\_{i-1},x\_{i},x\_{i+1},\ldots,x\_{n})-f(x\_{1},\ldots,x\_{i-1},y,x\_{i+1},\ldots,x\_{n})\right|\leq c\_{i} |  |

When we want to study how fğ‘“f applied to a random variable Xğ‘‹X concentrates around its mean ğ”¼â€‹[fâ€‹(X)]ğ”¼delimited-[]ğ‘“ğ‘‹{\mathbb{E}}[f(X)], the most standard tool is McDiarmidâ€™s inequality.
The usual form of McDiarmidâ€™s inequality is the following statement:

###### Theorem 25.

Let X=(X1,â€¦,Xn)ğ‘‹subscriptğ‘‹1â€¦subscriptğ‘‹ğ‘›X=(X\_{1},\ldots,X\_{n}) be a tuple of independent random variables supported on Î©1,â€¦,Î©n

subscriptÎ©1â€¦subscriptÎ©ğ‘›\Omega\_{1},\ldots,\Omega\_{n}, respectively.
If fğ‘“f has bounded differences with constants c1,â€¦,cn

subscriptğ‘1â€¦subscriptğ‘ğ‘›c\_{1},\ldots,c\_{n}, then:

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]>t]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹ğ‘¡\displaystyle\Pr\left[f(X)-{\mathbb{E}}[f(X)]>t\right] | â‰¤expâ¡(âˆ’2â€‹t2âˆ‘i=1nci2)absent2superscriptğ‘¡2superscriptsubscriptğ‘–1ğ‘›superscriptsubscriptğ‘ğ‘–2\displaystyle\leq\exp\left(-\frac{2t^{2}}{\sum\_{i=1}^{n}c\_{i}^{2}}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]<âˆ’t]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹ğ‘¡\displaystyle\Pr\left[f(X)-{\mathbb{E}}[f(X)]<-t\right] | â‰¤expâ¡(âˆ’2â€‹t2âˆ‘i=1nci2)absent2superscriptğ‘¡2superscriptsubscriptğ‘–1ğ‘›superscriptsubscriptğ‘ğ‘–2\displaystyle\leq\exp\left(-\frac{2t^{2}}{\sum\_{i=1}^{n}c\_{i}^{2}}\right) |  |

We now derive a standard variant (CorollaryÂ [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")) of McDiarmid that applies when the bounded differences hold with high probability.
This is not a novel modification, but we include it for completeness.
The corollary follows from the following lemma, which we will also use throughout our VSA analysis.

###### Lemma 26.

Let Xğ‘‹X be a random variable taking values in domain Dğ·D, e.g. D=â„nğ·superscriptâ„ğ‘›D={\mathbb{R}}^{n}.
Let fğ‘“f and gğ‘”g map from Dğ·D to â„â„{\mathbb{R}}, such that Prâ¡[gâ€‹(X)â‰ fâ€‹(X)]â‰¤Î´Prğ‘”ğ‘‹ğ‘“ğ‘‹ğ›¿\Pr[g(X)\neq f(X)]\leq\delta, with gâ€‹(X)=0ğ‘”ğ‘‹0g(X)=0 when gâ€‹(X)â‰ fâ€‹(X)ğ‘”ğ‘‹ğ‘“ğ‘‹g(X)\neq f(X), and supxâˆˆDfâ€‹(x)â‰¤Msubscriptsupremumğ‘¥ğ·ğ‘“ğ‘¥ğ‘€\sup\_{x\in D}f(x)\leq M for a value Mâˆˆâ„ğ‘€â„M\in{\mathbb{R}}.
Then

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]>t+Î´â€‹M]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹ğ‘¡ğ›¿ğ‘€\displaystyle\Pr[f(X)-{\mathbb{E}}[f(X)]>t+\delta M] | â‰¤Prâ¡[gâ€‹(X)âˆ’ğ”¼â€‹[gâ€‹(X)]>t]+Î´absentPrğ‘”ğ‘‹ğ”¼delimited-[]ğ‘”ğ‘‹ğ‘¡ğ›¿\displaystyle\leq\Pr[g(X)-{\mathbb{E}}[g(X)]>t]+\delta |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]<âˆ’tâˆ’Î´â€‹M]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹ğ‘¡ğ›¿ğ‘€\displaystyle\Pr[f(X)-{\mathbb{E}}[f(X)]<-t-\delta M] | â‰¤Prâ¡[gâ€‹(X)âˆ’ğ”¼â€‹[gâ€‹(X)]<âˆ’t]+Î´absentPrğ‘”ğ‘‹ğ”¼delimited-[]ğ‘”ğ‘‹ğ‘¡ğ›¿\displaystyle\leq\Pr[g(X)-{\mathbb{E}}[g(X)]<-t]+\delta |  |

###### Proof.

Let BğµB be the â€œbad subsetâ€ of Dğ·D where gâ€‹(X)â‰ fâ€‹(X)ğ‘”ğ‘‹ğ‘“ğ‘‹g(X)\neq f(X).
Here ğ”¼â€‹[gâ€‹(X)]ğ”¼delimited-[]ğ‘”ğ‘‹{\mathbb{E}}[g(X)] is close but not equal to ğ”¼â€‹[fâ€‹(X)]ğ”¼delimited-[]ğ‘“ğ‘‹{\mathbb{E}}[f(X)]:

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[fâ€‹(X)]ğ”¼delimited-[]ğ‘“ğ‘‹\displaystyle{\mathbb{E}}[f(X)] | =âˆ‘xâˆ‰BPrâ¡[X=x]â‹…fâ€‹(x)+âˆ‘xâˆˆBPrâ¡[X=x]â‹…fâ€‹(x)absentsubscriptğ‘¥ğµâ‹…Prğ‘‹ğ‘¥ğ‘“ğ‘¥subscriptğ‘¥ğµâ‹…Prğ‘‹ğ‘¥ğ‘“ğ‘¥\displaystyle=\sum\_{x\notin B}\Pr[X=x]\cdot f(x)+\sum\_{x\in B}\Pr[X=x]\cdot f(x) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤âˆ‘(x)âˆ‰BPrâ¡[X=x]â‹…gâ€‹(x)+Î´â€‹M=ğ”¼â€‹[gâ€‹(X)]+Î´â€‹Mabsentsubscriptğ‘¥ğµâ‹…Prğ‘‹ğ‘¥ğ‘”ğ‘¥ğ›¿ğ‘€ğ”¼delimited-[]ğ‘”ğ‘‹ğ›¿ğ‘€\displaystyle\leq\sum\_{(x)\notin B}\Pr[X=x]\cdot g(x)+\delta M={\mathbb{E}}[g(X)]+\delta M |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Similarly,Â â€‹ğ”¼â€‹[fâ€‹(X)]Similarly,Â ğ”¼delimited-[]ğ‘“ğ‘‹\displaystyle\text{Similarly, }{\mathbb{E}}[f(X)] | â‰¥ğ”¼â€‹[gâ€‹(X)]âˆ’Î´â€‹Mabsentğ”¼delimited-[]ğ‘”ğ‘‹ğ›¿ğ‘€\displaystyle\geq{\mathbb{E}}[g(X)]-\delta M |  |

Using this relationship between the means of fâ€‹(X)ğ‘“ğ‘‹f(X) and gâ€‹(X)ğ‘”ğ‘‹g(X), we have.

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]â‰¥tâ€²]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹superscriptğ‘¡â€²\displaystyle\Pr\left[f(X)-{\mathbb{E}}[f(X)]\geq t^{\prime}\right] | â‰¤Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]â‰¥tâ€²|fâ€‹(X)=gâ€‹(X)]â‹…Prâ¡[fâ€‹(X)=gâ€‹(X)]+Î´absentâ‹…Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹conditionalsuperscriptğ‘¡â€²ğ‘“ğ‘‹ğ‘”ğ‘‹Prğ‘“ğ‘‹ğ‘”ğ‘‹ğ›¿\displaystyle\leq\Pr\left[f(X)-{\mathbb{E}}[f(X)]\geq t^{\prime}\,|\,f(X)=g(X)\right]\cdot\Pr[f(X)=g(X)]+\delta |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Prâ¡[gâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]â‰¥tâ€²|fâ€‹(X)=gâ€‹(X)]â‹…Prâ¡[fâ€‹(X)=gâ€‹(X)]+Î´absentâ‹…Prğ‘”ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹conditionalsuperscriptğ‘¡â€²ğ‘“ğ‘‹ğ‘”ğ‘‹Prğ‘“ğ‘‹ğ‘”ğ‘‹ğ›¿\displaystyle\leq\Pr\left[g(X)-{\mathbb{E}}[f(X)]\geq t^{\prime}\,|\,f(X)=g(X)\right]\cdot\Pr[f(X)=g(X)]+\delta |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Prâ¡[gâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]â‰¥tâ€²]+Î´absentPrğ‘”ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹superscriptğ‘¡â€²ğ›¿\displaystyle\leq\Pr[g(X)-{\mathbb{E}}[f(X)]\geq t^{\prime}]+\delta |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Prâ¡[gâ€‹(X)âˆ’ğ”¼â€‹[gâ€‹(X)]â‰¥tâ€²âˆ’Î´â€‹M]+Î´absentPrğ‘”ğ‘‹ğ”¼delimited-[]ğ‘”ğ‘‹superscriptğ‘¡â€²ğ›¿ğ‘€ğ›¿\displaystyle\leq\Pr[g(X)-{\mathbb{E}}[g(X)]\geq t^{\prime}-\delta M]+\delta |  |

The final line comes from the fact that ğ”¼â€‹[fâ€‹(X)]â‰¥ğ”¼â€‹[gâ€‹(X)]âˆ’Î´â€‹Mğ”¼delimited-[]ğ‘“ğ‘‹ğ”¼delimited-[]ğ‘”ğ‘‹ğ›¿ğ‘€{\mathbb{E}}[f(X)]\geq{\mathbb{E}}[g(X)]-\delta M.
Letting tâ€²=t+Î´â€‹Msuperscriptğ‘¡â€²ğ‘¡ğ›¿ğ‘€t^{\prime}=t+\delta M yields the desired bound.
The upper bound for Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]â‰¤âˆ’tâ€²]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹superscriptğ‘¡â€²\Pr\left[f(X)-{\mathbb{E}}[f(X)]\leq-t^{\prime}\right] is analogous.
âˆ

###### Corollary 27.

Let X1,â€¦,Xn

subscriptğ‘‹1â€¦subscriptğ‘‹ğ‘›X\_{1},\ldots,X\_{n} be independent random variables supported on Î©1,â€¦,Î©n

subscriptÎ©1â€¦subscriptÎ©ğ‘›\Omega\_{1},\ldots,\Omega\_{n}, respectively.
Define M:=supx1,â€¦,xn|fâ€‹(x1,â€¦,xn)|assignğ‘€subscriptsupremum

subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘›ğ‘“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘›M:=\sup\_{x\_{1},\ldots,x\_{n}}|f(x\_{1},\ldots,x\_{n})|.
If with probability 1âˆ’Î´1ğ›¿1-\delta over X1,â€¦,Xn

subscriptğ‘‹1â€¦subscriptğ‘‹ğ‘›X\_{1},\ldots,X\_{n}, the function fğ‘“f has bounded differences with constants c1,â€¦,cn

subscriptğ‘1â€¦subscriptğ‘ğ‘›c\_{1},\ldots,c\_{n}, i.e. there is a set SâŠ†Î©ğ‘†Î©S\subseteq\Omega with Prâ¡[XâˆˆS]=1âˆ’Î´Prğ‘‹ğ‘†1ğ›¿\Pr[X\in S]=1-\delta such that for all (x1,â€¦,xn)âˆˆSsubscriptğ‘¥1â€¦subscriptğ‘¥ğ‘›ğ‘†(x\_{1},\ldots,x\_{n})\in S and iâˆˆ[n]ğ‘–delimited-[]ğ‘›i\in[n], we satisfy

|  |  |  |
| --- | --- | --- |
|  | supyâˆˆÎ©i|fâ€‹(x1,â€¦,xiâˆ’1,xi,xi+1,â€¦,xn)âˆ’fâ€‹(x1,â€¦,xiâˆ’1,y,xi+1,â€¦,xn)|â‰¤cisubscriptsupremumğ‘¦subscriptÎ©ğ‘–ğ‘“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘–1subscriptğ‘¥ğ‘–subscriptğ‘¥ğ‘–1â€¦subscriptğ‘¥ğ‘›ğ‘“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘–1ğ‘¦subscriptğ‘¥ğ‘–1â€¦subscriptğ‘¥ğ‘›subscriptğ‘ğ‘–\sup\_{y\in\Omega\_{i}}\left|f(x\_{1},\ldots,x\_{i-1},x\_{i},x\_{i+1},\ldots,x\_{n})-f(x\_{1},\ldots,x\_{i-1},y,x\_{i+1},\ldots,x\_{n})\right|\leq c\_{i} |  |

then both of the following inequalities hold.

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]>t+Î´â€‹M]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹ğ‘¡ğ›¿ğ‘€\displaystyle\Pr\left[f(X)-{\mathbb{E}}[f(X)]>t+\delta M\right] | â‰¤expâ¡(âˆ’2â€‹t2âˆ‘i=1nci2)+Î´absent2superscriptğ‘¡2superscriptsubscriptğ‘–1ğ‘›superscriptsubscriptğ‘ğ‘–2ğ›¿\displaystyle\leq\exp\left(-\frac{2t^{2}}{\sum\_{i=1}^{n}c\_{i}^{2}}\right)+\delta |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Pr[f(X)âˆ’ğ”¼[f(X)]<âˆ’tâˆ’Î´M]]\displaystyle\Pr\left[f(X)-{\mathbb{E}}[f(X)]<-t-\delta M]\right] | â‰¤expâ¡(âˆ’2â€‹t2âˆ‘i=1nci2)+Î´absent2superscriptğ‘¡2superscriptsubscriptğ‘–1ğ‘›superscriptsubscriptğ‘ğ‘–2ğ›¿\displaystyle\leq\exp\left(-\frac{2t^{2}}{\sum\_{i=1}^{n}c\_{i}^{2}}\right)+\delta |  |

###### Proof.

Apply LemmaÂ [26](#Thmtheorem26 "Lemma 26. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") to fğ‘“f and the function gğ‘”g defined as taking the same value of fğ‘“f for X1,â€¦,Xn

subscriptğ‘‹1â€¦subscriptğ‘‹ğ‘›X\_{1},\ldots,X\_{n} such that the bounded differences hold, and zero otherwise. Then, we apply TheoremÂ [25](#Thmtheorem25 "Theorem 25. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") toÂ gğ‘”g.
âˆ

There is also a version of McDiarmidâ€™s inequality that incorporates variances; we refer to it as the â€œBernstein form of McDiarmidâ€™s Inequality:â€

###### Theorem 28 ([ying\_mcdiarmids\_2004]).

Let X=(X1,â€¦,Xn)ğ‘‹subscriptğ‘‹1â€¦subscriptğ‘‹ğ‘›X=(X\_{1},\ldots,X\_{n}) be a tuple of independent random variables supported on Î©â‰¡âˆiâˆˆ[n]Î©iÎ©subscriptproductğ‘–delimited-[]ğ‘›subscriptÎ©ğ‘–\Omega\equiv\prod\_{i\in[n]}\Omega\_{i}.
For function f:Î©â†’Iâ€‹R:ğ‘“â†’Î©IRf:\Omega\rightarrow\operatorname{{\mathrm{I\!R}}} and xâˆˆÎ©,iâˆˆ[n],yâˆˆÎ©iformulae-sequenceğ‘¥Î©formulae-sequenceğ‘–delimited-[]ğ‘›ğ‘¦subscriptÎ©ğ‘–x\in\Omega,i\in[n],y\in\Omega\_{i}, let
giâ€‹(x,y)â‰¡fâ€‹(x1,â€¦,xiâˆ’1,y,xi+1,â€¦,xn)subscriptğ‘”ğ‘–ğ‘¥ğ‘¦ğ‘“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘–1ğ‘¦subscriptğ‘¥ğ‘–1â€¦subscriptğ‘¥ğ‘›g\_{i}(x,y)\equiv f(x\_{1},\ldots,x\_{i-1},y,x\_{i+1},\ldots,x\_{n}).
(Note that giâ€‹(x,y)subscriptğ‘”ğ‘–ğ‘¥ğ‘¦g\_{i}(x,y) does not depend on xisubscriptğ‘¥ğ‘–x\_{i}.)
Let

|  |  |  |  |
| --- | --- | --- | --- |
|  | Variâ€‹(f)subscriptVarğ‘–ğ‘“\displaystyle{\textbf{Var}}\_{i}(f) | â‰¡supxâˆˆÎ©ğ”¼Xiâ€‹[(giâ€‹(x,Xi)âˆ’ğ”¼Xiâ€²â€‹giâ€‹(x,Xiâ€²))2]absentsubscriptsupremumğ‘¥Î©subscriptğ”¼subscriptğ‘‹ğ‘–delimited-[]superscriptsubscriptğ‘”ğ‘–ğ‘¥subscriptğ‘‹ğ‘–subscriptğ”¼subscriptsuperscriptğ‘‹â€²ğ‘–subscriptğ‘”ğ‘–ğ‘¥subscriptsuperscriptğ‘‹â€²ğ‘–2\displaystyle\equiv\sup\_{x\in\Omega}{\mathbb{E}}\_{X\_{i}}\left[\left(g\_{i}(x,X\_{i})-{\mathbb{E}}\_{X^{\prime}\_{i}}g\_{i}(x,X^{\prime}\_{i})\right)^{2}\right] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Ïƒ~â€‹(f)~ğœğ‘“\displaystyle{\tilde{\sigma}}(f) | â‰¡âˆ‘iâˆˆ[n]Variâ€‹(f)absentsubscriptğ‘–delimited-[]ğ‘›subscriptVarğ‘–ğ‘“\displaystyle\equiv\sum\_{i\in[n]}{\textbf{Var}}\_{i}(f) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Bâ€‹(f)ğµğ‘“\displaystyle B(f) | â‰¡maxiâˆˆ[n]â€‹supxâˆˆÎ©|giâ€‹(x,Xi)âˆ’ğ”¼Xiâ€²â€‹giâ€‹(x,Xiâ€²)|absentsubscriptğ‘–delimited-[]ğ‘›subscriptsupremumğ‘¥Î©subscriptğ‘”ğ‘–ğ‘¥subscriptğ‘‹ğ‘–subscriptğ”¼subscriptsuperscriptğ‘‹â€²ğ‘–subscriptğ‘”ğ‘–ğ‘¥subscriptsuperscriptğ‘‹â€²ğ‘–\displaystyle\equiv\max\_{i\in[n]}\sup\_{x\in\Omega}\left|g\_{i}(x,X\_{i})-{\mathbb{E}}\_{X^{\prime}\_{i}}g\_{i}(x,X^{\prime}\_{i})\right| |  |

Then

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]>t]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹ğ‘¡\displaystyle\Pr\left[f(X)-{\mathbb{E}}[f(X)]>t\right] | â‰¤expâ¡(âˆ’2â€‹t2Ïƒ~â€‹(f)+tâ€‹Bâ€‹(f)/3)absent2superscriptğ‘¡2~ğœğ‘“ğ‘¡ğµğ‘“3\displaystyle\leq\exp\left(-\frac{2t^{2}}{{\tilde{\sigma}}(f)+tB(f)/3}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[fâ€‹(X)âˆ’ğ”¼â€‹[fâ€‹(X)]<âˆ’t]Prğ‘“ğ‘‹ğ”¼delimited-[]ğ‘“ğ‘‹ğ‘¡\displaystyle\Pr\left[f(X)-{\mathbb{E}}[f(X)]<-t\right] | â‰¤expâ¡(âˆ’2â€‹t2Ïƒ~â€‹(f)+tâ€‹Bâ€‹(f)/3)absent2superscriptğ‘¡2~ğœğ‘“ğ‘¡ğµğ‘“3\displaystyle\leq\exp\left(-\frac{2t^{2}}{{\tilde{\sigma}}(f)+tB(f)/3}\right) |  |

We will also need this known concentration bound for Rademacher random variables.

###### Theorem 29.

Let X1,â€¦,Xn

subscriptğ‘‹1â€¦subscriptğ‘‹ğ‘›X\_{1},\ldots,X\_{n} be independent Rademacher random variables. Let (a1,â€¦,an)subscriptğ‘1â€¦subscriptğ‘ğ‘›(a\_{1},\ldots,a\_{n}) be an arbitrary vector in â„nsuperscriptâ„ğ‘›{\mathbb{R}}^{n}. Then,

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[âˆ‘i=1naiâ€‹Xiâ‰¥tâ€‹â€–aâ€–2]â‰¤expâ¡(âˆ’t22)Prsuperscriptsubscriptğ‘–1ğ‘›subscriptğ‘ğ‘–subscriptğ‘‹ğ‘–ğ‘¡subscriptnormğ‘2superscriptğ‘¡22\Pr\left[\sum\_{i=1}^{n}a\_{i}X\_{i}\geq t\|a\|\_{2}\right]\leq\exp\left(-\frac{t^{2}}{2}\right) |  |

## 4 Analysis of MAP-I Using Johnson-Lindenstrauss

In Â§[4.1](#S4.SS1 "4.1 Bundling and Set Intersection â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures"), we analyze MAP-I bundling, including the relation of norm estimation to distance, set intersection, and angle estimation, and discuss how the JL perspective extends to the sparse JL and Subsampled Randomized Hadamard Transforms (SRHTs).

Next, in Â§[4.2](#S4.SS2 "4.2 Rotations for Encoding Sequences â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures"), we analyze the VSA dimension needed to reliably estimate the intersection of two *sequences* of sets, as encoded using rotations, in both a general and a more restricted setting.
This entails proving the JL property for a specific kind of random matrix with dependent entries.

Finally, in Â§[4.3](#S4.SS3 "4.3 Binding â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures"), we analyze intersection of bundles of bound pairs and bundles of kğ‘˜k-wise bindings.
Again, we establish the JL property for a random matrix with dependent entries.
While bundles of key-value bindings have been analyzed before, bundles of kğ‘˜k-wise bindings have not.

### 4.1 Bundling and Set Intersection

The results in this section may apply to VSAs beyond just MAP-I where the bundling operator is addition over the real numbers.
SectionÂ 3.1 of [thomas2021theoretical] gives some representational bounds in that setting.
Though we provide similar bounds, we frame our results using the Johnson-Lindenstrauss (JL) random projection lemma, which provides a simpler yet powerful lens through which to view the MAP-I VSA.
(A connection to JL was briefly mentioned by [kent2020multiplicative], but it did not factor into any capacity analysis there.)

We first introduce the Johnson-Lindenstrauss (JL) lemma:

###### Lemma (Restatement of Lemma [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Suppose SÂ¯âˆˆ1mâ€‹{âˆ’1,1}mÃ—dÂ¯ğ‘†1ğ‘šsuperscript11ğ‘šğ‘‘{\bar{S}}\in\frac{1}{\sqrt{m}}\{-1,1\}^{m\times d} is a scaled sign matrix (described in Def.Â [2](#Thmtheorem2 "Definition 2. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).
Then for given Î´,Ïµ>0

ğ›¿italic-Ïµ
0\delta,\epsilon>0 there is m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(1/Î´))ğ‘šğ‘‚superscriptitalic-Ïµ21ğ›¿m=O(\epsilon^{-2}\log(1/\delta)) such that for given vector vâˆˆIâ€‹Rdğ‘£superscriptIRğ‘‘v\in\operatorname{{\mathrm{I\!R}}}^{d}, it holds that â€–SÂ¯â€‹vâ€–=â€–vâ€–â€‹(1Â±Ïµ)normÂ¯ğ‘†ğ‘£normğ‘£plus-or-minus1italic-Ïµ\|{\bar{S}}v\|=\|v\|(1\pm\epsilon), with failure probability at most Î´ğ›¿\delta.

###### Remark 30.

We have a similar result for any matrix Pğ‘ƒP with i.i.d. subGaussian entries.

This approximation bound can be easily translated to a bound for multiple differences of vectors.
The proof is simply the application of of LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") to the Oâ€‹(n2)ğ‘‚superscriptğ‘›2O(n^{2}) pairs of differences of vectors of ğ’±ğ’±\mathcal{V}, and a union bound (yielding the logâ¡nğ‘›\log n part of the bound).

###### Corollary (Restatement of Corollary [4](#Thmtheorem4 "Corollary 4. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

If random matrix Pğ‘ƒP satisfies the JL property (LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")),
then for given Î´,Ïµ>0

ğ›¿italic-Ïµ
0\delta,\epsilon>0, and a set ğ’±âŠ‚Iâ€‹Rdğ’±superscriptIRğ‘‘\mathcal{V}\subset\operatorname{{\mathrm{I\!R}}}^{d} of cardinality nğ‘›n,
there is m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(n/Î´))ğ‘šğ‘‚superscriptitalic-Ïµ2ğ‘›ğ›¿m=O(\epsilon^{-2}\log(n/\delta)) such that
with failure probability Î´ğ›¿\delta, for all pairs v,wâˆˆğ’±

ğ‘£ğ‘¤
ğ’±v,w\in\mathcal{V},
â€–Pâ€‹(vâˆ’w)â€–2âˆˆâ€–vâˆ’wâ€–2â€‹(1Â±Ïµ)superscriptnormğ‘ƒğ‘£ğ‘¤2superscriptnormğ‘£ğ‘¤2plus-or-minus1italic-Ïµ\|P(v-w)\|^{2}\in\|v-w\|^{2}(1\pm\epsilon).

In other words, the linear mapping Pğ‘ƒP preserves Euclidean distances up to a multiplicative factor of (1Â±Ïµ)plus-or-minus1italic-Ïµ(1\pm\epsilon).
If vğ‘£v and wğ‘¤w are characteristic vectors for sets Xğ‘‹X and Yğ‘ŒY, then â€–vâˆ’yâ€–2=|Xâ€‹Î”â€‹Y|superscriptnormğ‘£ğ‘¦2ğ‘‹Î”ğ‘Œ\|v-y\|^{2}=|X\Delta Y|, the cardinality of the symmetric difference of Xğ‘‹X and Yğ‘ŒY.
Thus, by taking the difference between their VSA representations Pâ€‹vğ‘ƒğ‘£Pv and Pâ€‹vğ‘ƒğ‘£Pv, we can estimate how much the sets Xğ‘‹X and Yğ‘ŒY disagree, with small *relative* error Ïµitalic-Ïµ\epsilon in that estimate, mild dependence on the number of sets we can represent in this way, and no dependence, in the error, on the groundset size nğ‘›n.

However, this doesnâ€™t say what the needed dimensionality mğ‘šm is, for accurate estimation of the size of the intersection.
We consider this next, using the following standard corollary of LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

###### Corollary (Restatement of Corollary [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Suppose the random matrix Pğ‘ƒP satisfies the JL property (LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).
Then for v,wâˆˆIâ€‹Rd

ğ‘£ğ‘¤
superscriptIRğ‘‘v,w\in\operatorname{{\mathrm{I\!R}}}^{d}, there is m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(1/Î´))ğ‘šğ‘‚superscriptitalic-Ïµ21ğ›¿m=O(\epsilon^{-2}\log(1/\delta)) so that
vâŠ¤â€‹PâŠ¤â€‹Pâ€‹w=vâŠ¤â€‹wÂ±Ïµâ€‹â€–vâ€–â€‹â€–wâ€–superscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤plus-or-minussuperscriptğ‘£topğ‘¤italic-Ïµnormğ‘£normğ‘¤v^{\top}P^{\top}Pw=v^{\top}w\pm\epsilon\|v\|\|w\|
with failure probabilityÂ Î´ğ›¿\delta.

###### Proof.

First, suppose vğ‘£v and wğ‘¤w are unit vectors.
By LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and a union bound, with failure probability at most 3â€‹Î´3ğ›¿3\delta we have
vâŠ¤â€‹PâŠ¤â€‹Pâ€‹v=vâŠ¤â€‹vÂ±Ïµsuperscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘£plus-or-minussuperscriptğ‘£topğ‘£italic-Ïµv^{\top}P^{\top}Pv=v^{\top}v\pm\epsilon,
wâŠ¤â€‹PâŠ¤â€‹Pâ€‹w=wâŠ¤â€‹wÂ±Ïµsuperscriptğ‘¤topsuperscriptğ‘ƒtopğ‘ƒğ‘¤plus-or-minussuperscriptğ‘¤topğ‘¤italic-Ïµw^{\top}P^{\top}Pw=w^{\top}w\pm\epsilon, and
(v+w)âŠ¤â€‹PâŠ¤â€‹Pâ€‹(v+w)=(v+w)âŠ¤â€‹(v+w)Â±2â€‹Ïµsuperscriptğ‘£ğ‘¤topsuperscriptğ‘ƒtopğ‘ƒğ‘£ğ‘¤plus-or-minussuperscriptğ‘£ğ‘¤topğ‘£ğ‘¤2italic-Ïµ(v+w)^{\top}P^{\top}P(v+w)=(v+w)^{\top}(v+w)\pm 2\epsilon.
Since 2â€‹vâŠ¤â€‹w=(v+w)âŠ¤â€‹(v+w)âˆ’vâŠ¤â€‹vâˆ’wâŠ¤â€‹w2superscriptğ‘£topğ‘¤superscriptğ‘£ğ‘¤topğ‘£ğ‘¤superscriptğ‘£topğ‘£superscriptğ‘¤topğ‘¤2v^{\top}w=(v+w)^{\top}(v+w)-v^{\top}v-w^{\top}w and matrix multiplication is an application of a linear operator, an analogous expression holds for vâŠ¤â€‹PâŠ¤â€‹Pâ€‹wsuperscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤v^{\top}P^{\top}Pw.
Then,

|  |  |  |
| --- | --- | --- |
|  | 2â€‹(vâŠ¤â€‹PâŠ¤â€‹Pâ€‹wâˆ’vâŠ¤â€‹w)=Â±ÏµÂ±ÏµÂ±2â€‹Ïµ=Â±4â€‹Ïµ,2superscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤superscriptğ‘£topğ‘¤plus-or-minusplus-or-minusitalic-Ïµitalic-Ïµ2italic-Ïµplus-or-minus4italic-Ïµ2(v^{\top}P^{\top}Pw-v^{\top}w)=\pm\epsilon\pm\epsilon\pm 2\epsilon=\pm 4\epsilon, |  |

with failure probability 3â€‹Î´3ğ›¿3\delta.
If vğ‘£v and wğ‘¤w are not unit vectors,
we apply this reasoning to v/â€–vâ€–ğ‘£normğ‘£v/\|v\| and w/â€–wâ€–ğ‘¤normğ‘¤w/\|w\|, and then multiply through by â€–vâ€–â€‹â€–wâ€–normğ‘£normğ‘¤\|v\|\|w\|, getting vâŠ¤â€‹PâŠ¤â€‹Pâ€‹w=vâŠ¤â€‹wÂ±2â€‹Ïµâ€‹â€–vâ€–â€‹â€–wâ€–superscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤plus-or-minussuperscriptğ‘£topğ‘¤2italic-Ïµnormğ‘£normğ‘¤v^{\top}P^{\top}Pw=v^{\top}w\pm 2\epsilon\|v\|\|w\|.
That is, the conclusion holds with relative error parameter 2â€‹Ïµ2italic-Ïµ2\epsilon and failure probability 3â€‹Î´3ğ›¿3\delta.
We can fold the factors 2 and 3 into the bound for mğ‘šm, and the result follows.
âˆ

Beyond the approximation condition, the proof only depends on Pğ‘ƒP being a linear operator.
Suppose Pğ‘ƒP is a scaled sign matrix SÂ¯Â¯ğ‘†{\bar{S}}, and let v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d} be characteristic vectors.
We want vâŠ¤â€‹PâŠ¤â€‹Pâ€‹w=vâŠ¤â€‹wÂ±Ïµ0superscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤plus-or-minussuperscriptğ‘£topğ‘¤subscriptitalic-Ïµ0v^{\top}P^{\top}Pw=v^{\top}w\pm\epsilon\_{0}, where Ïµ0<1/2subscriptitalic-Ïµ012\epsilon\_{0}<1/2.
Since vâŠ¤â€‹wsuperscriptğ‘£topğ‘¤v^{\top}w is an integer, this assures that vâŠ¤â€‹PâŠ¤â€‹Pâ€‹wsuperscriptğ‘£topsuperscriptğ‘ƒtopğ‘ƒğ‘¤v^{\top}P^{\top}Pw rounds to vâŠ¤â€‹wsuperscriptğ‘£topğ‘¤v^{\top}w.
The next lemma gives conditions on Ïµitalic-Ïµ\epsilon and Î´ğ›¿\delta to attain this.

###### Theorem (Restatement of Theorem [6](#Thmtheorem6 "Theorem 6. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Suppose random matrix Pğ‘ƒP satisfies the JL property (LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).
Given Mğ‘€M pairs of characteristic vectors v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d} such that for every pair v,w

ğ‘£ğ‘¤v,w, â€–vâ€–1â€‹â€–wâ€–1â‰¤Nsubscriptnormğ‘£1subscriptnormğ‘¤1ğ‘\|v\|\_{1}\|w\|\_{1}\leq N, then there is m=Oâ€‹(Nâ€‹logâ¡(M/Î´))ğ‘šğ‘‚ğ‘ğ‘€ğ›¿m=O(N\log(M/\delta)) such that âŒŠvâŠ¤PâŠ¤PwâŒ‰=vâŠ¤w\lfloor v^{\top}P^{\top}Pw\rceil=v^{\top}w for all Mğ‘€M pairs with probability â‰¥1âˆ’Î´absent1ğ›¿\geq 1-\delta.

###### Remark 31.

In particular, this holds for the following special cases.

* â€¢

  Set membership: vğ‘£v is a characteristic vector, and wğ‘¤w is a standard basis vector eisubscriptğ‘’ğ‘–e\_{i} for iâˆˆ[d]ğ‘–delimited-[]ğ‘‘i\in[d].
  Then, N=â€–vâ€–1ğ‘subscriptnormğ‘£1N=\|v\|\_{1}, M=dğ‘€ğ‘‘M=d, and VSA dimension m=O(âˆ¥vâˆ¥1log(d/Î´)m=O(\|v\|\_{1}\log(d/\delta) suffices.
* â€¢

  To get all pairwise intersections among MOâ€‹(1)superscriptğ‘€ğ‘‚1M^{O(1)} vectors vğ‘£v with â€–vâ€–1â‰¤Nsubscriptnormğ‘£1ğ‘\|v\|\_{1}\leq\sqrt{N}, we can use m=Oâ€‹(Nâ€‹logâ¡(M/Î´))ğ‘šğ‘‚ğ‘ğ‘€ğ›¿m=O(N\log(M/\delta)).

###### Proof.

For a given pair of vectors vğ‘£v and wğ‘¤w, by CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") it is enough to choose Ïµ0<1/2subscriptitalic-Ïµ012\epsilon\_{0}<1/2 and Ïµ=Ïµ0/(â€–vâ€–â€‹â€–wâ€–)â‰¥Ïµ0/Nitalic-Ïµsubscriptitalic-Ïµ0normğ‘£normğ‘¤subscriptitalic-Ïµ0ğ‘\epsilon=\epsilon\_{0}/(\|v\|\|w\|)\geq\epsilon\_{0}/\sqrt{N}, to achieve the desired accuracy.

If Î´â€²superscriptğ›¿â€²\delta^{\prime} is the failure probability of CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), then the overall failure probability is at most Mâ€‹Î´â€²ğ‘€superscriptğ›¿â€²M\delta^{\prime}, by a union bound.
Thus for Î´â€²=Î´/Msuperscriptğ›¿â€²ğ›¿ğ‘€\delta^{\prime}=\delta/M and Ïµitalic-Ïµ\epsilon from the JL property equal to Ïµ0/Nsubscriptitalic-Ïµ0ğ‘\epsilon\_{0}/\sqrt{N}, the dimension mğ‘šm of CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") is m=Oâ€‹(Nâ€‹logâ¡(M/Î´))ğ‘šğ‘‚ğ‘ğ‘€ğ›¿m=O(N\log(M/\delta)), and
every dot product estimate is accurate to within additiveÂ Ïµ0subscriptitalic-Ïµ0\epsilon\_{0} with failure probability at mostÂ Î´ğ›¿\delta.
The result follows.
âˆ

##### Angle estimation

Let Î˜v,wsubscriptÎ˜

ğ‘£ğ‘¤\Theta\_{v,w} denote the angle between vectors vğ‘£v and wğ‘¤w.

###### Lemma 32.

Under the conditions of LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), for v,wâˆˆIâ€‹Rd

ğ‘£ğ‘¤
superscriptIRğ‘‘v,w\in\operatorname{{\mathrm{I\!R}}}^{d}, there is m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(1/Î´))ğ‘šğ‘‚superscriptitalic-Ïµ21ğ›¿m=O(\epsilon^{-2}\log(1/\delta)) so that cosâ¡Î˜SÂ¯â€‹v,SÂ¯â€‹w=cosâ¡Î˜v,wÂ±ÏµsubscriptÎ˜

Â¯ğ‘†ğ‘£Â¯ğ‘†ğ‘¤plus-or-minussubscriptÎ˜

ğ‘£ğ‘¤italic-Ïµ\cos\Theta\_{{\bar{S}}v,{\bar{S}}w}=\cos\Theta\_{v,w}\pm\epsilon with failure probabilityÂ Î´ğ›¿\delta.

###### Proof.

This follows from cosâ¡Î˜v,w=vâŠ¤â€‹wâ€–vâ€–â€‹â€–wâ€–subscriptÎ˜

ğ‘£ğ‘¤superscriptğ‘£topğ‘¤normğ‘£normğ‘¤\cos\Theta\_{v,w}=\frac{v^{\top}w}{\|v\|\|w\|}, and similarly for Î˜SÂ¯â€‹v,SÂ¯â€‹wsubscriptÎ˜

Â¯ğ‘†ğ‘£Â¯ğ‘†ğ‘¤\Theta\_{{\bar{S}}v,{\bar{S}}w}; applying CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") to the estimation of vâŠ¤â€‹wsuperscriptğ‘£topğ‘¤v^{\top}w, â€–vâ€–normğ‘£\|v\|, and â€–wâ€–normğ‘¤\|w\|, and finally folding constant-factor increases inÂ Ïµitalic-Ïµ\epsilon and Î´ğ›¿\delta intoÂ mğ‘šm.
âˆ

#### 4.1.1 Variations Using Alternative Sketching Matrices

##### Using sparse JL

The sparse JL transform has Ïµâ€‹mitalic-Ïµğ‘š\epsilon m nonzero entries per column of Pğ‘ƒP, each entry an independent sign (that is, Â±1plus-or-minus1\pm 1). Such a matrix, multiplied by a scaling factor, also satisfies LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), as shown in [kane2014sparser, cohen2018simple], and therefore could be used in VSAs with the same performance, at least as far as bundling goes.
However, element-wise product does not seem to be enough to do binding effectively for such a representation, as the element-wise product of sparse vectors is likely to be all zeros.

##### Using Subsampled Randomized Hadamard Transform (SRHT)

The SRHT, described in [boutsidis2013improved], is multiplication by a matrix Zâ€‹Hâ€‹Dğ‘ğ»ğ·ZHD, where Dğ·D is a random sign diagonal matrix (random sign flips on the diagonal), Hğ»H is a Hadamard matrix (an orthogonal sign matrix), and Zğ‘Z simply selects a uniform random subset of the rows (a diagonal binary matrix).
This operation, along with a scaling factor, is shown by [krahmer2011new] to satisfy the conditions of LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), up to needing the larger target dimension m=Oâ€‹(Ïµâˆ’2â€‹logâ¡(1/Î´)â€‹log4â¡d)ğ‘šğ‘‚superscriptitalic-Ïµ21ğ›¿superscript4ğ‘‘m=O(\epsilon^{-2}\log(1/\delta)\log^{4}d), that is, with an additional factor of log4â¡dsuperscript4ğ‘‘\log^{4}d.
While for many applications, a useful property of SRHT is that Zâ€‹Hâ€‹Dâ€‹vğ‘ğ»ğ·ğ‘£ZHDv is rapidly computed, here the main attraction is that the generation or storage of random sign values is greatly reduced; entries of the Hğ»H matrix are readily computed using bitwise operations on the entry indices.

### 4.2 Rotations for Encoding Sequences

For scaled sign matrices, using a rotation (i.e. a permutation that is a single large cycle), we can store length-Lğ¿L sequences of vectors with an error bound that grows quadratically with Lğ¿L.
It is possible that there is a better general bound than this; we found better performance in a special case.
If the vectors are, in particular, characteristic vectors, so that a sequence of symbols is being stored (and not e.g. a sequence of embeddings), then better error behavior (that depends on how much the vectors overlap, rather than naively on Lğ¿L) typically occurs.

Before further definition and analysis, we have some lemmas useful for the analysis.

###### Lemma 33.

Say we sample independent scaled random sign matrices P1,P2âˆˆ{Â±1}mÃ—d

subscriptğ‘ƒ1subscriptğ‘ƒ2
superscriptplus-or-minus1ğ‘šğ‘‘P\_{1},P\_{2}\in\{\pm 1\}^{m\times d} with mğ‘šm large enough to satisfy the JL property, i.e. for given vâˆˆIâ€‹Rdğ‘£superscriptIRğ‘‘v\in\operatorname{{\mathrm{I\!R}}}^{d}, with failure probability Î´ğ›¿\delta, it holds that â€–Piâ€‹xâ€–2=(1Â±Ïµ)â€‹â€–xâ€–2superscriptnormsubscriptğ‘ƒğ‘–ğ‘¥2plus-or-minus1italic-Ïµsuperscriptnormğ‘¥2\|P\_{i}x\|^{2}=(1\pm\epsilon)\|x\|^{2}.
If the block matrix [P1â€‹P2]delimited-[]subscriptğ‘ƒ1subscriptğ‘ƒ2[P\_{1}\,P\_{2}] also satisfies the JL property, then for given unit vectors x1,x2âˆˆIâ€‹Rd

subscriptğ‘¥1subscriptğ‘¥2
superscriptIRğ‘‘x\_{1},x\_{2}\in\operatorname{{\mathrm{I\!R}}}^{d}, with failure probability at most 3â€‹Î´3ğ›¿3\delta,
|x1âŠ¤â€‹P1âŠ¤â€‹P2â€‹x2|â‰¤2â€‹Ïµsuperscriptsubscriptğ‘¥1topsuperscriptsubscriptğ‘ƒ1topsubscriptğ‘ƒ2subscriptğ‘¥22italic-Ïµ|x\_{1}^{\top}P\_{1}^{\top}P\_{2}x\_{2}|\leq 2\epsilon.

###### Proof.

Since P1subscriptğ‘ƒ1P\_{1} and P2subscriptğ‘ƒ2P\_{2} were sampled independently, the block matrix [P1â€‹P2]delimited-[]subscriptğ‘ƒ1subscriptğ‘ƒ2[P\_{1}\,P\_{2}] itself is a larger random sign matrix, and it satisfies the JL property for Îµğœ€\varepsilon with probability â‰¤Î´absentğ›¿\leq\delta.
We have

|  |  |  |
| --- | --- | --- |
|  | â€–P1â€‹x1+P2â€‹x2â€–2=â€–[P1â€‹P2]â€‹[x1x2]â€–2=(â€–x1â€–2+â€–x2â€–2)â€‹(1Â±Ïµ)=2â€‹(1Â±Ïµ)superscriptnormsubscriptğ‘ƒ1subscriptğ‘¥1subscriptğ‘ƒ2subscriptğ‘¥22superscriptnormdelimited-[]subscriptğ‘ƒ1subscriptğ‘ƒ2delimited-[]matrixsubscriptğ‘¥1subscriptğ‘¥22superscriptnormsubscriptğ‘¥12superscriptnormsubscriptğ‘¥22plus-or-minus1italic-Ïµ2plus-or-minus1italic-Ïµ\|P\_{1}x\_{1}+P\_{2}x\_{2}\|^{2}=\|[P\_{1}\,P\_{2}]\left[\begin{matrix}x\_{1}\\ x\_{2}\end{matrix}\right]\|^{2}=(\|x\_{1}\|^{2}+\|x\_{2}\|^{2})(1\pm\epsilon)=2(1\pm\epsilon) |  |

with failure probability Î´ğ›¿\delta, since [P1â€‹P2]delimited-[]subscriptğ‘ƒ1subscriptğ‘ƒ2[P\_{1}\,P\_{2}] satisfies the same conditions as P1,P2

subscriptğ‘ƒ1subscriptğ‘ƒ2P\_{1},P\_{2}.
With failure probability at most 3â€‹Î´3ğ›¿3\delta, the embedding conditions hold for [P1â€‹P2]delimited-[]subscriptğ‘ƒ1subscriptğ‘ƒ2[P\_{1}\,P\_{2}], P1subscriptğ‘ƒ1P\_{1}, and P2subscriptğ‘ƒ2P\_{2}.
Assuming they do,

|  |  |  |  |
| --- | --- | --- | --- |
|  | |x1âŠ¤â€‹P1âŠ¤â€‹P2â€‹x2|superscriptsubscriptğ‘¥1topsuperscriptsubscriptğ‘ƒ1topsubscriptğ‘ƒ2subscriptğ‘¥2\displaystyle|x\_{1}^{\top}P\_{1}^{\top}P\_{2}x\_{2}| | =|12â€‹[â€–P1â€‹x1+P2â€‹x2â€–2âˆ’â€–P1â€‹x1â€–2âˆ’â€–P2â€‹x2â€–2]|absent12delimited-[]superscriptnormsubscriptğ‘ƒ1subscriptğ‘¥1subscriptğ‘ƒ2subscriptğ‘¥22superscriptnormsubscriptğ‘ƒ1subscriptğ‘¥12superscriptnormsubscriptğ‘ƒ2subscriptğ‘¥22\displaystyle=\left|\frac{1}{2}\left[\|P\_{1}x\_{1}+P\_{2}x\_{2}\|^{2}-\|P\_{1}x\_{1}\|^{2}-\|P\_{2}x\_{2}\|^{2}\right]\right| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤12â€‹[2â€‹(1+Ïµ)âˆ’(1âˆ’Ïµ)âˆ’(1âˆ’Ïµ)]â‰¤2â€‹Ïµ.absent12delimited-[]21italic-Ïµ1italic-Ïµ1italic-Ïµ2italic-Ïµ\displaystyle\leq\frac{1}{2}\left[2(1+\epsilon)-(1-\epsilon)-(1-\epsilon)\right]\leq 2\epsilon. |  |

The result follows.
âˆ

###### Lemma 34.

Let RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m} denote a rotation matrix, as in Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Let SÂ¯âˆˆIâ€‹RmÃ—dÂ¯ğ‘†superscriptIRğ‘šğ‘‘{\bar{S}}\in\operatorname{{\mathrm{I\!R}}}^{m\times d} be a scaled sign matrix such that for given xâˆˆIâ€‹Rdğ‘¥superscriptIRğ‘‘x\in\operatorname{{\mathrm{I\!R}}}^{d}, â€–SÂ¯â€‹xâ€–2=â€–xâ€–2â€‹(1Â±Ïµ)superscriptnormÂ¯ğ‘†ğ‘¥2superscriptnormğ‘¥2plus-or-minus1italic-Ïµ\|{\bar{S}}x\|^{2}=\|x\|^{2}(1\pm\epsilon) with failure probability Î´ğ›¿\delta.
Then for unit vectors x,yâˆˆIâ€‹Rd

ğ‘¥ğ‘¦
superscriptIRğ‘‘x,y\in\operatorname{{\mathrm{I\!R}}}^{d} and râ‰¤m/2ğ‘Ÿğ‘š2r\leq m/2, we have |xâŠ¤â€‹SÂ¯âŠ¤â€‹Rrâ€‹SÂ¯â€‹y|â‰¤4â€‹Ïµsuperscriptğ‘¥topsuperscriptÂ¯ğ‘†topsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†ğ‘¦4italic-Ïµ|x^{\top}{\bar{S}}^{\top}R^{r}{\bar{S}}y|\leq 4\epsilon,
with failure probability 6â€‹Î´6ğ›¿6\delta.
If xğ‘¥x and yğ‘¦y are not unit vectors, then |xâŠ¤â€‹SÂ¯âŠ¤â€‹Rrâ€‹SÂ¯â€‹y|â‰¤4â€‹Ïµâ€‹â€–xâ€–â€‹â€–yâ€–superscriptğ‘¥topsuperscriptÂ¯ğ‘†topsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†ğ‘¦4italic-Ïµnormğ‘¥normğ‘¦|x^{\top}{\bar{S}}^{\top}R^{r}{\bar{S}}y|\leq 4\epsilon\|x\|\|y\|.

###### Proof.

We have (Rrâ€‹SÂ¯)iâ£âˆ—=SÂ¯[(i+râˆ’1)%â€‹m+1]â£âˆ—subscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†

ğ‘–subscriptÂ¯ğ‘†

delimited-[]percentğ‘–ğ‘Ÿ1ğ‘š1(R^{r}{\bar{S}})\_{i\*}={\bar{S}}\_{[(i+r-1)\%m+1]\*}, where j%â€‹mpercentğ‘—ğ‘šj\%m denotes jğ‘—j modulo mğ‘šm.
Consider the division of the rows of SÂ¯Â¯ğ‘†{\bar{S}} and of Rrâ€‹SÂ¯superscriptğ‘…ğ‘ŸÂ¯ğ‘†R^{r}{\bar{S}} into blocks of sizeÂ rğ‘Ÿr.
The first rğ‘Ÿr rows of SÂ¯Â¯ğ‘†{\bar{S}} and the first rğ‘Ÿr rows of Rrâ€‹SÂ¯superscriptğ‘…ğ‘ŸÂ¯ğ‘†R^{r}{\bar{S}} comprise together the first and second blocks of SÂ¯Â¯ğ‘†{\bar{S}},
since {(i+râˆ’1)%â€‹m+1|iâˆˆ[r]}={1+r,2+r,â€¦,r+r}conditional-setpercentğ‘–ğ‘Ÿ1ğ‘š1ğ‘–delimited-[]ğ‘Ÿ1ğ‘Ÿ2ğ‘Ÿâ€¦ğ‘Ÿğ‘Ÿ\{(i+r-1)\%m+1|i\in[r]\}=\{1+r,2+r,\ldots,r+r\}.
The second block of rğ‘Ÿr rows of SÂ¯Â¯ğ‘†{\bar{S}} and of Rrâ€‹SÂ¯superscriptğ‘…ğ‘ŸÂ¯ğ‘†R^{r}{\bar{S}} comprise together the second and third block of rows of SÂ¯Â¯ğ‘†{\bar{S}},
and so on.

As a consequence, SÂ¯Â¯ğ‘†{\bar{S}} and Rrâ€‹SÂ¯superscriptğ‘…ğ‘ŸÂ¯ğ‘†R^{r}{\bar{S}} can each be split into two matrices SÂ¯1,SÂ¯2

subscriptÂ¯ğ‘†1subscriptÂ¯ğ‘†2{\bar{S}}\_{1},{\bar{S}}\_{2} and (Rrâ€‹SÂ¯)1,(Rrâ€‹SÂ¯)2

subscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†1subscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†2(R^{r}{\bar{S}})\_{1},(R^{r}{\bar{S}})\_{2}, where SÂ¯1subscriptÂ¯ğ‘†1{\bar{S}}\_{1} comprises the odd-numbered blocks of SÂ¯Â¯ğ‘†{\bar{S}}, and (Rrâ€‹SÂ¯)1subscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†1(R^{r}{\bar{S}})\_{1} comprises the corresponding blocks of Rrâ€‹SÂ¯superscriptğ‘…ğ‘ŸÂ¯ğ‘†R^{r}{\bar{S}}, such that the rows of SÂ¯1subscriptÂ¯ğ‘†1{\bar{S}}\_{1} and the rows of (Rrâ€‹SÂ¯)1subscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†1(R^{r}{\bar{S}})\_{1} are chosen from disjoint sets of rows of SÂ¯Â¯ğ‘†{\bar{S}}, and similarly for SÂ¯2subscriptÂ¯ğ‘†2{\bar{S}}\_{2} comprising the even-numbered blocks of SÂ¯Â¯ğ‘†{\bar{S}}, and (Rrâ€‹SÂ¯)2subscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†2(R^{r}{\bar{S}})\_{2} comprising the corresponding blocks of Rrâ€‹SÂ¯superscriptğ‘…ğ‘ŸÂ¯ğ‘†R^{r}{\bar{S}}.
That is, splitting the entries of xğ‘¥x and yğ‘¦y in the same way into vectors x1,x2,y1,y2

subscriptğ‘¥1subscriptğ‘¥2subscriptğ‘¦1subscriptğ‘¦2x\_{1},x\_{2},y\_{1},y\_{2}, we have that

|  |  |  |
| --- | --- | --- |
|  | xâŠ¤â€‹SÂ¯âŠ¤â€‹Rrâ€‹SÂ¯â€‹y=x1âŠ¤â€‹SÂ¯1âŠ¤â€‹(Rrâ€‹SÂ¯)1â€‹y1+x2âŠ¤â€‹SÂ¯2âŠ¤â€‹(Rrâ€‹SÂ¯)2â€‹y2.superscriptğ‘¥topsuperscriptÂ¯ğ‘†topsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†ğ‘¦superscriptsubscriptğ‘¥1topsuperscriptsubscriptÂ¯ğ‘†1topsubscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†1subscriptğ‘¦1superscriptsubscriptğ‘¥2topsuperscriptsubscriptÂ¯ğ‘†2topsubscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†2subscriptğ‘¦2x^{\top}{\bar{S}}^{\top}R^{r}{\bar{S}}y=x\_{1}^{\top}{\bar{S}}\_{1}^{\top}(R^{r}{\bar{S}})\_{1}y\_{1}+x\_{2}^{\top}{\bar{S}}\_{2}^{\top}(R^{r}{\bar{S}})\_{2}y\_{2}. |  |

Since the entries of SÂ¯1subscriptÂ¯ğ‘†1{\bar{S}}\_{1} were chosen independently from those of (Rrâ€‹SÂ¯)1subscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†1(R^{r}{\bar{S}})\_{1}, we can apply Lemma [33](#Thmtheorem33 "Lemma 33. â€£ 4.2 Rotations for Encoding Sequences â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures") to have that |x1âŠ¤â€‹SÂ¯1âŠ¤â€‹(Rrâ€‹SÂ¯)1â€‹y1|â‰¤2â€‹Ïµsuperscriptsubscriptğ‘¥1topsuperscriptsubscriptÂ¯ğ‘†1topsubscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†1subscriptğ‘¦12italic-Ïµ|x\_{1}^{\top}{\bar{S}}\_{1}^{\top}(R^{r}{\bar{S}})\_{1}y\_{1}|\leq 2\epsilon, with failure probability Câ€‹Î´ğ¶ğ›¿C\delta, with a similar statement for
x2âŠ¤â€‹SÂ¯2âŠ¤â€‹(Rrâ€‹SÂ¯)2â€‹y2superscriptsubscriptğ‘¥2topsuperscriptsubscriptÂ¯ğ‘†2topsubscriptsuperscriptğ‘…ğ‘ŸÂ¯ğ‘†2subscriptğ‘¦2x\_{2}^{\top}{\bar{S}}\_{2}^{\top}(R^{r}{\bar{S}})\_{2}y\_{2}. Adding these bounds, and taking a union bound on the failure probability, yields the result for unit vectors. The claim about non-unit vectors follows immediately.
âˆ

###### Definition 35.

For vâˆˆIâ€‹RLâ€‹dğ‘£superscriptIRğ¿ğ‘‘v\in\operatorname{{\mathrm{I\!R}}}^{Ld} encoding a sequence v(0),v(1),â€¦â€‹v(Lâˆ’1)âˆˆâ„d

subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1
superscriptâ„ğ‘‘v\_{(0)},v\_{(1)},\ldots v\_{(L-1)}\in\mathbb{R}^{d}, as in Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), define

|  |  |  |
| --- | --- | --- |
|  | â€–vâ€–L,1â‰¡âˆ‘0â‰¤j<Lâ€–v(j)â€–subscriptnormğ‘£  ğ¿1subscript0ğ‘—ğ¿normsubscriptğ‘£ğ‘—\|v\|\_{L,1}\equiv\sum\_{0\leq j<L}\|v\_{(j)}\| |  |

###### Theorem (Restatement of Theorem [9](#Thmtheorem9 "Theorem 9. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Given scaled sign matrix SÂ¯âˆˆIâ€‹RmÃ—dÂ¯ğ‘†superscriptIRğ‘šğ‘‘{\bar{S}}\in\operatorname{{\mathrm{I\!R}}}^{m\times d}, rotation matrix RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m} as in Def.Â [7](#Thmtheorem7 "Definition 7. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), integer L>0ğ¿0L>0, and SÂ¯R,LsubscriptÂ¯ğ‘†

ğ‘…ğ¿{\bar{S}}\_{R,L} as in Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Then for vâˆˆIâ€‹RLâ€‹dğ‘£superscriptIRğ¿ğ‘‘v\in\operatorname{{\mathrm{I\!R}}}^{Ld} as defined above,

|  |  |  |
| --- | --- | --- |
|  | |â€–SÂ¯R,Lâ€‹vâ€–2âˆ’â€–vâ€–2|â‰¤3â€‹Ïµâ€‹â€–vâ€–L,12â‰¤3â€‹Lâ€‹Ïµâ€‹â€–vâ€–2,superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2superscriptnormğ‘£23italic-Ïµsuperscriptsubscriptnormğ‘£  ğ¿123ğ¿italic-Ïµsuperscriptnormğ‘£2|\|{\bar{S}}\_{R,L}v\|^{2}-\|v\|^{2}|\leq 3\epsilon\|v\|\_{L,1}^{2}\leq 3L\epsilon\|v\|^{2}, |  |

with failure probability 6â€‹L2â€‹Î´6superscriptğ¿2ğ›¿6L^{2}\delta.
It follows that there is m=Oâ€‹((L/Îµ)2â€‹logâ¡(L/Î´))ğ‘šğ‘‚superscriptğ¿ğœ€2ğ¿ğ›¿m=O((L/{\varepsilon})^{2}\log(L/\delta)) such that with failure probability at most Î´ğ›¿\delta,
â€–SÂ¯R,Lâ€‹vâ€–2=(1Â±Îµ)â€‹â€–vâ€–2superscriptnormsubscriptÂ¯ğ‘†

ğ‘…ğ¿ğ‘£2plus-or-minus1ğœ€superscriptnormğ‘£2\|{\bar{S}}\_{R,L}v\|^{2}=(1\pm{\varepsilon})\|v\|^{2}.

Note that bounds for set difference and intersection follow by slight variation of CorollariesÂ [4](#Thmtheorem4 "Corollary 4. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), and sharper ones using â€–vâ€–L,1subscriptnormğ‘£

ğ¿1\|v\|\_{L,1} instead of â€–vâ€–normğ‘£\|v\|.

###### Proof.

Recall that RâŠ¤â€‹R=Isuperscriptğ‘…topğ‘…ğ¼R^{\top}R=I and RâŠ¤=Râˆ’1superscriptğ‘…topsuperscriptğ‘…1R^{\top}=R^{-1}.
Assuming the approximation bounds of LemmaÂ [34](#Thmtheorem34 "Lemma 34. â€£ 4.2 Rotations for Encoding Sequences â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures") hold for several instances, we have that

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–SÂ¯R,Lâ€‹vâ€–2superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2\displaystyle\|{\bar{S}}\_{R,L}v\|^{2} | =â€–âˆ‘0â‰¤j<LRjâ€‹SÂ¯â€‹v(j)â€–2absentsuperscriptnormsubscript0ğ‘—ğ¿superscriptğ‘…ğ‘—Â¯ğ‘†subscriptğ‘£ğ‘—2\displaystyle=\|\sum\_{0\leq j<L}R^{j}{\bar{S}}v\_{(j)}\|^{2} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ‘0â‰¤j,jâ€²<Lv(jâ€²)âŠ¤â€‹SÂ¯âŠ¤â€‹(RâŠ¤)jâ€²â€‹Rjâ€‹SÂ¯â€‹v(j)absentsubscriptformulae-sequence0ğ‘—superscriptğ‘—â€²ğ¿superscriptsubscriptğ‘£superscriptğ‘—â€²topsuperscriptÂ¯ğ‘†topsuperscriptsuperscriptğ‘…topsuperscriptğ‘—â€²superscriptğ‘…ğ‘—Â¯ğ‘†subscriptğ‘£ğ‘—\displaystyle=\sum\_{0\leq j,j^{\prime}<L}v\_{(j^{\prime})}^{\top}{\bar{S}}^{\top}(R^{\top})^{j^{\prime}}R^{j}{\bar{S}}v\_{(j)} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ‘0â‰¤j<Lv(j)âŠ¤â€‹SÂ¯âŠ¤â€‹SÂ¯â€‹v(j)+2â€‹âˆ‘0â‰¤jâ€²<j<Lv(jâ€²)âŠ¤â€‹SÂ¯âŠ¤â€‹Rjâˆ’jâ€²â€‹SÂ¯â€‹v(j)absentsubscript0ğ‘—ğ¿superscriptsubscriptğ‘£ğ‘—topsuperscriptÂ¯ğ‘†topÂ¯ğ‘†subscriptğ‘£ğ‘—2subscript0superscriptğ‘—â€²ğ‘—ğ¿superscriptsubscriptğ‘£superscriptğ‘—â€²topsuperscriptÂ¯ğ‘†topsuperscriptğ‘…ğ‘—superscriptğ‘—â€²Â¯ğ‘†subscriptğ‘£ğ‘—\displaystyle=\sum\_{0\leq j<L}v\_{(j)}^{\top}{\bar{S}}^{\top}{\bar{S}}v\_{(j)}+2\sum\_{0\leq j^{\prime}<j<L}v\_{(j^{\prime})}^{\top}{\bar{S}}^{\top}R^{j-j^{\prime}}{\bar{S}}v\_{(j)} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤â€–vâ€–2â€‹(1Â±Ïµ)+2â€‹âˆ‘0â‰¤jâ€²<j<LÏµâ€‹â€–v(jâ€²)â€–âˆ—â€–v(j)â€–absentsuperscriptnormğ‘£2plus-or-minus1italic-Ïµ2subscript0superscriptğ‘—â€²ğ‘—ğ¿italic-Ïµnormsubscriptğ‘£superscriptğ‘—â€²normsubscriptğ‘£ğ‘—\displaystyle\leq\|v\|^{2}(1\pm\epsilon)+2\sum\_{0\leq j^{\prime}<j<L}\epsilon\|v\_{(j^{\prime})}\|\*\|v\_{(j)}\| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤â€–vâ€–2+3â€‹Ïµâ€‹(âˆ‘0â‰¤j<Lâ€–v(j)â€–)2,absentsuperscriptnormğ‘£23italic-Ïµsuperscriptsubscript0ğ‘—ğ¿normsubscriptğ‘£ğ‘—2\displaystyle\leq\|v\|^{2}+3\epsilon\left(\sum\_{0\leq j<L}\|v\_{(j)}\|\right)^{2}, |  |

as claimed.
Here we use that for vector zâˆˆIâ€‹RLğ‘§superscriptIRğ¿z\in\operatorname{{\mathrm{I\!R}}}^{L}, â€–zâ€–2â‰¤â€–zâ€–1â‰¤â€–zâ€–2â€‹Lsubscriptnormğ‘§2subscriptnormğ‘§1subscriptnormğ‘§2ğ¿\|z\|\_{2}\leq\|z\|\_{1}\leq\|z\|\_{2}\sqrt{L}.
This also implies the last inequality of the theorem statement.
The failure probabilities of CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") for the diagonal terms, and LemmaÂ [34](#Thmtheorem34 "Lemma 34. â€£ 4.2 Rotations for Encoding Sequences â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures") for the off-diagonal terms, imply the overall bound via a union bound.
The last line follows using LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
âˆ

#### 4.2.1 Tighter Bounds for Characteristic Vectors

The above theorem applies to any sequence of vectors, but better bounds are obtainable for characteristic vectors, in some cases: consider vğ‘£v and wğ‘¤w the characteristic vectors of distinct symbols.
Then SÂ¯â€‹vÂ¯ğ‘†ğ‘£{\bar{S}}v and Râ€‹SÂ¯â€‹wğ‘…Â¯ğ‘†ğ‘¤R{\bar{S}}w are entry-wise independent, because vğ‘£v and wğ‘¤w select different columns of SÂ¯Â¯ğ‘†{\bar{S}}, and the rotation Râ€‹SÂ¯ğ‘…Â¯ğ‘†R{\bar{S}} doesnâ€™t change this.
Next we apply this idea more generally.

###### Theorem (Restatement of Theorem [10](#Thmtheorem10 "Theorem 10. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Given scaled sign matrix SÂ¯âˆˆIâ€‹RmÃ—dÂ¯ğ‘†superscriptIRğ‘šğ‘‘{\bar{S}}\in\operatorname{{\mathrm{I\!R}}}^{m\times d}, rotation matrix RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m} (Def.Â [7](#Thmtheorem7 "Definition 7. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")), integer L>0ğ¿0L>0, and SÂ¯R,LsubscriptÂ¯ğ‘†

ğ‘…ğ¿{\bar{S}}\_{R,L} as in Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
For a sequence of vectors v(0),v(1),â€¦â€‹v(Lâˆ’1)âˆˆ{0,1}d

subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1
superscript01ğ‘‘v\_{(0)},v\_{(1)},\ldots v\_{(L-1)}\in\{0,1\}^{d}, let
Kâ‰¡â€–âˆ‘0â‰¤j<Lv(j)â€–âˆğ¾subscriptnormsubscript0ğ‘—ğ¿subscriptğ‘£ğ‘—K\equiv\|\sum\_{0\leq j<L}v\_{(j)}\|\_{\infty}.
There is m=Oâ€‹(K2â€‹Îµâˆ’2â€‹logâ¡(K/(Îµâ€‹Î´)))ğ‘šğ‘‚superscriptğ¾2superscriptğœ€2ğ¾ğœ€ğ›¿m=O\left(K^{2}{\varepsilon}^{-2}\log(K/({\varepsilon}\delta))\right) such that with failure probabilityÂ Î´ğ›¿\delta,

|  |  |  |
| --- | --- | --- |
|  | |â€–SÂ¯R,Lâ€‹vâ€–2âˆ’â€–vâ€–2|â‰¤Ïµâ€‹â€–vâ€–2superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2superscriptnormğ‘£2italic-Ïµsuperscriptnormğ‘£2|\|{\bar{S}}\_{R,L}v\|^{2}-\|v\|^{2}|\leq\epsilon\|v\|^{2} |  |

Note that here, each v(j)subscriptğ‘£ğ‘—v\_{(j)} is the characteristic vector of a collection of symbols, and Kğ¾K is the maximum number of times that some symbol is represented, adding up appearances over the given vectors.
Bounds for set difference and intersection follow by slight variation of CorollariesÂ [4](#Thmtheorem4 "Corollary 4. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

###### Proof.

Our proof of this lemma uses a corollary of McDiarmidâ€™s Inequality (Theorem [25](#Thmtheorem25 "Theorem 25. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")).
The product SÂ¯R,Lâ€‹vsubscriptÂ¯ğ‘†

ğ‘…ğ¿ğ‘£{\bar{S}}\_{R,L}v is a sum of vectors of the form Rjâ€‹SÂ¯âˆ—isuperscriptğ‘…ğ‘—subscriptÂ¯ğ‘†absentğ‘–R^{j}{\bar{S}}\_{\*i}, for entries iğ‘–i of v(j)subscriptğ‘£ğ‘—v\_{(j)} equal to one.
Recall that v(j)âˆˆâ„dsubscriptğ‘£ğ‘—superscriptâ„ğ‘‘v\_{(j)}\in{\mathbb{R}}^{d} is the jğ‘—j-th block of vğ‘£v, and that we defined K=â€–âˆ‘0â‰¤j<Lv(j)â€–âˆğ¾subscriptnormsubscript0ğ‘—ğ¿subscriptğ‘£ğ‘—K=\|\sum\_{0\leq j<L}v\_{(j)}\|\_{\infty}.
We can decompose vğ‘£v into a sum v=âˆ‘kâˆˆ[K]xkğ‘£subscriptğ‘˜delimited-[]ğ¾superscriptğ‘¥ğ‘˜v=\sum\_{k\in[K]}x^{k}, where each xkâˆˆ{0,1}Lâ€‹dsuperscriptğ‘¥ğ‘˜superscript01ğ¿ğ‘‘x^{k}\in\{0,1\}^{Ld}, such that no j,jâ€²âˆˆsuppâ¡(xk)

ğ‘—superscriptğ‘—â€²
suppsuperscriptğ‘¥ğ‘˜j,j^{\prime}\in\operatorname{{\text{supp}}}(x^{k}) has jmodd=jâ€²moddmoduloğ‘—ğ‘‘modulosuperscriptğ‘—â€²ğ‘‘j\mod d=j^{\prime}\mod d.
For each kâˆˆKğ‘˜ğ¾k\in K, the vector mâ€‹SÂ¯R,Lâ€‹xkğ‘šsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜\sqrt{m}{\bar{S}}\_{R,L}x^{k} is a sum of independent sign vectors, since each entry of 111 in xksuperscriptğ‘¥ğ‘˜x^{k} will select a different column of SÂ¯Â¯ğ‘†{\bar{S}},

and so LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") applies, and
â€–SÂ¯R,Lâ€‹xkâ€–2=(1Â±Ïµ)â€‹â€–xkâ€–2superscriptnormsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜2plus-or-minus1italic-Ïµsuperscriptnormsuperscriptğ‘¥ğ‘˜2\|{\bar{S}}\_{R,L}x^{k}\|^{2}=(1\pm\epsilon)\|x^{k}\|^{2} with failure probabilityÂ Î´ğ›¿\delta.

We will show next for k,kâ€²âˆˆ[K]

ğ‘˜superscriptğ‘˜â€²
delimited-[]ğ¾k,k^{\prime}\in[K] with kâ‰ kâ€²ğ‘˜superscriptğ‘˜â€²k\neq k^{\prime}, that Dk,kâ€²â‰¡xkâ€²âŠ¤â€‹SÂ¯R,LâŠ¤â€‹SÂ¯R,Lâ€‹xksubscriptğ·

ğ‘˜superscriptğ‘˜â€²superscriptğ‘¥limit-fromsuperscriptğ‘˜â€²topsuperscriptsubscriptÂ¯ğ‘†

ğ‘…ğ¿topsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜D\_{k,k^{\prime}}\equiv x^{k^{\prime}\,\top}{\bar{S}}\_{R,L}^{\top}{\bar{S}}\_{R,L}x^{k} concentrates around its expectation xkâ€²âŠ¤â€‹xksuperscriptğ‘¥limit-fromsuperscriptğ‘˜â€²topsuperscriptğ‘¥ğ‘˜x^{k^{\prime}\,\top}x^{k}.
To do this, we will apply McDiarmidâ€™s Inequality, (CorollaryÂ [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")).
First, we note that each entry (SÂ¯R,Lâ€‹xk)isubscriptsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜ğ‘–({\bar{S}}\_{R,L}x^{k})\_{i} is a sum of independent Rademacher values, scaled by 1/m1ğ‘š1/\sqrt{m}, and so by TheoremÂ [29](#Thmtheorem29 "Theorem 29. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") its square is at most 1mâ€‹â€–xkâ€–2â€‹logâ¡(2/Î´1)1ğ‘šsuperscriptnormsuperscriptğ‘¥ğ‘˜22subscriptğ›¿1\frac{1}{m}\|x^{k}\|^{2}\log(2/\delta\_{1}) with failure probability Î´1subscriptğ›¿1\delta\_{1}, for Î´1subscriptğ›¿1\delta\_{1} to be determined.

Let â„°â„°\cal E be the event that all entries of SÂ¯R,Lâ€‹xksubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜{\bar{S}}\_{R,L}x^{k} and SÂ¯R,Lâ€‹xkâ€²subscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥superscriptğ‘˜â€²{\bar{S}}\_{R,L}x^{k^{\prime}} satisfy this bound; this holds with failure probability at most 2â€‹Î´1â€‹m2subscriptğ›¿1ğ‘š2\delta\_{1}m.
To apply TheoremÂ [25](#Thmtheorem25 "Theorem 25. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), we need to bound, for each entry of SÂ¯Â¯ğ‘†{\bar{S}}, the change in Dk,kâ€²subscriptğ·

ğ‘˜superscriptğ‘˜â€²D\_{k,k^{\prime}} that can occur when the entry takes one of its values +11+1 orÂ âˆ’11-1.
Due to the construction of xksuperscriptğ‘¥ğ‘˜x^{k} and xkâ€²superscriptğ‘¥superscriptğ‘˜â€²x^{k^{\prime}}, the entry affects only at most one entry (SÂ¯R,Lâ€‹xk)isubscriptsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜ğ‘–({\bar{S}}\_{R,L}x^{k})\_{i} and at most one entry (SÂ¯R,Lâ€‹xkâ€²)iâ€²subscriptsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥superscriptğ‘˜â€²superscriptğ‘–â€²({\bar{S}}\_{R,L}x^{k^{\prime}})\_{i^{\prime}}.

The difference in Dk,kâ€²subscriptğ·

ğ‘˜superscriptğ‘˜â€²D\_{k,k^{\prime}} due to a change in an entry of SÂ¯Â¯ğ‘†{\bar{S}} contributing to (SÂ¯R,Lâ€‹xk)isubscriptsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜ğ‘–({\bar{S}}\_{R,L}x^{k})\_{i} is at most 2mâ€‹(SÂ¯R,Lâ€‹xkâ€²)i2ğ‘šsubscriptsubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥superscriptğ‘˜â€²ğ‘–\frac{2}{\sqrt{m}}({\bar{S}}\_{R,L}x^{k^{\prime}})\_{i}; if event â„°â„°\cal E holds, its square is at most
4m2â€‹â€–xkâ€²â€–2â€‹logâ¡(2/Î´1)4superscriptğ‘š2superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²22subscriptğ›¿1\frac{4}{m^{2}}\|x^{k^{\prime}}\|^{2}\log(2/\delta\_{1}).
Similarly, the difference due to a change in an entry contributing to SÂ¯R,Lâ€‹xikâ€²subscriptÂ¯ğ‘†

ğ‘…ğ¿subscriptsuperscriptğ‘¥superscriptğ‘˜â€²ğ‘–{\bar{S}}\_{R,L}x^{k^{\prime}}\_{i} is at most 4m2â€‹â€–xkâ€–2â€‹logâ¡(2/Î´1)4superscriptğ‘š2superscriptnormsuperscriptğ‘¥ğ‘˜22subscriptğ›¿1\frac{4}{m^{2}}\|x^{k}\|^{2}\log(2/\delta\_{1}).
Putting these together, the squared change in Dk,kâ€²subscriptğ·

ğ‘˜superscriptğ‘˜â€²D\_{k,k^{\prime}} due to an entry that appears on both sides is at most

|  |  |  |  |
| --- | --- | --- | --- |
|  | (2|(SÂ¯R,Lxkâ€²)i|\displaystyle(2|({\bar{S}}\_{R,L}x^{k^{\prime}})\_{i}| | +2|(SÂ¯R,Lxk)iâ€²|)2\displaystyle+2|({\bar{S}}\_{R,L}x^{k})\_{i^{\prime}}|)^{2} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =4â€‹(|(SÂ¯R,Lâ€‹xkâ€²)i|2+2â€‹|(SÂ¯R,Lâ€‹xkâ€²)iâ‹…(SÂ¯R,Lâ€‹xk)iâ€²|+|(SÂ¯R,Lâ€‹xk)iâ€²|2)absent4superscriptsubscriptsubscriptÂ¯ğ‘†  ğ‘…ğ¿superscriptğ‘¥superscriptğ‘˜â€²ğ‘–22â‹…subscriptsubscriptÂ¯ğ‘†  ğ‘…ğ¿superscriptğ‘¥superscriptğ‘˜â€²ğ‘–subscriptsubscriptÂ¯ğ‘†  ğ‘…ğ¿superscriptğ‘¥ğ‘˜superscriptğ‘–â€²superscriptsubscriptsubscriptÂ¯ğ‘†  ğ‘…ğ¿superscriptğ‘¥ğ‘˜superscriptğ‘–â€²2\displaystyle=4\left(|({\bar{S}}\_{R,L}x^{k^{\prime}})\_{i}|^{2}+2|({\bar{S}}\_{R,L}x^{k^{\prime}})\_{i}\cdot({\bar{S}}\_{R,L}x^{k})\_{i^{\prime}}|+|({\bar{S}}\_{R,L}x^{k})\_{i^{\prime}}|^{2}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤8â€‹|(SÂ¯R,Lâ€‹xkâ€²)i|2+8â€‹|(SÂ¯R,Lâ€‹xk)iâ€²|2absent8superscriptsubscriptsubscriptÂ¯ğ‘†  ğ‘…ğ¿superscriptğ‘¥superscriptğ‘˜â€²ğ‘–28superscriptsubscriptsubscriptÂ¯ğ‘†  ğ‘…ğ¿superscriptğ‘¥ğ‘˜superscriptğ‘–â€²2\displaystyle\leq 8|({\bar{S}}\_{R,L}x^{k^{\prime}})\_{i}|^{2}+8|({\bar{S}}\_{R,L}x^{k})\_{i^{\prime}}|^{2} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =8m2â‹…logâ¡(2/Î´1)â€‹(â€–xkâ€²â€–2+â€–xkâ€–2).absentâ‹…8superscriptğ‘š22subscriptğ›¿1superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²2superscriptnormsuperscriptğ‘¥ğ‘˜2\displaystyle=\frac{8}{m^{2}}\cdot\log(2/\delta\_{1})(\|x^{k^{\prime}}\|^{2}+\|x^{k}\|^{2}). |  |

The third line follows from the AM-GM inequality.

To obtain the total of the squared difference bounds, as needed in CorollaryÂ [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"),
note that a given entry of SÂ¯Â¯ğ‘†{\bar{S}} may be one of mâ€‹â€–xkâ€–2ğ‘šsuperscriptnormsuperscriptğ‘¥ğ‘˜2m\|x^{k}\|^{2} relevant entries of SÂ¯Â¯ğ‘†{\bar{S}} on one side, and may be one of mâ€‹â€–xkâ€²â€–2ğ‘šsuperscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²2m\|x^{k^{\prime}}\|^{2} relevant entries on the other.
Suppose we â€œchargeâ€ an appearance of an entry among the mâ€‹â€–xkâ€–2ğ‘šsuperscriptnormsuperscriptğ‘¥ğ‘˜2m\|x^{k}\|^{2} entries contributing to SÂ¯R,Lâ€‹xksubscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥ğ‘˜{\bar{S}}\_{R,L}x^{k} an amount of 8m2â€‹logâ¡(2/Î´1)â€‹â€–xkâ€²â€–28superscriptğ‘š22subscriptğ›¿1superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²2\frac{8}{m^{2}}\log(2/\delta\_{1})\|x^{k^{\prime}}\|^{2}, and an appearance of an entry among among the mâ€‹â€–xkâ€²â€–2ğ‘šsuperscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²2m\|x^{k^{\prime}}\|^{2} contributing to SÂ¯R,Lâ€‹xkâ€²subscriptÂ¯ğ‘†

ğ‘…ğ¿superscriptğ‘¥superscriptğ‘˜â€²{\bar{S}}\_{R,L}x^{k^{\prime}} an amount of 8m2â€‹logâ¡(2/Î´1)â€‹â€–xkâ€–28superscriptğ‘š22subscriptğ›¿1superscriptnormsuperscriptğ‘¥ğ‘˜2\frac{8}{m^{2}}\log(2/\delta\_{1})\|x^{k}\|^{2}.
Then from the above, the contribution of every entry, and its one or two appearances, to the sum of squares of per-entry changes to Dk,kâ€²subscriptğ·

ğ‘˜superscriptğ‘˜â€²D\_{k,k^{\prime}}, is accounted for.
That sum of squares, as needed for Cor.Â [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), is therefore at most

|  |  |  |  |
| --- | --- | --- | --- |
|  | 16m16ğ‘š\displaystyle\frac{16}{m} | logâ¡(2/Î´1)â€‹â€–xkâ€–2â€‹â€–xkâ€²â€–2,2subscriptğ›¿1superscriptnormsuperscriptğ‘¥ğ‘˜2superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²2\displaystyle\log(2/\delta\_{1})\|x^{k}\|^{2}\|x^{k^{\prime}}\|^{2}, |  |

assuming still event â„°â„°\cal E.

To apply Cor.Â [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), we have upper bound M=â€–xkâ€–2â€‹â€–xkâ€²â€–2ğ‘€superscriptnormsuperscriptğ‘¥ğ‘˜2superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²2M=\|x^{k}\|^{2}\|x^{k^{\prime}}\|^{2}, and Î´ğ›¿\delta of that corollary at most 2â€‹Î´1â€‹m2subscriptğ›¿1ğ‘š2\delta\_{1}m.
We note that since kâ‰ kâ€²ğ‘˜superscriptğ‘˜â€²k\neq k^{\prime}, we have
ğ”¼â€‹[Dk,kâ€²]=0ğ”¼delimited-[]subscriptğ·

ğ‘˜superscriptğ‘˜â€²0{\mathbb{E}}[D\_{k,k^{\prime}}]=0.
So

|  |  |  |
| --- | --- | --- |
|  | Prâ¡(Dk,kâ€²â‰¥t+2â€‹Î´1â€‹mâ€‹â€–xkâ€–2â€‹â€–xkâ€²â€–2)â‰¤2â€‹expâ¡(âˆ’t2â€‹m16â€‹logâ¡(2/Î´1)â€‹â€–xkâ€–2â€‹â€–xkâ€²â€–2)+2â€‹Î´1â€‹m.Prsubscriptğ·  ğ‘˜superscriptğ‘˜â€²ğ‘¡2subscriptğ›¿1ğ‘šsuperscriptnormsuperscriptğ‘¥ğ‘˜2superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²22superscriptğ‘¡2ğ‘š162subscriptğ›¿1superscriptnormsuperscriptğ‘¥ğ‘˜2superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²22subscriptğ›¿1ğ‘š\Pr(D\_{k,k^{\prime}}\geq t+2\delta\_{1}m\|x^{k}\|^{2}\|x^{k^{\prime}}\|^{2})\leq 2\exp\left(-\frac{t^{2}m}{16\log(2/\delta\_{1})\|x^{k}\|^{2}\|x^{k^{\prime}}\|^{2}}\right)+2\delta\_{1}m. |  |

Setting Î´1â‰¤Îµâ€‹Î´/4â€‹K2â€‹msubscriptğ›¿1ğœ€ğ›¿4superscriptğ¾2ğ‘š\delta\_{1}\leq{\varepsilon}\delta/4K^{2}m for target failure probability Î´ğ›¿\delta, and
t=12â€‹Îµâ€‹â€–xkâ€–â€‹â€–xkâ€²â€–ğ‘¡12ğœ€normsuperscriptğ‘¥ğ‘˜normsuperscriptğ‘¥superscriptğ‘˜â€²t=\frac{1}{2}{\varepsilon}\|x^{k}\|\|x^{k^{\prime}}\|,
we get

|  |  |  |
| --- | --- | --- |
|  | Prâ¡(Dk,kâ€²â‰¥Îµâ€‹â€–xkâ€–2â€‹â€–xkâ€²â€–2)â‰¤2â€‹expâ¡(âˆ’Îµ2â€‹m16â€‹logâ¡(2/Î´1))+Îµâ€‹Î´/2â€‹K2,Prsubscriptğ·  ğ‘˜superscriptğ‘˜â€²ğœ€superscriptnormsuperscriptğ‘¥ğ‘˜2superscriptnormsuperscriptğ‘¥superscriptğ‘˜â€²22superscriptğœ€2ğ‘š162subscriptğ›¿1ğœ€ğ›¿2superscriptğ¾2\Pr(D\_{k,k^{\prime}}\geq{\varepsilon}\|x^{k}\|^{2}\|x^{k^{\prime}}\|^{2})\leq 2\exp\left(-\frac{{\varepsilon}^{2}m}{16\log(2/\delta\_{1})}\right)+{\varepsilon}\delta/2K^{2}, |  |

so the failure probability is less than Î´/K2ğ›¿superscriptğ¾2\delta/K^{2} for m=Oâ€‹(Îµâˆ’2â€‹logâ¡(K/Îµâ€‹Î´))ğ‘šğ‘‚superscriptğœ€2ğ¾ğœ€ğ›¿m=O({\varepsilon}^{-2}\log(K/{\varepsilon}\delta)).
(As is not hard to verify.)

Suppose we have this bound for all kâ‰ kâ€²ğ‘˜superscriptğ‘˜â€²k\neq k^{\prime}, which by union bound holds with failure probability at mostÂ Î´ğ›¿\delta.
We have

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–SÂ¯R,Lâ€‹vâ€–2superscriptnormsubscriptÂ¯ğ‘†  ğ‘…ğ¿ğ‘£2\displaystyle\|{\bar{S}}\_{R,L}v\|^{2} | =âˆ‘k(1Â±Îµ)â€‹â€–xkâ€–2Â±12â€‹Îµâ€‹âˆ‘kâ‰ kâ€²â€–xkâ€–â€‹â€–xkâ€²â€–absentplus-or-minussubscriptğ‘˜plus-or-minus1ğœ€superscriptnormsuperscriptğ‘¥ğ‘˜212ğœ€subscriptğ‘˜superscriptğ‘˜â€²normsuperscriptğ‘¥ğ‘˜normsuperscriptğ‘¥superscriptğ‘˜â€²\displaystyle=\sum\_{k}(1\pm{\varepsilon})\|x^{k}\|^{2}\pm\frac{1}{2}{\varepsilon}\sum\_{k\neq k^{\prime}}\|x^{k}\|\|x^{k^{\prime}}\| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =â€–vâ€–2â€‹(1Â±Îµ)Â±Îµâ€‹(âˆ‘kâ€–xkâ€–)2=â€–vâ€–2â€‹(1Â±Îµ)Â±Kâ€‹Îµâ€‹â€–vâ€–2,absentplus-or-minussuperscriptnormğ‘£2plus-or-minus1ğœ€ğœ€superscriptsubscriptğ‘˜normsuperscriptğ‘¥ğ‘˜2plus-or-minussuperscriptnormğ‘£2plus-or-minus1ğœ€ğ¾ğœ€superscriptnormğ‘£2\displaystyle=\|v\|^{2}(1\pm{\varepsilon})\pm{\varepsilon}\left(\sum\_{k}\|x^{k}\|\right)^{2}=\|v\|^{2}(1\pm{\varepsilon})\pm K{\varepsilon}\|v\|^{2}, |  |

and the theorem follows, after folding Kğ¾K into Îµğœ€{\varepsilon} and adjusting constants.
âˆ

### 4.3 Binding

#### 4.3.1 Bundles of pair-wise bindings

As discussed in the introduction, a bundle of pairwise bindings can be given as a vector SÂ¯âŠ™2â€‹vsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£{\bar{S}}^{\odot 2}v, where
vâˆˆ{0,1}(d2)ğ‘£superscript01binomialğ‘‘2v\in\{0,1\}^{\binom{d}{2}}, and SÂ¯âŠ™2âˆˆ{Â±1m}mÃ—(d2)superscriptÂ¯ğ‘†direct-productabsent2superscriptplus-or-minus1ğ‘šğ‘šbinomialğ‘‘2{\bar{S}}^{\odot 2}\in\{\pm\frac{1}{\sqrt{m}}\}^{m\times\binom{d}{2}} is defined in Def.Â [11](#Thmtheorem11 "Definition 11. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
We have
ğ”¼â€‹[â€–SÂ¯âŠ™2â€‹vâ€–2]=â€–vâ€–2ğ”¼delimited-[]superscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2superscriptnormğ‘£2{\mathbb{E}}[\|{\bar{S}}^{\odot 2}v\|^{2}]=\|v\|^{2}, and need to show that
â€–SÂ¯âŠ™2â€‹vâ€–2âˆˆâ€–vâ€–2â€‹(1Â±Îµ)superscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2superscriptnormğ‘£2plus-or-minus1ğœ€\|{\bar{S}}^{\odot 2}v\|^{2}\in\|v\|^{2}(1\pm{\varepsilon}) with high probability.

###### Theorem (Restatement of Theorem [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

For vâˆˆ{0,1}(d2)ğ‘£superscript01binomialğ‘‘2v\in\{0,1\}^{\binom{d}{2}}, there is m=Oâ€‹(Îµâˆ’2â€‹log3â¡(â€–vâ€–1/Îµâ€‹Î´))ğ‘šğ‘‚superscriptğœ€2superscript3subscriptnormğ‘£1ğœ€ğ›¿m=O({\varepsilon}^{-2}\log^{3}(\|v\|\_{1}/{\varepsilon}\delta)) so that
for SÂ¯âŠ™2âˆˆ{Â±1m}(d2)superscriptÂ¯ğ‘†direct-productabsent2superscriptplus-or-minus1ğ‘šbinomialğ‘‘2{\bar{S}}^{\odot 2}\in\{\pm\frac{1}{\sqrt{m}}\}^{\binom{d}{2}},

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|â€–SÂ¯âŠ™2â€‹vâ€–2âˆ’â€–vâ€–2|>Îµâ€‹â€–vâ€–2]â‰¤Î´.PrsuperscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2superscriptnormğ‘£2ğœ€superscriptnormğ‘£2ğ›¿\Pr[|\|{\bar{S}}^{\odot 2}v\|^{2}-\|v\|^{2}|>{\varepsilon}\|v\|^{2}]\leq\delta. |  |

For our analysis we will use a graph Gâ€‹(V,E)ğºğ‘‰ğ¸G(V,E) of interactions in SÂ¯âŠ™ksuperscriptÂ¯ğ‘†direct-productabsentğ‘˜{\bar{S}}^{\odot k} of columns in SÂ¯Â¯ğ‘†{\bar{S}}.
Index the columns of SÂ¯âŠ™ksuperscriptÂ¯ğ‘†direct-productabsentğ‘˜{\bar{S}}^{\odot k} by the columns of SÂ¯Â¯ğ‘†{\bar{S}} from which they came, so SÂ¯âˆ—,{i1,i2,â€¦,ik}âŠ™ksubscriptsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜

subscriptğ‘–1subscriptğ‘–2â€¦subscriptğ‘–ğ‘˜{\bar{S}}^{\odot k}\_{\*,\{i\_{1},i\_{2},\ldots,i\_{k}\}} denotes the column of SÂ¯âŠ™ksuperscriptÂ¯ğ‘†direct-productabsentğ‘˜{\bar{S}}^{\odot k} that is the binding of columns SÂ¯âˆ—,i1,SÂ¯âˆ—,i2,â€¦â€‹SÂ¯âˆ—,ik

subscriptÂ¯ğ‘†

subscriptğ‘–1subscriptÂ¯ğ‘†

subscriptğ‘–2â€¦subscriptÂ¯ğ‘†

subscriptğ‘–ğ‘˜{\bar{S}}\_{\*,i\_{1}},{\bar{S}}\_{\*,i\_{2}},\ldots{\bar{S}}\_{\*,i\_{k}} of SÂ¯Â¯ğ‘†{\bar{S}}.
Also use this indexing scheme for vâˆˆâ„(dk)ğ‘£superscriptâ„binomialğ‘‘ğ‘˜v\in{\mathbb{R}}^{\binom{d}{k}}.
Now for given vâˆˆâ„(dk)ğ‘£superscriptâ„binomialğ‘‘ğ‘˜v\in{\mathbb{R}}^{\binom{d}{k}}, the graph (or hyper-graph, for k>2ğ‘˜2k>2) GğºG has
edges E={eâŠ‚[(dk)]âˆ£veâ‰ 0}ğ¸conditional-setğ‘’delimited-[]binomialğ‘‘ğ‘˜subscriptğ‘£ğ‘’0E=\{e\subset[\binom{d}{k}]\mid v\_{e}\neq 0\}, and
vertices V={iâˆ£iâˆˆeâˆˆE}ğ‘‰conditional-setğ‘–ğ‘–ğ‘’ğ¸V=\{i\mid i\in e\in E\}.

We can also include singleton atomic vectors in the bundling, by including the all-ones vector 1â†’msubscriptâ†’1ğ‘š\vec{1}\_{m} as an atomic vector, bound to each singleton.
Note that approximate orthogonality holds also for these bindings, and the dimension is (d+12)binomialğ‘‘12\binom{d+1}{2}, within a constant factor of (d2)binomialğ‘‘2\binom{d}{2}.

We prove TheoremÂ [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") using this graphical view of SÂ¯âŠ™2â€‹vsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£{\bar{S}}^{\odot 2}v in the following way.
For given â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m] we can write the Rademacher variables contributing to nonzero summands of SÂ¯â„“âŠ™2â€‹vsuperscriptsubscriptÂ¯ğ‘†â„“direct-productabsent2ğ‘£{\bar{S}}\_{\ell}^{\odot 2}v as
Xâ„“=(x1,x2,â€¦,x|V|)subscriptğ‘‹â„“subscriptğ‘¥1subscriptğ‘¥2â€¦subscriptğ‘¥ğ‘‰X\_{\ell}=(x\_{1},x\_{2},\ldots,x\_{|V|}), for Vğ‘‰V the vertex set of the associated graph GğºG.
Also, we can express SÂ¯â„“âŠ™2â€‹vsuperscriptsubscriptÂ¯ğ‘†â„“direct-productabsent2ğ‘£{\bar{S}}\_{\ell}^{\odot 2}v as a function

|  |  |  |  |
| --- | --- | --- | --- |
|  | mâ‹…SÂ¯â„“,âˆ—âŠ™2â€‹v=fâ€‹(Xâ„“),whereâ€‹fâ€‹(x)=âˆ‘{i,j}âˆˆExiâ€‹xj.formulae-sequenceâ‹…ğ‘šsuperscriptsubscriptÂ¯ğ‘†  â„“direct-productabsent2ğ‘£ğ‘“subscriptğ‘‹â„“whereğ‘“ğ‘¥subscriptğ‘–ğ‘—ğ¸subscriptğ‘¥ğ‘–subscriptğ‘¥ğ‘—\sqrt{m}\cdot{\bar{S}}\_{\ell,\*}^{\odot 2}v=f(X\_{\ell}),\mathrm{\ where\ }f(x)=\sum\_{\{i,j\}\in E}x\_{i}x\_{j}. |  | (1) |

###### Proof of Theorem [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

For iâˆˆ[|V|]ğ‘–delimited-[]ğ‘‰i\in[|V|], let function giâ€‹(x1,â€¦,x|V|)subscriptğ‘”ğ‘–subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘‰g\_{i}(x\_{1},\ldots,x\_{|V|}) take value xiâ€‹(1{i}âˆˆE+âˆ‘j:(i,j)âˆˆExj)subscriptğ‘¥ğ‘–subscript1ğ‘–ğ¸subscript:ğ‘—ğ‘–ğ‘—ğ¸subscriptğ‘¥ğ‘—x\_{i}(1\_{\{i\}\in E}+\sum\_{j:\,(i,j)\in E}x\_{j}).
(Here 1{i}âˆˆEsubscript1ğ‘–ğ¸1\_{\{i\}\in E} equals one when {i}âˆˆEğ‘–ğ¸\{i\}\in E, and zero otherwise.)
Then, for any â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m], flipping the sign of xisubscriptğ‘¥ğ‘–x\_{i} changes any fâ€‹(Xâ„“)ğ‘“subscriptğ‘‹â„“f(X\_{\ell}) by no more than 2â€‹|giâ€‹(Xâ„“)|2subscriptğ‘”ğ‘–subscriptğ‘‹â„“2|g\_{i}(X\_{\ell})|.
By Theorem [29](#Thmtheorem29 "Theorem 29. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), with a1,â€¦,adegGâ¡(i)=1

subscriptğ‘1â€¦subscriptğ‘subscriptdegreeğºğ‘–
1a\_{1},\ldots,a\_{\deg\_{G}(i)}=1 and t=6â€‹logâ¡(|E|â€‹m/Î´)ğ‘¡6ğ¸ğ‘šğ›¿t=\sqrt{6\log(|E|m/\delta)}, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[2â€‹|giâ€‹(Xâ„“)|>2â€‹6â€‹degGâ¡(i)â‹…logâ¡(2â€‹|E|â€‹m/Î´)]<Î´38â€‹|E|3â€‹m3.Pr2subscriptğ‘”ğ‘–subscriptğ‘‹â„“2â‹…6subscriptdegreeğºğ‘–2ğ¸ğ‘šğ›¿superscriptğ›¿38superscriptğ¸3superscriptğ‘š3\Pr\left[2|g\_{i}(X\_{\ell})|>2\sqrt{6\deg\_{G}(i)\cdot\log(2|E|m/\delta)}\right]<\frac{\delta^{3}}{8|E|^{3}m^{3}}. |  | (2) |

Let â„°â„°{\mathcal{E}} be the event that these upper bounds hold for all â„“âˆˆ[m],iâˆˆVformulae-sequenceâ„“delimited-[]ğ‘šğ‘–ğ‘‰\ell\in[m],i\in V.
Then taking the union bound over all mâ€‹|V|ğ‘šğ‘‰m|V| such giâ€‹(Xâ„“)subscriptğ‘”ğ‘–subscriptğ‘‹â„“g\_{i}(X\_{\ell}), event â„°â„°{\mathcal{E}} occurs with failure probability at most

|  |  |  |
| --- | --- | --- |
|  | Î´â„°â‰¡Î´34â€‹|E|2â€‹m2,subscriptğ›¿â„°superscriptğ›¿34superscriptğ¸2superscriptğ‘š2\delta\_{\mathcal{E}}\equiv\frac{\delta^{3}}{4|E|^{2}m^{2}}, |  |

noting that 2â€‹|E|â‰¥|V|2ğ¸ğ‘‰2|E|\geq|V|, since each vertex occurs in some edge, and at most two vertices occur in one edge.

For â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m], let function fË‡â€‹(Xâ„“)Ë‡ğ‘“subscriptğ‘‹â„“{\check{f}}(X\_{\ell}) be equal to fâ€‹(Xâ„“)ğ‘“subscriptğ‘‹â„“f(X\_{\ell}) when â„°â„°{\mathcal{E}} holds, and be zero otherwise.
By McDiarmidâ€™s Inequality, TheoremÂ [25](#Thmtheorem25 "Theorem 25. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"),

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[|fË‡â€‹(Xâ„“)âˆ’ğ”¼â€‹[fË‡â€‹(Xâ„“)]|â‰¥t]PrË‡ğ‘“subscriptğ‘‹â„“ğ”¼delimited-[]Ë‡ğ‘“subscriptğ‘‹â„“ğ‘¡\displaystyle\Pr[|{\check{f}}(X\_{\ell})-{\mathbb{E}}[{\check{f}}(X\_{\ell})]|\geq t] | â‰¤2â€‹expâ¡(âˆ’2â€‹t2âˆ‘iâˆˆ[|V|](2â€‹6â€‹degGâ¡(i)â‹…logâ¡(|E|â€‹m/Î´))2)absent22superscriptğ‘¡2subscriptğ‘–delimited-[]ğ‘‰superscript2â‹…6subscriptdegreeğºğ‘–ğ¸ğ‘šğ›¿2\displaystyle\leq 2\exp\left(\frac{-2t^{2}}{\sum\_{i\in[|V|]}(2\sqrt{6\deg\_{G}(i)\cdot\log(|E|m/\delta)})^{2}}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =2â€‹expâ¡(âˆ’t212â€‹|E|â€‹logâ¡(|E|â€‹m/Î´)).absent2superscriptğ‘¡212ğ¸ğ¸ğ‘šğ›¿\displaystyle=2\exp\left(-\frac{t^{2}}{12|E|\log(|E|m/\delta)}\right). |  |

From PropositionÂ 2.5.2 of [vershynin\_high-dimensional\_2018], therefore, for all â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m], fË‡â€‹(Xâ„“)âˆ’ğ”¼â€‹[fË‡â€‹(Xâ„“)]Ë‡ğ‘“subscriptğ‘‹â„“ğ”¼delimited-[]Ë‡ğ‘“subscriptğ‘‹â„“{\check{f}}(X\_{\ell})-{\mathbb{E}}[{\check{f}}(X\_{\ell})] is a sub-Gaussian random variable, with proxy variance within a constant factor of at most

|  |  |  |
| --- | --- | --- |
|  | ÏƒfË‡2â‰¡12â€‹|E|â€‹logâ¡(|E|â€‹m/Î´).subscriptsuperscriptğœ2Ë‡ğ‘“12ğ¸ğ¸ğ‘šğ›¿\sigma^{2}\_{\check{f}}\equiv 12|E|\log(|E|m/\delta). |  |

Let fÂ¯â‰¡ğ”¼â€‹[fË‡â€‹(X)]Â¯ğ‘“ğ”¼delimited-[]Ë‡ğ‘“ğ‘‹\bar{f}\equiv{\mathbb{E}}[{\check{f}}(X)], for Rademacher Xğ‘‹X.
Since ğ”¼â€‹[fâ€‹(X)]=0ğ”¼delimited-[]ğ‘“ğ‘‹0{\mathbb{E}}[f(X)]=0, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | |fÂ¯|Â¯ğ‘“\displaystyle|\bar{f}| | =|ğ”¼[fË‡(X)âˆ£â„°]Pr[â„°]+ğ”¼[fË‡(X)âˆ£Â¬â„°]Pr[Â¬â„°]|\displaystyle=|\,{\mathbb{E}}[{\check{f}}(X)\mid{\mathcal{E}}]\Pr[{\mathcal{E}}]+{\mathbb{E}}[{\check{f}}(X)\mid\neg{\mathcal{E}}]\Pr[\neg{\mathcal{E}}]\,| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =|ğ”¼[f(X)âˆ£â„°]Pr[â„°]+0|\displaystyle=|\,{\mathbb{E}}[f(X)\mid{\mathcal{E}}]\Pr[{\mathcal{E}}]+0\,| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =|ğ”¼[f(X)]âˆ’ğ”¼[f(X)âˆ£Â¬â„°]Pr[Â¬â„°]|\displaystyle=|\,{\mathbb{E}}[f(X)]-{\mathbb{E}}[f(X)\mid\neg{\mathcal{E}}]\Pr[\neg{\mathcal{E}}]\,| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤|â€‰0âˆ’ğ”¼[f(X)âˆ£Â¬â„°]Î´â„°|\displaystyle\leq|\,0-{\mathbb{E}}[f(X)\mid\neg{\mathcal{E}}]\delta\_{\mathcal{E}}\,| |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | â‰¤|E|â€‹Î´â„°,absentğ¸subscriptğ›¿â„°\displaystyle\leq|E|\delta\_{\mathcal{E}}, |  | (3) |

since |fâ€‹(X)|â‰¤|E|ğ‘“ğ‘‹ğ¸|f(X)|\leq|E|.

Let FË‡â‰¡1mâ€‹âˆ‘â„“fË‡â€‹(Xâ„“)2Ë‡ğ¹1ğ‘šsubscriptâ„“Ë‡ğ‘“superscriptsubscriptğ‘‹â„“2{\check{F}}\equiv\frac{1}{m}\sum\_{\ell}{\check{f}}(X\_{\ell})^{2}, and FË‡câ‰¡1mâ€‹âˆ‘â„“(fË‡â€‹(Xâ„“)âˆ’fÂ¯)2subscriptË‡ğ¹ğ‘1ğ‘šsubscriptâ„“superscriptË‡ğ‘“subscriptğ‘‹â„“Â¯ğ‘“2{\check{F}}\_{c}\equiv\frac{1}{m}\sum\_{\ell}({\check{f}}(X\_{\ell})-\bar{f})^{2}.
Using ExerciseÂ 2.7.10 and CorollaryÂ 2.8.3 of [vershynin\_high-dimensional\_2018], it follows that

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|FË‡câˆ’ğ”¼â€‹[FË‡c]|>t]â‰¤2â€‹expâ¡(âˆ’câ€‹mâ€‹minâ¡(t2ÏƒfË‡4,tÏƒfË‡2)).PrsubscriptË‡ğ¹ğ‘ğ”¼delimited-[]subscriptË‡ğ¹ğ‘ğ‘¡2ğ‘ğ‘šsuperscriptğ‘¡2superscriptsubscriptğœË‡ğ‘“4ğ‘¡superscriptsubscriptğœË‡ğ‘“2\displaystyle\Pr[|{\check{F}}\_{c}-{\mathbb{E}}[{\check{F}}\_{c}]|>t]\leq 2\exp\left(-cm\min\left(\frac{t^{2}}{\sigma\_{\check{f}}^{4}},\frac{t}{\sigma\_{\check{f}}^{2}}\right)\right). |  |

For t=Îµâ€‹|E|/2<ÏƒfË‡2ğ‘¡ğœ€ğ¸2superscriptsubscriptğœË‡ğ‘“2t={\varepsilon}|E|/2<\sigma\_{\check{f}}^{2}, the upper bound is
2exp(âˆ’cmÎµ2/log(|E|m/Î´)2)2\exp(-cm{\varepsilon}^{2}/\log(|E|m/\delta)^{2}), for a different constant cğ‘c, so there is m=O(Îµâˆ’2log(|E|/ÎµÎ´)3)m=O({\varepsilon}^{-2}\log(|E|/{\varepsilon}\delta)^{3}) such that

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[|FË‡câˆ’ğ”¼â€‹[FË‡c]|>Îµâ€‹|E|/2]â‰¤Î´/2.PrsubscriptË‡ğ¹ğ‘ğ”¼delimited-[]subscriptË‡ğ¹ğ‘ğœ€ğ¸2ğ›¿2\Pr[|{\check{F}}\_{c}-{\mathbb{E}}[{\check{F}}\_{c}]|>{\varepsilon}|E|/2]\leq\delta/2. |  | (4) |

We have a tail estimate for FË‡csubscriptË‡ğ¹ğ‘{\check{F}}\_{c}, but not for FË‡Ë‡ğ¹{\check{F}} or
â€–PâŠ™2â€‹vâ€–2=1mâ€‹âˆ‘â„“fâ€‹(Xâ„“)2superscriptnormsuperscriptğ‘ƒdirect-productabsent2ğ‘£21ğ‘šsubscriptâ„“ğ‘“superscriptsubscriptğ‘‹â„“2\|P^{\odot 2}v\|^{2}=\frac{1}{m}\sum\_{\ell}f(X\_{\ell})^{2}.
We have

|  |  |  |  |
| --- | --- | --- | --- |
|  | FË‡câˆ’ğ”¼â€‹[FË‡c]subscriptË‡ğ¹ğ‘ğ”¼delimited-[]subscriptË‡ğ¹ğ‘\displaystyle{\check{F}}\_{c}-{\mathbb{E}}[{\check{F}}\_{c}] | =1mâ€‹âˆ‘â„“(fË‡â€‹(Xâ„“)âˆ’fÂ¯)2âˆ’ğ”¼â€‹[fË‡â€‹(Xâ„“âˆ’fÂ¯)2]absent1ğ‘šsubscriptâ„“superscriptË‡ğ‘“subscriptğ‘‹â„“Â¯ğ‘“2ğ”¼delimited-[]Ë‡ğ‘“superscriptsubscriptğ‘‹â„“Â¯ğ‘“2\displaystyle=\frac{1}{m}\sum\_{\ell}({\check{f}}(X\_{\ell})-\bar{f})^{2}-{\mathbb{E}}[{\check{f}}(X\_{\ell}-\bar{f})^{2}] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =FË‡âˆ’ğ”¼â€‹[FË‡]+1mâ€‹âˆ‘â„“âˆ’2â€‹fË‡â€‹(Xâ„“)â€‹fÂ¯+fÂ¯2+2â€‹ğ”¼â€‹[fË‡â€‹(Xâ„“)â€‹fÂ¯]âˆ’fÂ¯2absentË‡ğ¹ğ”¼delimited-[]Ë‡ğ¹1ğ‘šsubscriptâ„“2Ë‡ğ‘“subscriptğ‘‹â„“Â¯ğ‘“superscriptÂ¯ğ‘“22ğ”¼delimited-[]Ë‡ğ‘“subscriptğ‘‹â„“Â¯ğ‘“superscriptÂ¯ğ‘“2\displaystyle={\check{F}}-{\mathbb{E}}[{\check{F}}]+\frac{1}{m}\sum\_{\ell}-2{\check{f}}(X\_{\ell})\bar{f}+\bar{f}^{2}+2{\mathbb{E}}[{\check{f}}(X\_{\ell})\bar{f}]-\bar{f}^{2} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =FË‡âˆ’ğ”¼â€‹[FË‡]+2â€‹fÂ¯2âˆ’2mâ€‹fÂ¯â€‹âˆ‘â„“fË‡â€‹(Xâ„“).absentË‡ğ¹ğ”¼delimited-[]Ë‡ğ¹2superscriptÂ¯ğ‘“22ğ‘šÂ¯ğ‘“subscriptâ„“Ë‡ğ‘“subscriptğ‘‹â„“\displaystyle={\check{F}}-{\mathbb{E}}[{\check{F}}]+2\bar{f}^{2}-\frac{2}{m}\bar{f}\sum\_{\ell}{\check{f}}(X\_{\ell}). |  |

Using ([3](#S4.E3 "In Proof of Theorem 12. â€£ 4.3.1 Bundles of pair-wise bindings â€£ 4.3 Binding â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures")) and |fâ€‹(X)|â‰¤|E|ğ‘“ğ‘‹ğ¸|f(X)|\leq|E|, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | |FË‡âˆ’ğ”¼â€‹[FË‡]|â‰¤|FË‡câˆ’ğ”¼â€‹[FË‡c]|+4â€‹Î´â„°â€‹|E|2.Ë‡ğ¹ğ”¼delimited-[]Ë‡ğ¹subscriptË‡ğ¹ğ‘ğ”¼delimited-[]subscriptË‡ğ¹ğ‘4subscriptğ›¿â„°superscriptğ¸2|{\check{F}}-{\mathbb{E}}[{\check{F}}]|\leq|{\check{F}}\_{c}-{\mathbb{E}}[{\check{F}}\_{c}]|+4\delta\_{\mathcal{E}}|E|^{2}. |  | (5) |

We can apply LemmaÂ [26](#Thmtheorem26 "Lemma 26. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") to SÂ¯âŠ™2â€‹vsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£{\bar{S}}^{\odot 2}v and FË‡Ë‡ğ¹{\check{F}}, as fğ‘“f and gğ‘”g in that lemma, using that FË‡=â€–SÂ¯âŠ™2â€‹vâ€–2Ë‡ğ¹superscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2{\check{F}}=\|{\bar{S}}^{\odot 2}v\|^{2} with failure probability at most Î´â„°subscriptğ›¿â„°\delta\_{\mathcal{E}}, and that â€–SÂ¯âŠ™2â€‹vâ€–2â‰¤|E|2superscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2superscriptğ¸2\|{\bar{S}}^{\odot 2}v\|^{2}\leq|E|^{2}.
Using t=Îµâ€‹â€–vâ€–2/2+4â€‹Î´â„°â€‹|E|2ğ‘¡ğœ€superscriptnormğ‘£224subscriptğ›¿â„°superscriptğ¸2t={\varepsilon}\|v\|^{2}/2+4\delta\_{\mathcal{E}}|E|^{2} in that lemma, together with ([5](#S4.E5 "In Proof of Theorem 12. â€£ 4.3.1 Bundles of pair-wise bindings â€£ 4.3 Binding â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures")) and ([4](#S4.E4 "In Proof of Theorem 12. â€£ 4.3.1 Bundles of pair-wise bindings â€£ 4.3 Binding â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures")), we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[|â€–SÂ¯âŠ™2â€‹vâ€–2âˆ’â€–vâ€–2|>Îµâ€‹â€–vâ€–2/2+4â€‹Î´â„°â€‹|E|2+Î´â„°â€‹|E|2]PrsuperscriptnormsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£2superscriptnormğ‘£2ğœ€superscriptnormğ‘£224subscriptğ›¿â„°superscriptğ¸2subscriptğ›¿â„°superscriptğ¸2\displaystyle\Pr[|\|{\bar{S}}^{\odot 2}v\|^{2}-\|v\|^{2}|>{\varepsilon}\|v\|^{2}/2+4\delta\_{\mathcal{E}}|E|^{2}+\delta\_{\mathcal{E}}|E|^{2}] | â‰¤Prâ¡[|FË‡âˆ’ğ”¼â€‹[FË‡]|>Îµâ€‹â€–vâ€–2/2+4â€‹Î´â„°â€‹|E|2]absentPrË‡ğ¹ğ”¼delimited-[]Ë‡ğ¹ğœ€superscriptnormğ‘£224subscriptğ›¿â„°superscriptğ¸2\displaystyle\leq\Pr[|{\check{F}}-{\mathbb{E}}[{\check{F}}]|>{\varepsilon}\|v\|^{2}/2+4\delta\_{\mathcal{E}}|E|^{2}] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Prâ¡[|FË‡câˆ’ğ”¼â€‹[FË‡c]|>Îµâ€‹â€–vâ€–2/2]+Î´â„°absentPrsubscriptË‡ğ¹ğ‘ğ”¼delimited-[]subscriptË‡ğ¹ğ‘ğœ€superscriptnormğ‘£22subscriptğ›¿â„°\displaystyle\leq\Pr[|{\check{F}}\_{c}-{\mathbb{E}}[{\check{F}}\_{c}]|>{\varepsilon}\|v\|^{2}/2]+\delta\_{\mathcal{E}} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤Î´/2+Î´â„°â‰¤Î´.absentğ›¿2subscriptğ›¿â„°ğ›¿\displaystyle\leq\delta/2+\delta\_{\mathcal{E}}\leq\delta. |  |

The theorem follows, using 5â€‹Î´â„°â€‹|E|2=5â€‹Î´3/4â€‹m2<Îµâ€‹â€–vâ€–2/25subscriptğ›¿â„°superscriptğ¸25superscriptğ›¿34superscriptğ‘š2ğœ€superscriptnormğ‘£225\delta\_{\mathcal{E}}|E|^{2}=5\delta^{3}/4m^{2}<{\varepsilon}\|v\|^{2}/2, possibly adjusting mğ‘šm by a constant factor.

âˆ

#### 4.3.2 Bundles of Bindings of Multiple Vectors

We can again hope to use Corollary [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") in this setting.
However, to obtain the appropriate constants c1,â€¦,cn

subscriptğ‘1â€¦subscriptğ‘ğ‘›c\_{1},\ldots,c\_{n} to use in Corollary [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), we cannot directly apply TheoremÂ [29](#Thmtheorem29 "Theorem 29. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"); it is only a base case, for when k=2ğ‘˜2k=2.
We proceed via induction on the maximum binding size.

###### Lemma 36.

Given hypergraph G=(V,E)ğºğ‘‰ğ¸G=(V,E), let fâ€‹(x1,â€¦,x|V|)=âˆ‘eâˆˆEâˆiâˆˆexiğ‘“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘‰subscriptğ‘’ğ¸subscriptproductğ‘–ğ‘’subscriptğ‘¥ğ‘–f(x\_{1},\ldots,x\_{|V|})=\sum\_{e\in E}\prod\_{i\in e}x\_{i}, and let kğ‘˜k be the maximum hyperedge size.
Let X=(X1,â€¦,X|V|)ğ‘‹subscriptğ‘‹1â€¦subscriptğ‘‹ğ‘‰X=(X\_{1},\ldots,X\_{|V|}) be a tuple of independent random Rademacher variables, i.e., each takes values {Â±1}plus-or-minus1\{\pm 1\} with probability 1212\frac{1}{2}.
For Î´0â‰¤Oâ€‹(1/|E|)subscriptğ›¿0ğ‘‚1ğ¸\delta\_{0}\leq O\left(1/\sqrt{|E|}\right):

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[|fâ€‹(X)|â‰¥2â€‹k!â‹…|E|â€‹logk/2â¡(k/Î´0)]Prğ‘“ğ‘‹2â‹…ğ‘˜ğ¸superscriptğ‘˜2ğ‘˜subscriptğ›¿0\displaystyle\Pr\left[|f(X)|\geq 2\sqrt{k!\cdot|E|}\log^{k/2}\left(k/\delta\_{0}\right)\right] | â‰¤Î´0absentsubscriptğ›¿0\displaystyle\leq\delta\_{0} |  |

###### Proof.

We proceed by induction on kğ‘˜k.
When k=2ğ‘˜2k=2, we are done by TheoremÂ [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

To handle general kğ‘˜k, we again apply the version of McDiarmid in Corollary [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures").
If we fix (x1,â€¦,x|V|)subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘‰(x\_{1},\ldots,x\_{|V|}), changing the value of xisubscriptğ‘¥ğ‘–x\_{i} again changes fğ‘“f by at most âˆ‘eâˆˆE:iâˆˆEâˆjâˆˆE:jâ‰ ixjsubscript:ğ‘’ğ¸ğ‘–ğ¸subscriptproduct:ğ‘—ğ¸ğ‘—ğ‘–subscriptğ‘¥ğ‘—\sum\_{e\in E:\,i\in E}\prod\_{j\in E:\,j\neq i}x\_{j}.
The expression âˆ‘eâˆˆE:iâˆˆEâˆjâˆˆE:jâ‰ ixjsubscript:ğ‘’ğ¸ğ‘–ğ¸subscriptproduct:ğ‘—ğ¸ğ‘—ğ‘–subscriptğ‘¥ğ‘—\sum\_{e\in E:\,i\in E}\prod\_{j\in E:\,j\neq i}x\_{j} encodes a hypergraph Gi=(Vi,Ei)subscriptğºğ‘–subscriptğ‘‰ğ‘–subscriptğ¸ğ‘–G\_{i}=(V\_{i},E\_{i}) with maximum edge size kâˆ’1ğ‘˜1k-1, so by induction, we may assume:

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|âˆ‘eâˆˆE:iâˆˆEâˆjâˆˆE:jâ‰ ixj|â‰¥2â€‹(kâˆ’1)!â€‹|Ei|â€‹log(kâˆ’1)/2â¡(k/Î´0)]â‰¤(kâˆ’1)â€‹Î´0kPrsubscript:ğ‘’ğ¸ğ‘–ğ¸subscriptproduct:ğ‘—ğ¸ğ‘—ğ‘–subscriptğ‘¥ğ‘—2ğ‘˜1subscriptğ¸ğ‘–superscriptğ‘˜12ğ‘˜subscriptğ›¿0ğ‘˜1subscriptğ›¿0ğ‘˜\Pr\left[\left|\sum\_{e\in E:\,i\in E}\prod\_{j\in E:\,j\neq i}x\_{j}\right|\geq 2\sqrt{(k-1)!|E\_{i}|}\log^{(k-1)/2}\left(k/\delta\_{0}\right)\right]\leq\frac{(k-1)\delta\_{0}}{k} |  |

Now, we invoke Corollary [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") with ci=2â€‹(kâˆ’1)!â€‹|Ei|â€‹log(kâˆ’1)/2â¡(k/Î´0)subscriptğ‘ğ‘–2ğ‘˜1subscriptğ¸ğ‘–superscriptğ‘˜12ğ‘˜subscriptğ›¿0c\_{i}=2\sqrt{(k-1)!|E\_{i}|}\log^{(k-1)/2}(k/\delta\_{0}).

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ‘i=1|V|ci2superscriptsubscriptğ‘–1ğ‘‰superscriptsubscriptğ‘ğ‘–2\displaystyle\sum\_{i=1}^{|V|}c\_{i}^{2} | =âˆ‘i=1|V|4â€‹(kâˆ’1)!â€‹|Ei|â€‹logkâˆ’1â¡(k/Î´0)absentsuperscriptsubscriptğ‘–1ğ‘‰4ğ‘˜1subscriptğ¸ğ‘–superscriptğ‘˜1ğ‘˜subscriptğ›¿0\displaystyle=\sum\_{i=1}^{|V|}4(k-1)!|E\_{i}|\log^{k-1}(k/\delta\_{0}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =4â€‹(kâˆ’1)!â€‹logkâˆ’1â¡(k/Î´0)â€‹âˆ‘i=1|V||Ei|absent4ğ‘˜1superscriptğ‘˜1ğ‘˜subscriptğ›¿0superscriptsubscriptğ‘–1ğ‘‰subscriptğ¸ğ‘–\displaystyle=4(k-1)!\log^{k-1}(k/\delta\_{0})\sum\_{i=1}^{|V|}|E\_{i}| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤4â€‹(kâˆ’1)!â€‹(logkâˆ’1â¡(k/Î´0))â‹…kâ€‹|E|absentâ‹…4ğ‘˜1superscriptğ‘˜1ğ‘˜subscriptğ›¿0ğ‘˜ğ¸\displaystyle\leq 4(k-1)!(\log^{k-1}(k/\delta\_{0}))\cdot k|E| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =4â€‹k!â‹…|E|â€‹logkâˆ’1â¡(k/Î´0)absentâ‹…4ğ‘˜ğ¸superscriptğ‘˜1ğ‘˜subscriptğ›¿0\displaystyle=4k!\cdot|E|\log^{k-1}(k/\delta\_{0}) |  |

We can also set t=2â€‹k!â‹…|E|â€‹logk/2â¡(k/Î´0)ğ‘¡2â‹…ğ‘˜ğ¸superscriptğ‘˜2ğ‘˜subscriptğ›¿0t=\sqrt{2}\sqrt{k!\cdot|E|}\log^{k/2}(k/\delta\_{0}). Then,

|  |  |  |
| --- | --- | --- |
|  | t2=2â€‹k!â‹…|E|â€‹logkâ¡(k/Î´0)â‰¥12â€‹logâ¡(k/Î´0)â€‹âˆ‘i=1|V|ci2superscriptğ‘¡2â‹…2ğ‘˜ğ¸superscriptğ‘˜ğ‘˜subscriptğ›¿012ğ‘˜subscriptğ›¿0superscriptsubscriptğ‘–1ğ‘‰superscriptsubscriptğ‘ğ‘–2t^{2}=2k!\cdot|E|\log^{k}(k/\delta\_{0})\geq\frac{1}{2}\log(k/\delta\_{0})\sum\_{i=1}^{|V|}c\_{i}^{2} |  |

Finally, setting Î´=(kâˆ’1)â€‹Î´0kğ›¿ğ‘˜1subscriptğ›¿0ğ‘˜\delta=\frac{(k-1)\delta\_{0}}{k}, M=|E|ğ‘€ğ¸M=|E|, Corollary [27](#Thmtheorem27 "Corollary 27. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") implies:

|  |  |  |
| --- | --- | --- |
|  | Pr[|f(X)]|â‰¥2k!â‹…|E|logk/2(k/Î´0)+(kâˆ’1)â‹…|E|â‹…Î´0k]â‰¤Î´0k+(kâˆ’1)â€‹Î´0kâ‰¤Î´0\Pr\left[\left|f(X)]\right|\geq\sqrt{2}\sqrt{k!\cdot|E|}\log^{k/2}(k/\delta\_{0})+\frac{(k-1)\cdot|E|\cdot\delta\_{0}}{k}\right]\leq\frac{\delta\_{0}}{k}+\frac{(k-1)\delta\_{0}}{k}\leq\delta\_{0} |  |

To complete the proof, it suffices to show

|  |  |  |
| --- | --- | --- |
|  | (kâˆ’1)â‹…|E|â‹…Î´0kâ‰¤(2âˆ’2)â€‹k!â‹…|E|â€‹logk/2â¡(k/Î´0)â‹…ğ‘˜1ğ¸subscriptğ›¿0ğ‘˜22â‹…ğ‘˜ğ¸superscriptğ‘˜2ğ‘˜subscriptğ›¿0\frac{(k-1)\cdot|E|\cdot\delta\_{0}}{k}\leq(2-\sqrt{2})\sqrt{k!\cdot|E|}\log^{k/2}(k/\delta\_{0}) |  |

However, given our upper bound on Î´0subscriptğ›¿0\delta\_{0}, this holds for all values of kğ‘˜k.
âˆ

###### Corollary (Restatement of Corollary [13](#Thmtheorem13 "Corollary 13. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

For scaled sign SÂ¯âŠ™kâˆˆ{Â±1m}(dk)superscriptÂ¯ğ‘†direct-productabsentğ‘˜superscriptplus-or-minus1ğ‘šbinomialğ‘‘ğ‘˜{\bar{S}}^{\odot k}\in\{\pm\frac{1}{\sqrt{m}}\}^{\binom{d}{k}}, vâˆˆ{0,1}(dk)ğ‘£superscript01binomialğ‘‘ğ‘˜v\in\{0,1\}^{\binom{d}{k}}, and iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m],
there is C>0ğ¶0C>0 and m=Oâ€‹(Îµâˆ’2â€‹Ckâ€‹logâ¡kâ€‹logk+1â¡(kâ€‹â€–vâ€–1/(Îµâ€‹Î´)))ğ‘šğ‘‚superscriptğœ€2superscriptğ¶ğ‘˜ğ‘˜superscriptğ‘˜1ğ‘˜subscriptnormğ‘£1ğœ€ğ›¿m=O(\varepsilon^{-2}C^{k\log k}\log^{k+1}(k\|v\|\_{1}/(\varepsilon\delta))) such that

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|â€–SÂ¯âŠ™kâ€‹vâ€–2âˆ’â€–vâ€–2|>Îµâ€‹â€–vâ€–2]â‰¤Î´.PrsuperscriptnormsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£2superscriptnormğ‘£2ğœ€superscriptnormğ‘£2ğ›¿\Pr[|\|{\bar{S}}^{\odot k}v\|^{2}-\|v\|^{2}|>{\varepsilon}\|v\|^{2}]\leq\delta. |  |

Just as there was a graphical view of SÂ¯âŠ™2â€‹vsuperscriptÂ¯ğ‘†direct-productabsent2ğ‘£{\bar{S}}^{\odot 2}v, we have a natural way to view SÂ¯âŠ™kâ€‹vsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£{\bar{S}}^{\odot k}v as a hypergraph H=(V,E)ğ»ğ‘‰ğ¸H=(V,E).
For each â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m], let Xâ„“=(x1,x2,â€¦,x|V|)subscriptğ‘‹â„“subscriptğ‘¥1subscriptğ‘¥2â€¦subscriptğ‘¥ğ‘‰X\_{\ell}=(x\_{1},x\_{2},\ldots,x\_{|V|}) be the Rademacher variables contributing to the summands of SÂ¯â„“âŠ™k,âˆ—v{\bar{S}}^{\odot k}\_{\ell},\*v, the â„“â„“\ell-th entry of SÂ¯âŠ™kâ€‹vsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜ğ‘£{\bar{S}}^{\odot k}v, and we can write

|  |  |  |
| --- | --- | --- |
|  | fâ€‹(Xâ„“)â‰¡mâ€‹SÂ¯â„“âŠ™k=âˆ‘(i1,â€¦,ik)âˆˆExi1â€‹xi2â€‹â‹¯â€‹xikğ‘“subscriptğ‘‹â„“ğ‘šsubscriptsuperscriptÂ¯ğ‘†direct-productabsentğ‘˜â„“subscriptsubscriptğ‘–1â€¦subscriptğ‘–ğ‘˜ğ¸subscriptğ‘¥subscriptğ‘–1subscriptğ‘¥subscriptğ‘–2â‹¯subscriptğ‘¥subscriptğ‘–ğ‘˜f(X\_{\ell})\equiv\sqrt{m}{\bar{S}}^{\odot k}\_{\ell}=\sum\_{(i\_{1},\ldots,i\_{k})\in E}x\_{i\_{1}}x\_{i\_{2}}\cdots x\_{i\_{k}} |  |

###### Proof.

We will follow the same approach to the proof of Theorem [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Due to the similarity of the proofs, we will omit steps here, but we will keep track of the parameters and calculations that differ.

Fix iâˆˆ[|V|]ğ‘–delimited-[]ğ‘‰i\in[|V|], and define giâ€‹(x1,â€¦,x|V|)=xiâ€‹âˆ‘eâˆˆE:iâˆˆeâˆjâˆˆe,jâ‰ ixjsubscriptğ‘”ğ‘–subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘‰subscriptğ‘¥ğ‘–subscript:ğ‘’ğ¸ğ‘–ğ‘’subscriptproductformulae-sequenceğ‘—ğ‘’ğ‘—ğ‘–subscriptğ‘¥ğ‘—g\_{i}(x\_{1},\ldots,x\_{|V|})=x\_{i}\sum\_{e\in E:i\in e}\prod\_{j\in e,j\neq i}x\_{j}.
For each coordinate â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m], flipping the sign of xisubscriptğ‘¥ğ‘–x\_{i} will change fâ€‹(Xâ„“)ğ‘“subscriptğ‘‹â„“f(X\_{\ell}) by at most âˆ‘eâˆˆE:iâˆˆeâˆjâˆˆe,jâ‰ ixjsubscript:ğ‘’ğ¸ğ‘–ğ‘’subscriptproductformulae-sequenceğ‘—ğ‘’ğ‘—ğ‘–subscriptğ‘¥ğ‘—\sum\_{e\in E:i\in e}\prod\_{j\in e,j\neq i}x\_{j}.
Lemma [36](#Thmtheorem36 "Lemma 36. â€£ 4.3.2 Bundles of Bindings of Multiple Vectors â€£ 4.3 Binding â€£ 4 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ Capacity Analysis of Vector Symbolic Architectures") gives us a high probability bound on the magnitude of âˆ‘eâˆˆE:iâˆˆeâˆjâˆˆe,jâ‰ ixjsubscript:ğ‘’ğ¸ğ‘–ğ‘’subscriptproductformulae-sequenceğ‘—ğ‘’ğ‘—ğ‘–subscriptğ‘¥ğ‘—\sum\_{e\in E:i\in e}\prod\_{j\in e,j\neq i}x\_{j}:

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[2â€‹|giâ€‹(Xâ„“)|>2â€‹(kâˆ’1)!â‹…3kâˆ’1â‹…degGâ¡(i)â‹…log(kâˆ’1)â¡(kâ€‹|E|â€‹m/Î´)]â‰¤Î´34â€‹kâ€‹|E|3â€‹m3Pr2subscriptğ‘”ğ‘–subscriptğ‘‹â„“2â‹…ğ‘˜1superscript3ğ‘˜1subscriptdegreeğºğ‘–superscriptğ‘˜1ğ‘˜ğ¸ğ‘šğ›¿superscriptğ›¿34ğ‘˜superscriptğ¸3superscriptğ‘š3\Pr\left[2|g\_{i}(X\_{\ell})|>2\sqrt{(k-1)!\cdot 3^{k-1}\cdot\deg\_{G}(i)\cdot\log^{(k-1)}(k|E|m/\delta)}\right]\leq\frac{\delta^{3}}{4k|E|^{3}m^{3}} |  |

Choosing this upper bound on the probability ensures that we obtain the same Î´â„°subscriptğ›¿â„°\delta\_{\mathcal{E}} as we do in Theorem [12](#Thmtheorem12 "Theorem 12. â€£ Bundles of bindings the JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Defining fË‡â€‹(Xâ„“)Ë‡ğ‘“subscriptğ‘‹â„“{\check{f}}(X\_{\ell}) as before, Theorem [25](#Thmtheorem25 "Theorem 25. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") says

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|fË‡â€‹(Xâ„“)âˆ’ğ”¼â€‹[fË‡â€‹(Xâ„“)]|â‰¥t]â‰¤2â€‹expâ¡(âˆ’t2k!â‹…3kâˆ’1â‹…|E|â€‹log(kâˆ’1)â¡(kâ€‹|E|â€‹m/Î´))PrË‡ğ‘“subscriptğ‘‹â„“ğ”¼delimited-[]Ë‡ğ‘“subscriptğ‘‹â„“ğ‘¡2superscriptğ‘¡2â‹…ğ‘˜superscript3ğ‘˜1ğ¸superscriptğ‘˜1ğ‘˜ğ¸ğ‘šğ›¿\Pr\left[|{\check{f}}(X\_{\ell})-{\mathbb{E}}[{\check{f}}(X\_{\ell})]|\geq t\right]\leq 2\exp\left(-\frac{t^{2}}{k!\cdot 3^{k-1}\cdot|E|\log^{(k-1)}(k|E|m/\delta)}\right) |  |

The proxy variance of fË‡â€‹(Xâ„“)âˆ’ğ”¼â€‹[fË‡â€‹(Xâ„“)]Ë‡ğ‘“subscriptğ‘‹â„“ğ”¼delimited-[]Ë‡ğ‘“subscriptğ‘‹â„“{\check{f}}(X\_{\ell})-{\mathbb{E}}[{\check{f}}(X\_{\ell})] is now

|  |  |  |
| --- | --- | --- |
|  | ÏƒfË‡2â‰¡k!â‹…3kâˆ’1â‹…|E|â€‹log(kâˆ’1)â¡(kâ€‹|E|â€‹m/Î´)superscriptsubscriptğœË‡ğ‘“2â‹…ğ‘˜superscript3ğ‘˜1ğ¸superscriptğ‘˜1ğ‘˜ğ¸ğ‘šğ›¿\sigma\_{{\check{f}}}^{2}\equiv k!\cdot 3^{k-1}\cdot|E|\log^{(k-1)}(k|E|m/\delta) |  |

Defining FË‡Ë‡ğ¹{\check{F}} and FË‡csubscriptË‡ğ¹ğ‘{\check{F}}\_{c} the same way, and choosing large enough m=Oâ€‹(Îµâˆ’2â‹…k!2â‹…32â€‹kâ‹…logk+1â¡(kâ€‹|E|/(Îµâ€‹Î´)))ğ‘šğ‘‚â‹…superscriptğœ€2superscriptğ‘˜2superscript32ğ‘˜superscriptğ‘˜1ğ‘˜ğ¸ğœ€ğ›¿m=O(\varepsilon^{-2}\cdot k!^{2}\cdot 3^{2k}\cdot\log^{k+1}(k|E|/(\varepsilon\delta))), we have

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[|FË‡câˆ’ğ”¼â€‹[FË‡c]|>Îµâ€‹|E|/2]â‰¤Î´/2PrsubscriptË‡ğ¹ğ‘ğ”¼delimited-[]subscriptË‡ğ¹ğ‘ğœ€ğ¸2ğ›¿2\Pr\left[|{\check{F}}\_{c}-{\mathbb{E}}[{\check{F}}\_{c}]|>\varepsilon|E|/2\right]\leq\delta/2 |  |

The remainder of the proof follows without changes after we fix the value of mğ‘šm.
Regarding the dependence on kğ‘˜k,

|  |  |  |
| --- | --- | --- |
|  | logâ¡(k!2â€‹32â€‹k)â‰¤logâ¡(2â€‹Ï€â€‹kâ€‹(k/e)2â€‹kâ€‹e1/6â€‹kâ€‹32â€‹k)=2â€‹kâ€‹logâ¡(3â€‹k/e)+Oâ€‹(logâ¡k)=Oâ€‹(kâ€‹logâ¡k),superscriptğ‘˜2superscript32ğ‘˜2ğœ‹ğ‘˜superscriptğ‘˜ğ‘’2ğ‘˜superscriptğ‘’16ğ‘˜superscript32ğ‘˜2ğ‘˜3ğ‘˜ğ‘’ğ‘‚ğ‘˜ğ‘‚ğ‘˜ğ‘˜\log(k!^{2}3^{2k})\leq\log(2\pi k(k/e)^{2k}e^{1/6k}3^{2k})=2k\log(3k/e)+O(\log k)=O(k\log k), |  |

using an inequality form of Stirlingâ€™s approximation. The corollary follows.
âˆ

## 5 Autocorrelation Associative Memories as Bundles of Robust Bindings

As discussed in Â§[2.3](#S2.SS3 "2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), this section provides a new analysis of Hopfield networks, and proposes a Hopfield variant that is a space-efficient VSA bundling operation.

### 5.1 Analysis of Hopfield Networks via Concentration Bounds

Our analysis is akin to that of [mceliece\_capacity\_1987], but uses concentration bounds instead of large deviation bounds holding in the limit.
The results are similar, in leading terms.

###### Theorem (Restatement of Theorem [14](#Thmtheorem14 "Theorem 14. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Given matrix Sâˆˆ{Â±1}mÃ—nğ‘†superscriptplus-or-minus1ğ‘šğ‘›S\in\{\pm 1\}^{m\times n} with uniform independent entries, jâˆˆ[n]ğ‘—delimited-[]ğ‘›j\in[n], and Î´âˆˆ(0,1]ğ›¿01\delta\in(0,1].
If yâˆˆ{0,Â±1}mğ‘¦superscript0plus-or-minus1ğ‘šy\in\{0,\pm 1\}^{m} with
yâŠ¤â€‹Sâˆ—j/â€–yâ€–â‰¥2â€‹nâ€‹logâ¡(2â€‹m/Î´)superscriptğ‘¦topsubscriptğ‘†absentğ‘—normğ‘¦2ğ‘›2ğ‘šğ›¿y^{\top}S\_{\*j}/\|y\|\geq 2\sqrt{n\log(2m/\delta)}, then with failure probability at mostÂ Î´ğ›¿\delta, signâ‰¥â¡((Sâ€‹SâŠ¤âˆ’nâ€‹Im)â€‹y)=Sâˆ—jsubscriptsignğ‘†superscriptğ‘†topğ‘›subscriptğ¼ğ‘šğ‘¦subscriptğ‘†absentğ‘—\operatorname{{\text{sign}\_{\geq}}}((SS^{\top}-nI\_{m})y)=S\_{\*j}.
Here it is assumed that the coordinates iğ‘–i at which yiâ‰ Siâ€‹jsubscriptğ‘¦ğ‘–subscriptğ‘†ğ‘–ğ‘—y\_{i}\neq S\_{ij} are chosen beforeÂ Sğ‘†S, or without knowledge of it.

Since mâ‰¥(yâŠ¤â€‹Sâˆ—j)2/â€–yâ€–1ğ‘šsuperscriptsuperscriptğ‘¦topsubscriptğ‘†absentğ‘—2subscriptnormğ‘¦1m\geq(y^{\top}S\_{\*j})^{2}/\|y\|\_{1}, a necessary condition here is that mâ‰¥4â€‹nâ€‹logâ¡(2â€‹m/Î´)ğ‘š4ğ‘›2ğ‘šğ›¿m\geq 4n\log(2m/\delta).
When y=Sâˆ—jğ‘¦subscriptğ‘†absentğ‘—y=S\_{\*j}, yâŠ¤â€‹Sâˆ—j=m=â€–yâ€–1superscriptğ‘¦topsubscriptğ‘†absentğ‘—ğ‘šsubscriptnormğ‘¦1y^{\top}S\_{\*j}=m=\|y\|\_{1}, and mâ‰¥4â€‹nâ€‹logâ¡(2â€‹m/Î´)ğ‘š4ğ‘›2ğ‘šğ›¿m\geq 4n\log(2m/\delta) suffices.
There is

|  |  |  |
| --- | --- | --- |
|  | m=(1+oâ€‹(1))â€‹4â€‹nâ€‹logâ¡(2â€‹n/Î´)â€‹asâ€‹n/Î´â†’âˆğ‘š1ğ‘œ14ğ‘›2ğ‘›ğ›¿asğ‘›ğ›¿â†’m=(1+o(1))4n\log(2n/\delta)\mathrm{\ as\ }n/\delta\rightarrow\infty |  |

such that mâ‰¥4â€‹nâ€‹logâ¡(2â€‹m/Î´)ğ‘š4ğ‘›2ğ‘šğ›¿m\geq 4n\log(2m/\delta).

###### Proof.

Let Iâˆ’jâˆˆâ„nÃ—nsubscriptğ¼ğ‘—superscriptâ„ğ‘›ğ‘›I\_{-j}\in{\mathbb{R}}^{n\times n} denote the identity matrix with its jğ‘—jâ€™th diagonal entry set to zero.
We have

|  |  |  |
| --- | --- | --- |
|  | (Sâ€‹SâŠ¤âˆ’nâ€‹Im)â€‹y=Sâˆ—jâ€‹Sâˆ—jâŠ¤â€‹yâˆ’y+(Sâ€‹Iâˆ’jâ€‹SâŠ¤âˆ’(nâˆ’1)â€‹I)â€‹y.ğ‘†superscriptğ‘†topğ‘›subscriptğ¼ğ‘šğ‘¦subscriptğ‘†absentğ‘—superscriptsubscriptğ‘†absentğ‘—topğ‘¦ğ‘¦ğ‘†subscriptğ¼ğ‘—superscriptğ‘†topğ‘›1ğ¼ğ‘¦(SS^{\top}-nI\_{m})y=S\_{\*j}S\_{\*j}^{\top}y-y+(SI\_{-j}S^{\top}-(n-1)I)y. |  |

The first coordinate of (Sâ€‹Iâˆ’jâ€‹SâŠ¤âˆ’(nâˆ’1)â€‹I)â€‹yğ‘†subscriptğ¼ğ‘—superscriptğ‘†topğ‘›1ğ¼ğ‘¦(SI\_{-j}S^{\top}-(n-1)I)y
is âˆ‘jâ€²âˆˆ[n]jâ€²â‰ jâˆ‘1<jâ€²â€²â‰¤mS1â€‹jâ€²â€‹Sjâ€²â€‹jâ€²â€²â€‹yjâ€²â€²subscript

superscriptğ‘—â€²delimited-[]ğ‘›superscriptğ‘—â€²ğ‘—subscript1superscriptğ‘—â€²â€²ğ‘šsubscriptğ‘†1superscriptğ‘—â€²subscriptğ‘†superscriptğ‘—â€²superscriptğ‘—â€²â€²subscriptğ‘¦superscriptğ‘—â€²â€²\sum\_{\begin{subarray}{c}j^{\prime}\in[n]\\
j^{\prime}\neq j\end{subarray}}\sum\_{1<j^{\prime\prime}\leq m}S\_{1j^{\prime}}S\_{j^{\prime}j^{\prime\prime}}y\_{j^{\prime\prime}},
which is a sum of at most (nâˆ’1)â€‹(â€–yâ€–1âˆ’1)â‰¤nâ€‹â€–yâ€–1ğ‘›1subscriptnormğ‘¦11ğ‘›subscriptnormğ‘¦1(n-1)(\|y\|\_{1}-1)\leq n\|y\|\_{1} independent Â±1plus-or-minus1\pm 1 values.
By TheoremÂ [29](#Thmtheorem29 "Theorem 29. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), with failure probability at most 2â€‹expâ¡(âˆ’Î±)2ğ›¼2\exp(-\alpha), this sum is bounded by
2â€‹Î±â€‹nâ€‹â€–yâ€–12ğ›¼ğ‘›subscriptnormğ‘¦1\sqrt{2\alpha n\|y\|\_{1}} in magnitude.
For Î±=logâ¡(2â€‹m/Î´)ğ›¼2ğ‘šğ›¿\alpha=\log(2m/\delta), with failure probability Î´ğ›¿\delta, every coordinate of (Sâ€‹Iâˆ’jâ€‹SâŠ¤âˆ’(nâˆ’1)â€‹I)â€‹yğ‘†subscriptğ¼ğ‘—superscriptğ‘†topğ‘›1ğ¼ğ‘¦(SI\_{-j}S^{\top}-(n-1)I)y is at most 2â€‹Î±â€‹nâ€‹â€–yâ€–12ğ›¼ğ‘›subscriptnormğ‘¦1\sqrt{2\alpha n\|y\|\_{1}}.

Assuming this bound, if
Sâˆ—jâŠ¤â€‹yâˆ’1>2â€‹Î±â€‹nâ€‹â€–yâ€–1superscriptsubscriptğ‘†absentğ‘—topğ‘¦12ğ›¼ğ‘›subscriptnormğ‘¦1S\_{\*j}^{\top}y-1>\sqrt{2\alpha n\|y\|\_{1}},
then Siâ€‹jâ€‹Sâˆ—jâŠ¤â€‹yâˆ’yisubscriptğ‘†ğ‘–ğ‘—superscriptsubscriptğ‘†absentğ‘—topğ‘¦subscriptğ‘¦ğ‘–S\_{ij}S\_{\*j}^{\top}y-y\_{i} agree in sign with Siâ€‹jsubscriptğ‘†ğ‘–ğ‘—S\_{ij}, and will exceed ((Sâ€‹Iâˆ’jâ€‹SâŠ¤âˆ’(nâˆ’1)â€‹I)â€‹y)isubscriptğ‘†subscriptğ¼ğ‘—superscriptğ‘†topğ‘›1ğ¼ğ‘¦ğ‘–((SI\_{-j}S^{\top}-(n-1)I)y)\_{i} in magnitude, for all iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m], and therefore signâ‰¥â¡(Sâ€‹SâŠ¤â€‹y)=Sâˆ—jsubscriptsignğ‘†superscriptğ‘†topğ‘¦subscriptğ‘†absentğ‘—\operatorname{{\text{sign}\_{\geq}}}(SS^{\top}y)=S\_{\*j}.
For this it is enough if Sâˆ—jâŠ¤â€‹y/â€–yâ€–1>2â€‹Î±â€‹n=2â€‹nâ€‹logâ¡(2â€‹m/Î´)superscriptsubscriptğ‘†absentğ‘—topğ‘¦subscriptnormğ‘¦12ğ›¼ğ‘›2ğ‘›2ğ‘šğ›¿S\_{\*j}^{\top}y/\sqrt{\|y\|\_{1}}>2\sqrt{\alpha n}=2\sqrt{n\log(2m/\delta)}, as claimed.
âˆ

##### Relation to VSA: bundling of bindings

Suppose mğ‘šm is even, and we can write Sâˆ—j=[xy]subscriptğ‘†absentğ‘—delimited-[]ğ‘¥ğ‘¦S\_{\*j}=\left[\begin{smallmatrix}x\\
y\end{smallmatrix}\right], for x,yâˆˆ{Â±1}m/2

ğ‘¥ğ‘¦
superscriptplus-or-minus1ğ‘š2x,y\in\{\pm 1\}^{m/2}.
Then assuming the above conditions, there is m=Oâ€‹(nâ€‹logâ¡(n/Î´))ğ‘šğ‘‚ğ‘›ğ‘›ğ›¿m=O(n\log(n/\delta)) so that the Hopfield output on input [x0]delimited-[]ğ‘¥0\left[\begin{smallmatrix}x\\
0\end{smallmatrix}\right] or [0y]delimited-[]0ğ‘¦\left[\begin{smallmatrix}0\\
y\end{smallmatrix}\right] will be Sâˆ—jsubscriptğ‘†absentğ‘—S\_{\*j}.
In this special case, the Hopfield network does a bit more than a bundle of pairwise bindings can do: it returns the other vector of a binding, without performing membership tests over a dictionary of vectors (cleanup).
This should not be entirely surprising, since
[xy]â€‹[xy]âŠ¤=[xâ€‹xâŠ¤xâ€‹yâŠ¤yâ€‹xâŠ¤yâ€‹yâŠ¤]delimited-[]ğ‘¥ğ‘¦superscriptdelimited-[]ğ‘¥ğ‘¦topdelimited-[]ğ‘¥superscriptğ‘¥topğ‘¥superscriptğ‘¦topğ‘¦superscriptğ‘¥topğ‘¦superscriptğ‘¦top\left[\begin{smallmatrix}x\\
y\end{smallmatrix}\right]\left[\begin{smallmatrix}x\\
y\end{smallmatrix}\right]^{\top}=\left[\begin{smallmatrix}xx^{\top}&xy^{\top}\\
yx^{\top}&yy^{\top}\end{smallmatrix}\right], and the diagonal entries of xâ€‹yâŠ¤ğ‘¥superscriptğ‘¦topxy^{\top} and yâ€‹xâŠ¤ğ‘¦superscriptğ‘¥topyx^{\top} form the Hadamard product vector (i.e. element-wise product vector) xâˆ˜yğ‘¥ğ‘¦x\circ y, which is the MAP-I binding of xğ‘¥x and yğ‘¦y.

Looking at the weight matrix W=âˆ‘j=1nSâˆ—jâ€‹Sâˆ—jâŠ¤ğ‘Šsuperscriptsubscriptğ‘—1ğ‘›subscriptğ‘†absentğ‘—superscriptsubscriptğ‘†absentğ‘—topW=\sum\_{j=1}^{n}S\_{\*j}S\_{\*j}^{\top}, the two particular diagonals observed above contain exactly the MAP-I bundling of pairwise bindings of MAP-I atomic vectors, of dimension equal to half the net size.
Also, the outer product xâ€‹yâŠ¤ğ‘¥superscriptğ‘¦topxy^{\top} is the binding operator for xğ‘¥x and yğ‘¦y proposed by [smolensky\_tensor\_1990], and the relation of this binding operator to the MAP-I binding as a reduced representation is well-known via [frady\_variable\_2021].

As mentioned in the introduction, much of this discussion, including the weight matrix as a sum of outer products of the input vectors, the fixed-point condition for representation, the mapping to neural networks, and reconstruction from erasures, goes back at least to [nakano\_associatron-model\_1972, kohonen\_correlation\_1972, anderson\_simple\_1972].

##### Thinning the weight matrix

By TheoremÂ [14](#Thmtheorem14 "Theorem 14. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), it suffices if â€–yâ€–1â‰¥2â€‹nâ€‹logâ¡(2â€‹m/Î´)subscriptnormğ‘¦12ğ‘›2ğ‘šğ›¿\|y\|\_{1}\geq 2n\log(2m/\delta) for the theoremâ€™s conclusion to apply, so that the Sâˆ—jsubscriptğ‘†absentğ‘—S\_{\*j} matching yğ‘¦y can be reconstructed.
That is, for diagonal matrix Vâˆˆ{0,1}mÃ—mğ‘‰superscript01ğ‘šğ‘šV\in\{0,1\}^{m\times m}, if â€–Vâ€‹yâ€–1â‰¥2â€‹nâ€‹logâ¡(2â€‹m/Î´)subscriptnormğ‘‰ğ‘¦12ğ‘›2ğ‘šğ›¿\|Vy\|\_{1}\geq 2n\log(2m/\delta) is large enough, signâ‰¥â¡(Sâ€‹SâŠ¤â€‹Vâ€‹y)=Sâˆ—jsubscriptsignğ‘†superscriptğ‘†topğ‘‰ğ‘¦subscriptğ‘†absentğ‘—\operatorname{{\text{sign}\_{\geq}}}(SS^{\top}Vy)=S\_{\*j}.
We could regard this, for given V,y

ğ‘‰ğ‘¦V,y, as signâ‰¥â¡(Wâ€‹y)subscriptsignğ‘Šğ‘¦\operatorname{{\text{sign}\_{\geq}}}(Wy) for a matrix Wâ‰¡Sâ€‹SâŠ¤â€‹Vğ‘Šğ‘†superscriptğ‘†topğ‘‰W\equiv SS^{\top}V with â€–Vâ€–F2superscriptsubscriptnormğ‘‰ğ¹2\|V\|\_{F}^{2} nonzero columns: we erase columns of Sâ€‹SâŠ¤ğ‘†superscriptğ‘†topSS^{\top}, not entries ofÂ yğ‘¦y.
That is, if nğ‘›n vectors are to be stored, but the vector dimension is fixed at larger than mâ‰«2â€‹nâ€‹logâ¡(2â€‹m/Î´)much-greater-thanğ‘š2ğ‘›2ğ‘šğ›¿m\gg 2n\log(2m/\delta), the necessary number of stored entries is smaller than m2superscriptğ‘š2m^{2}.

##### VSAs, Autocorrelation Associative Memories, and modern Hopfield nets.

A different neural network model was proposed in recent years by [krotov\_dense\_2016], sometimes called a *modern* Hopfield network, which also uses a dynamic process to produce its output.
Here the output of an iteration is more â€œpeaked;â€ for example, a version by [demircigil\_model\_2017] uses softmax when computing the next iterate.
This model has a higher capacity than classical associative memories using sums of outer products.
However, it stores all its input vectors explicitly, so that the main question is not whether the given vectors are *represented* (since they are stored), but under what circumstances the dynamic process *converges*.
The number of entries stored in this model is Î˜â€‹(mâ€‹n)Î˜ğ‘šğ‘›\Theta(mn), where (classic) associative networks store Î˜â€‹(m2)Î˜superscriptğ‘š2\Theta(m^{2}), and VSAs store Î˜â€‹(m)Î˜ğ‘š\Theta(m).
The different amounts of storage imply different capabilities:

* â€¢

  The modern Hopfield model gives a high-capacity way to do maximum inner product search on a set of vectors, using a neural network formalism.
* â€¢

  The associatron/original Hopfield model supports the reconstruction of a vector in a stored set of vectors from an erased or noisy version.
* â€¢

  VSAs support membership tests, telling us whether two given vectors are present as a bound pair in a set.

### 5.2 HopfieldÂ±plus-or-minus\pm: Autocorrelation Associative Memories as VSAs

We can also use an AAM/Hopfield model (a sum of vector outer products) to do set intersection estimation, as in VSAs.
Here we represent a bundle as the sum of outer products of a vector with itself, as in [smolensky\_tensor\_1990]. The key theorem, proven below, is the following.

###### Theorem (Restatement of Theorem [15](#Thmtheorem15 "Theorem 15. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Given Îµ,Î´âˆˆ(0,1]

ğœ€ğ›¿
01{\varepsilon},\delta\in(0,1], scaled sign matrix SÂ¯âˆˆ1mâ€‹{Â±1}mÃ—dÂ¯ğ‘†1ğ‘šsuperscriptplus-or-minus1ğ‘šğ‘‘{\bar{S}}\in\frac{1}{\sqrt{m}}\{\pm 1\}^{m\times d} with uniform independent entries, diagonal matrix Vâˆˆâ„dÃ—dğ‘‰superscriptâ„ğ‘‘ğ‘‘V\in{\mathbb{R}}^{d\times d}, and diagonal matrix Dâˆˆ{0,Â±1}dÃ—dğ·superscript0plus-or-minus1ğ‘‘ğ‘‘D\in\{0,\pm 1\}^{d\times d} with uniform independent Â±1plus-or-minus1\pm 1 diagonal entries.
There is m=O(Îµâˆ’1log(d/Î´)2)m=O({\varepsilon}^{-1}\log(d/\delta)^{2}) such that with failure probability Î´ğ›¿\delta,
â€–SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤â€–F2=(1Â±Îµ)â€‹â€–Vâ€–F2superscriptsubscriptnormÂ¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†topğ¹2plus-or-minus1ğœ€superscriptsubscriptnormğ‘‰ğ¹2\|{\bar{S}}VD{\bar{S}}^{\top}\|\_{F}^{2}=(1\pm{\varepsilon})\|V\|\_{F}^{2}.

Since SÂ¯Â¯ğ‘†{\bar{S}} is a JL projection matrix, it will, with high probability, preserve the norms of the columns ofÂ Vğ‘‰V, and multiplying by SÂ¯âŠ¤superscriptÂ¯ğ‘†top{\bar{S}}^{\top} on the right will preserve the norms of the rows of SÂ¯â€‹VÂ¯ğ‘†ğ‘‰{\bar{S}}V.
We can think of this as SÂ¯Â¯ğ‘†{\bar{S}} satisfying the JL property with respect to the operation SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤Â¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†top{\bar{S}}VD{\bar{S}}^{\top}.
The novelty here is that the dependence of mğ‘šm on Îµğœ€{\varepsilon} is Îµâˆ’1superscriptğœ€1{\varepsilon}^{-1}, not Îµâˆ’2superscriptğœ€2{\varepsilon}^{-2}; on the other hand, SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤Â¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†top{\bar{S}}VD{\bar{S}}^{\top} comprises m2superscriptğ‘š2m^{2} values, notÂ mğ‘šm.
This is yet another route to preserving the norm of a vector, stored as the diagonal of Vğ‘‰V, using the same storage and speed of computation (up to log factors) as that of simply using a larger projection matrix on one side, as in MAP-I.
In other words, we obtain a bundling operator with performance characteristics similar to those of MAP-I, but using fewer random bits.

This theorem is analogous to LemmaÂ [3](#Thmtheorem3 "Lemma 3 ([johnson_extensions_1984, achlioptas_database-friendly_2003], JL). â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
The following is analogous to CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), and can be proven in exactly the same way.
It implies in particular that for diagonal matrices X,Y

ğ‘‹ğ‘ŒX,Y representing sets, with 0/1 diagonal entries encoding element membership, the size of their intersection can be estimated accurately using their â€œHopfield netâ€ representations.

We have a direct analog of CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), stated below. Analogs of CorollaryÂ [4](#Thmtheorem4 "Corollary 4. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") and TheoremÂ [6](#Thmtheorem6 "Theorem 6. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") also follow directly; we omit the proofs.

###### Corollary 37.

Under the conditions of TheoremÂ [15](#Thmtheorem15 "Theorem 15. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") (the JL property for SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤Â¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†top{\bar{S}}VD{\bar{S}}^{\top}), for diagonal X,YâˆˆIâ€‹RdÃ—d

ğ‘‹ğ‘Œ
superscriptIRğ‘‘ğ‘‘X,Y\in\operatorname{{\mathrm{I\!R}}}^{d\times d}, there is m=O(Îµâˆ’2log(d/Î´)2)m=O({\varepsilon}^{-2}\log(d/\delta)^{2}) so that
trâ¡((SÂ¯â€‹Xâ€‹Dâ€‹SÂ¯âŠ¤)â€‹(SÂ¯â€‹Yâ€‹Dâ€‹SÂ¯âŠ¤))=trâ¡(Xâ€‹Y)Â±Ïµâ€‹â€–Xâ€–Fâ€‹â€–Yâ€–FtrÂ¯ğ‘†ğ‘‹ğ·superscriptÂ¯ğ‘†topÂ¯ğ‘†ğ‘Œğ·superscriptÂ¯ğ‘†topplus-or-minustrğ‘‹ğ‘Œitalic-Ïµsubscriptnormğ‘‹ğ¹subscriptnormğ‘Œğ¹\operatorname{tr}(({\bar{S}}XD{\bar{S}}^{\top})({\bar{S}}YD{\bar{S}}^{\top}))=\operatorname{tr}(XY)\pm\epsilon\|X\|\_{F}\|Y\|\_{F} with failure probabilityÂ Î´ğ›¿\delta.

Note that trâ¡(Xâ€‹Y)trğ‘‹ğ‘Œ\operatorname{tr}(XY) is here the Frobenius product of Xğ‘‹X and Yğ‘ŒY.
We omit the proof; it is isomorphic to the proof of CorollaryÂ [5](#Thmtheorem5 "Corollary 5. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

To prove TheoremÂ [15](#Thmtheorem15 "Theorem 15. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), we will use the Hanson-Wright inequality.
In its statement,

|  |  |  |
| --- | --- | --- |
|  | âˆ¥Xâˆ¥Ïˆ2=inf{Kâˆ£ğ”¼(exp(X2/K2)â‰¤2}\|X\|\_{\psi\_{2}}=\inf\{K\mid{\mathbb{E}}(\exp(X^{2}/K^{2})\leq 2\} |  |

is the sub-Gaussian norm of random variable Xğ‘‹X, which in our case, for a Rademacher variable, will be 1/logâ¡2121/\sqrt{\log 2}.

###### Theorem 38 (Hanson-Wright inequality, [rudelson\_hanson-wright\_2013]).

Let xâˆˆâ„dğ‘¥superscriptâ„ğ‘‘x\in\mathbb{R}^{d} be a random vector with independent entries,
ğ”¼â€‹[x]=0ğ”¼delimited-[]ğ‘¥0{\mathbb{E}}[x]=0, and â€–xiâ€–Ïˆ2â‰¤Ksubscriptnormsubscriptğ‘¥ğ‘–subscriptğœ“2ğ¾\|x\_{i}\|\_{\psi\_{2}}\leq K for some positive constant Kğ¾K.
Let Ağ´A be an nÃ—nğ‘›ğ‘›n\times n matrix.
Then for every tâ‰¥0ğ‘¡0t\geq 0,

|  |  |  |
| --- | --- | --- |
|  | Prâ¡{|xâŠ¤â€‹Aâ€‹xâˆ’ğ”¼â€‹[xâŠ¤â€‹Aâ€‹x]|>t}â‰¤2â€‹expâ¡[âˆ’câ€‹minâ¡(t2K4â€‹â€–Aâ€–F2,tK2â€‹â€–Aâ€–)],Prsuperscriptğ‘¥topğ´ğ‘¥ğ”¼delimited-[]superscriptğ‘¥topğ´ğ‘¥ğ‘¡2ğ‘superscriptğ‘¡2superscriptğ¾4superscriptsubscriptnormğ´ğ¹2ğ‘¡superscriptğ¾2normğ´\displaystyle\Pr\left\{|x^{\top}Ax-{\mathbb{E}}[x^{\top}Ax]|>t\right\}\leq 2\exp\left[-c\min\left(\frac{t^{2}}{K^{4}\|A\|\_{F}^{2}},\frac{t}{K^{2}\|A\|}\right)\right], |  |

where c is some positive constant.
In particular, t=K2câ€‹â€–Aâ€–Fâ€‹logâ¡(2/Î´)ğ‘¡superscriptğ¾2ğ‘subscriptnormğ´ğ¹2ğ›¿t=\frac{K^{2}}{c}\|A\|\_{F}\log(2/\delta) yields a failure probability bound of at mostÂ Î´ğ›¿\delta, when logâ¡(1/Î´)â‰¥c1ğ›¿ğ‘\log(1/\delta)\geq c.

###### Proof of TheoremÂ [15](#Thmtheorem15 "Theorem 15. â€£ 2.3 Hopfield Nets and HopfieldÂ± â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

Let E=SÂ¯âŠ¤â€‹SÂ¯âˆ’Iğ¸superscriptÂ¯ğ‘†topÂ¯ğ‘†ğ¼E={\bar{S}}^{\top}{\bar{S}}-I; since the diagonal entries of Eğ¸E are zero, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | â€–SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤â€–F2superscriptsubscriptnormÂ¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†topğ¹2\displaystyle\|{\bar{S}}VD{\bar{S}}^{\top}\|\_{F}^{2} | =trâ¡(SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤â€‹SÂ¯â€‹Vâ€‹Dâ€‹SÂ¯âŠ¤)=trâ¡(Vâ€‹Dâ€‹(I+E)â€‹Vâ€‹Dâ€‹(I+E))absenttrÂ¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†topÂ¯ğ‘†ğ‘‰ğ·superscriptÂ¯ğ‘†toptrğ‘‰ğ·ğ¼ğ¸ğ‘‰ğ·ğ¼ğ¸\displaystyle=\operatorname{tr}({\bar{S}}VD{\bar{S}}^{\top}{\bar{S}}VD{\bar{S}}^{\top})=\operatorname{tr}(VD(I+E)VD(I+E)) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =trâ¡(V2â€‹D2)+2â€‹trâ¡(V2â€‹D2â€‹E)+trâ¡(Vâ€‹Dâ€‹Eâ€‹Vâ€‹Dâ€‹E)absenttrsuperscriptğ‘‰2superscriptğ·22trsuperscriptğ‘‰2superscriptğ·2ğ¸trğ‘‰ğ·ğ¸ğ‘‰ğ·ğ¸\displaystyle=\operatorname{tr}(V^{2}D^{2})+2\operatorname{tr}(V^{2}D^{2}E)+\operatorname{tr}(VDEVDE) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =â€–Vâ€–F2+0+trâ¡(Vâ€‹Dâ€‹Eâ€‹Vâ€‹Dâ€‹E)absentsuperscriptsubscriptnormğ‘‰ğ¹20trğ‘‰ğ·ğ¸ğ‘‰ğ·ğ¸\displaystyle=\|V\|\_{F}^{2}+0+\operatorname{tr}(VDEVDE) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =â€–Vâ€–F2+0+âˆ‘iâˆˆ[d](Vâ€‹Dâ€‹E)iâ£âˆ—â€‹(Vâ€‹Dâ€‹E)âˆ—iabsentsuperscriptsubscriptnormğ‘‰ğ¹20subscriptğ‘–delimited-[]ğ‘‘subscriptğ‘‰ğ·ğ¸  ğ‘–subscriptğ‘‰ğ·ğ¸absentğ‘–\displaystyle=\|V\|\_{F}^{2}+0+\sum\_{i\in[d]}(VDE)\_{i\*}(VDE)\_{\*i} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =â€–Vâ€–F2+0+âˆ‘i,jâˆˆ[d]Viâ€‹iâ€‹Diâ€‹iâ€‹Eiâ€‹jâ€‹Vjâ€‹jâ€‹Djâ€‹jâ€‹Ejâ€‹iabsentsuperscriptsubscriptnormğ‘‰ğ¹20subscript  ğ‘–ğ‘— delimited-[]ğ‘‘subscriptğ‘‰ğ‘–ğ‘–subscriptğ·ğ‘–ğ‘–subscriptğ¸ğ‘–ğ‘—subscriptğ‘‰ğ‘—ğ‘—subscriptğ·ğ‘—ğ‘—subscriptğ¸ğ‘—ğ‘–\displaystyle=\|V\|\_{F}^{2}+0+\sum\_{i,j\in[d]}V\_{ii}D\_{ii}E\_{ij}V\_{jj}D\_{jj}E\_{ji} |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =â€–Vâ€–F2+bâŠ¤â€‹Vâ€‹(Eâˆ˜E)â€‹Vâ€‹b,absentsuperscriptsubscriptnormğ‘‰ğ¹2superscriptğ‘topğ‘‰ğ¸ğ¸ğ‘‰ğ‘\displaystyle=\|V\|\_{F}^{2}+b^{\top}V(E\circ E)Vb, |  | (6) |

where in the last step bâˆˆ{Â±1}dğ‘superscriptplus-or-minus1ğ‘‘b\in\{\pm 1\}^{d} comprises the diagonal entries of Dğ·D, and we use the symmetry ofÂ Eğ¸E.
The simplifications also use the fact that Vğ‘‰V and Dğ·D commute and D2superscriptğ·2D^{2} is a projection matrix.

We will apply the Hanson-Wright inequality, for which we need to bound â€–Vâ€‹(Eâˆ˜E)â€‹Vâ€–F2superscriptsubscriptnormğ‘‰ğ¸ğ¸ğ‘‰ğ¹2\|V(E\circ E)V\|\_{F}^{2}.
First, we bound the entries of Eğ¸E: each such entry is 1m1ğ‘š\frac{1}{m} times a sum of mğ‘šm independent Rademacher values, and therefore from TheoremÂ [29](#Thmtheorem29 "Theorem 29. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") is at most 1mâ€‹2â€‹logâ¡(2/Î´1)1ğ‘š22subscriptğ›¿1\frac{1}{\sqrt{m}}\sqrt{2\log(2/\delta\_{1})} with failure probability Î´1subscriptğ›¿1\delta\_{1}.
By applying a union bound to all dâ€‹(dâˆ’1)ğ‘‘ğ‘‘1d(d-1) off-diagonal entries of Eğ¸E, we have that all such entries are at most 2mâ€‹logâ¡(2â€‹d/Î´1)2ğ‘š2ğ‘‘subscriptğ›¿1\frac{2}{\sqrt{m}}\sqrt{\log(2d/\delta\_{1})} with failure probabilityÂ Î´1subscriptğ›¿1\delta\_{1}.
Assuming this event, the square of each entry is at most 4mâ€‹logâ¡(2â€‹d/Î´1)4ğ‘š2ğ‘‘subscriptğ›¿1\frac{4}{m}\log(2d/\delta\_{1}).
We have

|  |  |  |
| --- | --- | --- |
|  | â€–Vâ€‹(Eâˆ˜E)â€‹Vâ€–F2=âˆ‘i,jâˆˆ[d]Viâ€‹i2â€‹Vjâ€‹j2â€‹Eiâ€‹j4â‰¤16log(2d/Î´1)2m2â€‹âˆ‘i,jâˆˆ[d]Viâ€‹i2â€‹Vjâ€‹j2=16log(2d/Î´1)2m2â‹…â€–Vâ€–F4.\|V(E\circ E)V\|\_{F}^{2}=\sum\_{i,j\in[d]}V\_{ii}^{2}V\_{jj}^{2}E\_{ij}^{4}\leq\frac{16\log(2d/\delta\_{1})^{2}}{m^{2}}\sum\_{i,j\in[d]}V\_{ii}^{2}V\_{jj}^{2}=\frac{16\log(2d/\delta\_{1})^{2}}{m^{2}}\cdot\|V\|\_{F}^{4}. |  |

We will apply TheoremÂ [38](#Thmtheorem38 "Theorem 38 (Hanson-Wright inequality, [rudelson_hanson-wright_2013]). â€£ 5.2 HopfieldÂ±: Autocorrelation Associative Memories as VSAs â€£ 5 Autocorrelation Associative Memories as Bundles of Robust Bindings â€£ Capacity Analysis of Vector Symbolic Architectures") with xğ‘¥x and Ağ´A of the theorem mapping to bğ‘b and Vâ€‹(Eâˆ˜E)â€‹Vğ‘‰ğ¸ğ¸ğ‘‰V(E\circ E)V.
We have ğ”¼bâ€‹[bâŠ¤â€‹Vâ€‹(Eâˆ˜E)â€‹Vâ€‹b]=0subscriptğ”¼ğ‘delimited-[]superscriptğ‘topğ‘‰ğ¸ğ¸ğ‘‰ğ‘0{\mathbb{E}}\_{b}[b^{\top}V(E\circ E)Vb]=0, since off-diagonal terms with ğ”¼bâ€‹[biâ€‹bjâ€‹â€¦],iâ‰ j

subscriptğ”¼ğ‘delimited-[]subscriptğ‘ğ‘–subscriptğ‘ğ‘—â€¦ğ‘–
ğ‘—{\mathbb{E}}\_{b}[b\_{i}b\_{j}\ldots],i\neq j are zero, and the diagonal entries of Eğ¸E are zero.
The value of tğ‘¡t in the last line of TheoremÂ [38](#Thmtheorem38 "Theorem 38 (Hanson-Wright inequality, [rudelson_hanson-wright_2013]). â€£ 5.2 HopfieldÂ±: Autocorrelation Associative Memories as VSAs â€£ 5 Autocorrelation Associative Memories as Bundles of Robust Bindings â€£ Capacity Analysis of Vector Symbolic Architectures") translates here to

|  |  |  |
| --- | --- | --- |
|  | bâŠ¤â€‹Vâ€‹(Eâˆ˜E)â€‹Vâ€‹bâ‰¤clogâ¡(2)â‹…4â€‹logâ¡(2â€‹d/Î´1)mâ‹…â€–Vâ€–F2â€‹logâ¡(1/Î´2)superscriptğ‘topğ‘‰ğ¸ğ¸ğ‘‰ğ‘â‹…ğ‘242ğ‘‘subscriptğ›¿1ğ‘šsuperscriptsubscriptnormğ‘‰ğ¹21subscriptğ›¿2b^{\top}V(E\circ E)Vb\leq\frac{c}{\log(2)}\cdot\frac{4\log(2d/\delta\_{1})}{m}\cdot\|V\|\_{F}^{2}\log(1/\delta\_{2}) |  |

with failure probability Î´2subscriptğ›¿2\delta\_{2}, using â€–Xâ€–Ïˆ2=1/2subscriptnormğ‘‹subscriptğœ“212\|X\|\_{\psi\_{2}}=1/\sqrt{2}, for Xâˆ¼{Â±1}similar-toğ‘‹plus-or-minus1X\sim\{\pm 1\}.
Putting this together with ([6](#S5.E6 "In Proof of Theorem 15. â€£ 5.2 HopfieldÂ±: Autocorrelation Associative Memories as VSAs â€£ 5 Autocorrelation Associative Memories as Bundles of Robust Bindings â€£ Capacity Analysis of Vector Symbolic Architectures")), using a union bound for the events with failure probabilities Î´1subscriptğ›¿1\delta\_{1} and Î´2subscriptğ›¿2\delta\_{2}, and reducing the precise bound above to Oâ€‹()ğ‘‚

O() notation, yields the result.
âˆ

## 6 Analysis of MAP-B

We will analyze membership testing for MAP-B, for bundles (Â§[6.1](#S6.SS1 "6.1 Bundling â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures")), sequences of sets as encoded with rotations (Â§[6.2](#S6.SS2 "6.2 Rotations â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures")), and bundles of bound key-value pairs (Â§[6.3](#S6.SS3 "6.3 Binding â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures")). Here being a key-value pair means that some restrictions are placed on members of a bound pair, in particular that the keys come from a set that is disjoint from the set of values, and so there is greater independence among the relevant random variables.

Recall that the MAP-B bundling operator is signâ¡(Sâ€‹v)signğ‘†ğ‘£\operatorname{{\text{sign}}}(Sv), where Sğ‘†S is a sign matrix, Def.Â [2](#Thmtheorem2 "Definition 2. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"),
and the sign function takes a random Â±1plus-or-minus1\pm 1 value when its argument is zero.

### 6.1 Bundling

#### 6.1.1 Membership Test

We first consider testing membership in a MAP-B bundling of nğ‘›n atomic vectors.

###### Theorem (Restatement of Theorem [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

For vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d},
let x=signâ¡(Sâ€‹v)ğ‘¥signğ‘†ğ‘£x=\operatorname{{\text{sign}}}(Sv) be the MAP-B bundling of n=â€–vâ€–1ğ‘›subscriptnormğ‘£1n=\|v\|\_{1} atomic vectors.
Then for all iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m] and jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v), Prâ¡[xiâ€‹Siâ€‹j=+1]=1/2+Î˜â€‹(1/n)Prsubscriptğ‘¥ğ‘–subscriptğ‘†ğ‘–ğ‘—112Î˜1ğ‘›\Pr[x\_{i}S\_{ij}=+1]=1/2+\Theta(1/\sqrt{n}), as nâ†’âˆâ†’ğ‘›n\rightarrow\infty, and there is m=Oâ€‹(nâ€‹logâ¡(d/Î´))ğ‘šğ‘‚ğ‘›ğ‘‘ğ›¿m=O(n\log(d/\delta)) such that with failure probability Î´ğ›¿\delta,
jâˆˆ[d]ğ‘—delimited-[]ğ‘‘j\in[d] has jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) if and only if xâŠ¤â€‹Sâˆ—j=ejâŠ¤â€‹Sâ€‹signâ¡(Sâ€‹v)superscriptğ‘¥topsubscriptğ‘†absentğ‘—superscriptsubscriptğ‘’ğ‘—topğ‘†signğ‘†ğ‘£x^{\top}S\_{\*j}=e\_{j}^{\top}S\operatorname{{\text{sign}}}(Sv) has xâŠ¤â€‹Sâˆ—jâ‰¥2â€‹mâ€‹logâ¡(2â€‹d/Î´)superscriptğ‘¥topsubscriptğ‘†absentğ‘—2ğ‘š2ğ‘‘ğ›¿x^{\top}S\_{\*j}\geq\sqrt{2m\log(2d/\delta)}.

Note that MAP-B bundling is not associative, so analysis of this bundling operation is not the end of the story, as discussed in Â§[6.1.2](#S6.SS1.SSS2 "6.1.2 Dependence on Depth â€£ 6.1 Bundling â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures").

###### Proof.

We consider Sâˆ—jâŠ¤â€‹xsuperscriptsubscriptğ‘†absentğ‘—topğ‘¥S\_{\*j}^{\top}x in the two cases where jğ‘—j is, and is not, in suppâ¡(v)suppğ‘£\operatorname{{\text{supp}}}(v).
Fix some j^âˆˆsuppâ¡(v)^ğ‘—suppğ‘£\hat{j}\in\operatorname{{\text{supp}}}(v), and let a=S1â€‹j^ğ‘subscriptğ‘†1^ğ‘—a=S\_{1\hat{j}} and b=(Sâ€‹v)1âˆ’ağ‘subscriptğ‘†ğ‘£1ğ‘b=(Sv)\_{1}-a, so that x1=signâ¡(a+b)subscriptğ‘¥1signğ‘ğ‘x\_{1}=\operatorname{{\text{sign}}}(a+b), and aâ€‹signâ¡((a+b))=signâ¡(aâ€‹(a+b))ğ‘signğ‘ğ‘signğ‘ğ‘ğ‘a\operatorname{{\text{sign}}}((a+b))=\operatorname{{\text{sign}}}(a(a+b)) is a summand of Sâˆ—j^âŠ¤â€‹xsuperscriptsubscriptğ‘†absent^ğ‘—topğ‘¥S\_{\*\hat{j}}^{\top}x.
We consider the cases where nâˆ’1ğ‘›1n-1 is even vs. odd. Let â„°â„°{\mathcal{E}} denote the event signâ¡(aâ€‹(a+b))>0signğ‘ğ‘ğ‘0\operatorname{{\text{sign}}}(a(a+b))>0.

Since the nâˆ’1ğ‘›1n-1 summands of b=(Sâ€‹v)1âˆ’ağ‘subscriptğ‘†ğ‘£1ğ‘b=(Sv)\_{1}-a are i.i.d. Rademacher variables, the probability that b=0ğ‘0b=0 is, for nâˆ’1ğ‘›1n-1 even, equal to
(2â€‹pp)â€‹122â€‹p=1Ï€â€‹pâ€‹(1+Oâ€‹(1/p))=2Ï€â€‹nâ€‹(1+Oâ€‹(1/n))binomial2ğ‘ğ‘1superscript22ğ‘1ğœ‹ğ‘1ğ‘‚1ğ‘2ğœ‹ğ‘›1ğ‘‚1ğ‘›\binom{2p}{p}\frac{1}{2^{2p}}=\frac{1}{\sqrt{\pi p}}(1+O(1/p))=\sqrt{\frac{2}{\pi n}}(1+O(1/n)),
where p=(nâˆ’1)/2ğ‘ğ‘›12p=(n-1)/2, using Stirlingâ€™s approximation, or the related expression for the Catalan numbers.
For nâˆ’1ğ‘›1n-1 even, when bâ‰ 0ğ‘0b\neq 0, |b|>=2ğ‘2|b|>=2, so a+b>0ğ‘ğ‘0a+b>0, and Prâ¡[â„°|bâ‰ 0]=1/2Prconditionalâ„°ğ‘012\Pr[{\mathcal{E}}|b\neq 0]=1/2. We have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[â„°]Prâ„°\displaystyle\Pr[{\mathcal{E}}] | =Prâ¡[â„°âˆ£b=0]â€‹Prâ¡[b=0]+Prâ¡[â„°âˆ£bâ‰ 0]â€‹Prâ¡[bâ‰ 0]absentPrconditionalâ„°ğ‘0Prğ‘0Prconditionalâ„°ğ‘0Prğ‘0\displaystyle=\Pr[{\mathcal{E}}\mid b=0]\Pr[b=0]+\Pr[{\mathcal{E}}\mid b\neq 0]\Pr[b\neq 0] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Prâ¡[b=0]+12â€‹(1âˆ’Prâ¡[b=0])absentPrğ‘0121Prğ‘0\displaystyle=\Pr[b=0]+\frac{1}{2}(1-\Pr[b=0]) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =12+12â€‹2Ï€â€‹nâ€‹(1+Oâ€‹(1/n))=12+12â€‹Ï€â€‹nâ€‹(1+Oâ€‹(1/n)).absent12122ğœ‹ğ‘›1ğ‘‚1ğ‘›1212ğœ‹ğ‘›1ğ‘‚1ğ‘›\displaystyle=\frac{1}{2}+\frac{1}{2}\sqrt{\frac{2}{\pi n}}(1+O(1/n))=\frac{1}{2}+\sqrt{\frac{1}{2\pi n}}(1+O(1/n)). |  |

When nâˆ’1ğ‘›1n-1 is odd, bğ‘b cannot be zero, while

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[b=1]=Prâ¡[b=âˆ’1]=(nâˆ’1n/2âˆ’1)â€‹12nâˆ’1=n/2nâ€‹(nn/2)â€‹22n=1Ï€â€‹(n/2)â€‹(1+Oâ€‹(1/n)).Prğ‘1Prğ‘1binomialğ‘›1ğ‘›211superscript2ğ‘›1ğ‘›2ğ‘›binomialğ‘›ğ‘›22superscript2ğ‘›1ğœ‹ğ‘›21ğ‘‚1ğ‘›\Pr[b=1]=\Pr[b=-1]=\binom{n-1}{n/2-1}\frac{1}{2^{n-1}}=\frac{n/2}{n}\binom{n}{n/2}\frac{2}{2^{n}}=\frac{1}{\sqrt{\pi(n/2)}}(1+O(1/n)). |  |

Considering the rounding for the case a+b=0ğ‘ğ‘0a+b=0, we have
Prâ¡[â„°âˆ£b=Â±1]=3/2Prconditionalâ„°ğ‘plus-or-minus132\Pr[{\mathcal{E}}\mid b=\pm 1]=3/2. Therefore,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[â„°]Prâ„°\displaystyle\Pr[{\mathcal{E}}] | =32â€‹Prâ¡[b=Â±1]+12â€‹Prâ¡[bâ‰ Â±1]absent32Prğ‘plus-or-minus112Prğ‘plus-or-minus1\displaystyle=\frac{3}{2}\Pr[b=\pm 1]+\frac{1}{2}\Pr[b\neq\pm 1] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =12+Prâ¡[b=Â±1]absent12Prğ‘plus-or-minus1\displaystyle=\frac{1}{2}+\Pr[b=\pm 1] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =12+2Ï€â€‹nâ€‹(1+Oâ€‹(1/n)).absent122ğœ‹ğ‘›1ğ‘‚1ğ‘›\displaystyle=\frac{1}{2}+\sqrt{\frac{2}{\pi n}}(1+O(1/n)). |  |

So

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[x1(1)â€‹x1=1]Prsubscriptsuperscriptğ‘¥11subscriptğ‘¥11\displaystyle\Pr[x^{(1)}\_{1}x\_{1}=1] | =Prâ¡[signâ¡(aâ€‹(a+b))>0]absentPrsignğ‘ğ‘ğ‘0\displaystyle=\Pr[\operatorname{{\text{sign}}}(a(a+b))>0] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Prâ¡[â„°]â‰¥1/2+1/2â€‹Ï€â€‹nâ€‹(1+Oâ€‹(1/n))absentPrâ„°1212ğœ‹ğ‘›1ğ‘‚1ğ‘›\displaystyle=\Pr[{\mathcal{E}}]\geq 1/2+\sqrt{1/2\pi n}(1+O(1/n)) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | >1/7â€‹nâ€‹forâ€‹largeâ€‹enoughâ€‹n.absent17ğ‘›forlargeenoughğ‘›\displaystyle>1/\sqrt{7n}\mathrm{\ for\ large\ enough\ }n. |  |

This applies to all coordinates of all vectors Si,jsubscriptğ‘†

ğ‘–ğ‘—S\_{i,j} for jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v), and inspection of the expressions shows the first claim of the theorem,
Prâ¡[xiâ€‹Siâ€‹j=+1]=1/2+Î˜â€‹(1/n)Prsubscriptğ‘¥ğ‘–subscriptğ‘†ğ‘–ğ‘—112Î˜1ğ‘›\Pr[x\_{i}S\_{ij}=+1]=1/2+\Theta(1/\sqrt{n}) for such i,j

ğ‘–ğ‘—i,j.

For the remaining claim: we have that xâŠ¤â€‹Sâˆ—jsuperscriptğ‘¥topsubscriptğ‘†absentğ‘—x^{\top}S\_{\*j} for jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) is a sum of Â±1plus-or-minus1\pm 1 independent values, with +11+1 having probability 1/2+Î˜â€‹(1/n)12Î˜1ğ‘›1/2+\Theta(1/\sqrt{n}), and at least 1/2+1/7â€‹n1217ğ‘›1/2+\sqrt{1/7n}, for large enough nğ‘›n; this implies expectation at least m/7â€‹nğ‘š7ğ‘›m/\sqrt{7n}.
Hoeffdingâ€™s inequality implies that
Prâ¡[xâŠ¤â€‹Sâˆ—jâˆ’m/7â€‹n<âˆ’2â€‹mâ€‹logâ¡(2â€‹d/Î´)]â‰¤Î´/2â€‹dPrsuperscriptğ‘¥topsubscriptğ‘†absentğ‘—ğ‘š7ğ‘›2ğ‘š2ğ‘‘ğ›¿ğ›¿2ğ‘‘\Pr[x^{\top}S\_{\*j}-m/\sqrt{7n}<-\sqrt{2m\log(2d/\delta)}]\leq\delta/2d.
Now suppose jâˆ‰suppâ¡(v)ğ‘—suppğ‘£j\notin\operatorname{{\text{supp}}}(v). Then using Hoeffding again, we obtain:

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[xâŠ¤â€‹Sâˆ—j>2â€‹mâ€‹logâ¡(2â€‹d/Î´)]â‰¤Î´/2â€‹d.Prsuperscriptğ‘¥topsubscriptğ‘†absentğ‘—2ğ‘š2ğ‘‘ğ›¿ğ›¿2ğ‘‘\Pr[x^{\top}S\_{\*j}>\sqrt{2m\log(2d/\delta)}]\leq\delta/2d. |  |

Thus, there is m=Oâ€‹(nâ€‹logâ¡(d/Î´))ğ‘šğ‘‚ğ‘›ğ‘‘ğ›¿m=O(n\log(d/\delta)) such that m/7â€‹n>2â€‹2â€‹mâ€‹logâ¡(2â€‹d/Î´)ğ‘š7ğ‘›22ğ‘š2ğ‘‘ğ›¿m/\sqrt{7n}>2\sqrt{2m\log(2d/\delta)}, and therefore by a union bound for all jâˆˆ[d]ğ‘—delimited-[]ğ‘‘j\in[d], with failure probability at most Î´ğ›¿\delta,
xâŠ¤â€‹Sâˆ—j>2â€‹mâ€‹logâ¡(2â€‹d/Î´)superscriptğ‘¥topsubscriptğ‘†absentğ‘—2ğ‘š2ğ‘‘ğ›¿x^{\top}S\_{\*j}>\sqrt{2m\log(2d/\delta)} if an only if jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v).
âˆ

#### 6.1.2 Dependence on Depth

Instead of bundling a set of elements all at once, suppose instead that bundling is done as a sequence of operations. We will see that for some such sequences, with high depth, so much information is lost that accurate membership tests become impossible.

###### Lemma (Restatement of Lemma [17](#Thmtheorem17 "Lemma 17. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Given independent sign vectors x(i)âˆˆ{Â±1}m,iâˆˆ[r]formulae-sequencesuperscriptğ‘¥ğ‘–superscriptplus-or-minus1ğ‘šğ‘–delimited-[]ğ‘Ÿx^{(i)}\in\{\pm 1\}^{m},i\in[r], construct vectorÂ xğ‘¥x by setting xâ†x(1)â†ğ‘¥superscriptğ‘¥1x\leftarrow x^{(1)}, and for j=2,â€¦,rğ‘—

2â€¦ğ‘Ÿj=2,\ldots,r, setting xâ†signâ¡(x+x(j))â†ğ‘¥signğ‘¥superscriptğ‘¥ğ‘—x\leftarrow\operatorname{{\text{sign}}}(x+x^{(j)}).
Then, for â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m],

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[xâ„“(1)â€‹xâ„“=1]=1/2+1/2rPrsubscriptsuperscriptğ‘¥1â„“subscriptğ‘¥â„“1121superscript2ğ‘Ÿ\Pr[x^{(1)}\_{\ell}x\_{\ell}=1]=1/2+1/2^{r} |  |

###### Proof.

We consider x1(1)â€‹x1subscriptsuperscriptğ‘¥11subscriptğ‘¥1x^{(1)}\_{1}x\_{1}; the same analysis applies to xâ„“(1)â€‹xâ„“subscriptsuperscriptğ‘¥1â„“subscriptğ‘¥â„“x^{(1)}\_{\ell}x\_{\ell} for â„“>1â„“1\ell>1.
Let ağ‘a denote x1(1)subscriptsuperscriptğ‘¥11x^{(1)}\_{1}, and let z(j)subscriptğ‘§ğ‘—z\_{(j)} denote the value of x1subscriptğ‘¥1x\_{1} just after the assignment xâ†signâ¡(x+x(j))â†ğ‘¥signğ‘¥superscriptğ‘¥ğ‘—x\leftarrow\operatorname{{\text{sign}}}(x+x^{(j)}) in computingÂ xğ‘¥x.
Since bâ€‹signâ¡(c+e)=signâ¡(bâ€‹c+bâ€‹e)ğ‘signğ‘ğ‘’signğ‘ğ‘ğ‘ğ‘’b\operatorname{{\text{sign}}}(c+e)=\operatorname{{\text{sign}}}(bc+be) for b=Â±1ğ‘plus-or-minus1b=\pm 1, we have that

|  |  |  |
| --- | --- | --- |
|  | x1x1(1)=az(r)=sign(az(râˆ’1))+ax(r)).x\_{1}x^{(1)}\_{1}=az\_{(r)}=\operatorname{{\text{sign}}}(az\_{(r-1)})+ax^{(r)}). |  |

By induction on jğ‘—j with this base case,
az(râˆ’j))=sign(az(râˆ’(j+1)))+ax(râˆ’j))az\_{(r-j)})=\operatorname{{\text{sign}}}(az\_{(r-(j+1))})+ax^{(r-j)}), ending with aâ€‹z(1)=a2=1ğ‘subscriptğ‘§1superscriptğ‘21az\_{(1)}=a^{2}=1.
Suppose inductively on jğ‘—j (in the other direction) that aâ€‹z(j)ğ‘subscriptğ‘§ğ‘—az\_{(j)} is +11+1 with probability 1/2+1/2j121superscript2ğ‘—1/2+1/2^{j}, respectively; this is true for j=1ğ‘—1j=1, as noted.
We have
az(j)=sign(az(jâˆ’1))+ax(j))az\_{(j)}=\operatorname{{\text{sign}}}(az\_{(j-1)})+ax^{(j)}), and aâ€‹x(j)=Â±1ğ‘superscriptğ‘¥ğ‘—plus-or-minus1ax^{(j)}=\pm 1 with equal probability independent of aâ€‹z(jâˆ’1)ğ‘subscriptğ‘§ğ‘—1az\_{(j-1)}.
Analysis of the four combinations az(jâˆ’1))=Â±1,ax(j)=Â±1az\_{(j-1)})=\pm 1,ax^{(j)}=\pm 1 and their probabilities shows that the inductive step holds, that is, aâ€‹z(j+1)ğ‘subscriptğ‘§ğ‘—1az\_{(j+1)} is +11+1 with probability 1/2+1/2j+1121superscript2ğ‘—11/2+1/2^{j+1}.
In particular,
Prâ¡[x1â€‹x1(1)=aâ€‹z(r)=+1]=1/2+1/2rPrsubscriptğ‘¥1subscriptsuperscriptğ‘¥11ğ‘subscriptğ‘§ğ‘Ÿ1121superscript2ğ‘Ÿ\Pr[x\_{1}x^{(1)}\_{1}=az\_{(r)}=+1]=1/2+1/2^{r}, as claimed.
âˆ

Note that this property of xâ„“â€‹xâ„“(1)subscriptğ‘¥â„“subscriptsuperscriptğ‘¥1â„“x\_{\ell}x^{(1)}\_{\ell} does not require the x(i)superscriptğ‘¥ğ‘–x^{(i)} to be atomic vectors of theÂ VSA.
Considering such summands for xâŠ¤â€‹x(1)superscriptğ‘¥topsuperscriptğ‘¥1x^{\top}x^{(1)} leads to
ğ”¼â€‹[xâŠ¤â€‹x(1)]â‰ˆm/2rğ”¼delimited-[]superscriptğ‘¥topsuperscriptğ‘¥1ğ‘šsuperscript2ğ‘Ÿ{\mathbb{E}}[x^{\top}x^{(1)}]\approx m/2^{r}, as compared to at least m/7â€‹nğ‘š7ğ‘›m/\sqrt{7n} as in TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), with a corresponding change in mğ‘šm needed to obtain effective membership testing.
Suppose all the x(i)superscriptğ‘¥ğ‘–x^{(i)} are bundles, and xğ‘¥x is the root of a tree of bundlings of a total ofÂ nğ‘›n vectors.
Then x(1)superscriptğ‘¥1x^{(1)} is a leaf of a tree of bundling operations of depth at leastÂ rğ‘Ÿr, with possibly n=rğ‘›ğ‘Ÿn=r, when all x(i)superscriptğ‘¥ğ‘–x^{(i)} involved with x(1)superscriptğ‘¥1x^{(1)} are atomic; n=2rğ‘›superscript2ğ‘Ÿn=2^{r}, when xğ‘¥x is the root of a complete binary tree of depth rğ‘Ÿr; or n>2rğ‘›superscript2ğ‘Ÿn>2^{r}, when x(1)superscriptğ‘¥1x^{(1)} is not at the maximum depth, or when a single bundling operation involves more than two vectors.
Thus for membership testing to be effective, mğ‘šmÂ might need to be at large as 4nsuperscript4ğ‘›4^{n}, or as small asÂ O~â€‹(n)~ğ‘‚ğ‘›\tilde{O}(n), depending on operation depth in computing xğ‘¥x.

The following lemma puts x(1)superscriptğ‘¥1x^{(1)} in a more general bundle.

###### Corollary 39.

Given independent sign vectors x(i)âˆˆ{Â±1}msuperscriptğ‘¥ğ‘–superscriptplus-or-minus1ğ‘šx^{(i)}\in\{\pm 1\}^{m} for iâˆˆ[nâ€²]ğ‘–delimited-[]superscriptğ‘›â€²i\in[n^{\prime}] and y(j)âˆˆ{Â±1}msuperscriptğ‘¦ğ‘—superscriptplus-or-minus1ğ‘šy^{(j)}\in\{\pm 1\}^{m} for jâˆˆ[r]ğ‘—delimited-[]ğ‘Ÿj\in[r], construct vectorÂ xğ‘¥x by setting xâ†signâ¡(âˆ‘iâˆˆnâ€²x(i))â†ğ‘¥signsubscriptğ‘–superscriptğ‘›â€²superscriptğ‘¥ğ‘–x\leftarrow\operatorname{{\text{sign}}}(\sum\_{i\in n^{\prime}}x^{(i)}), and then
for j=1,â€¦,rğ‘—

1â€¦ğ‘Ÿj=1,\ldots,r, setting xâ†signâ¡(x+y(j))â†ğ‘¥signğ‘¥superscriptğ‘¦ğ‘—x\leftarrow\operatorname{{\text{sign}}}(x+y^{(j)}).
Then, for â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m],

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[xâ„“(1)â€‹xâ„“=1]=12+12râ€‹Î˜â€‹(1n)Prsubscriptsuperscriptğ‘¥1â„“subscriptğ‘¥â„“1121superscript2ğ‘ŸÎ˜1ğ‘›\Pr[x^{(1)}\_{\ell}x\_{\ell}=1]=\frac{1}{2}+\frac{1}{2^{r}}\Theta\left(\frac{1}{\sqrt{n}}\right) |  |

###### Proof.

Combine the analysis of TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") with the lemma just above.

âˆ

Note that this corollary covers any sequence of operations yielding a vector of the form x(1)âŠ•ydirect-sumsuperscriptğ‘¥1ğ‘¦x^{(1)}\oplus y, that is x(1)superscriptğ‘¥1x^{(1)} bundled with yğ‘¦y, regardless of how yğ‘¦y was computed in the MAP-B algebra.

#### 6.1.3 Testing for Empty Intersection

In this section, rather than estimating set intersection size, we aim for bounds on mğ‘šm so that we can distinguish between nonempty and empty set intersections.
Estimating the set intersection *size* will depend on a rather complicated convolution of Rademacher random variable; the question of distinguishing emptiness has a much cleaner analysis.

Throughout this section, we assume that the elements comprising Xğ‘‹X and Yğ‘ŒY were all bundled during the same operation.
In other words, they correspond to a depth-1 bundling tree, in the language of the previous section.

###### Lemma 40.

Let X,YâŠ†[d]

ğ‘‹ğ‘Œ
delimited-[]ğ‘‘X,Y\subseteq[d], and use xğ‘¥x and yğ‘¦y to denote their respective MAP-B vectors.
If we choose dimension mâ‰¥Î©â€‹(logâ¡(1/Î´)â‹…|X|â€‹|Y|)ğ‘šÎ©â‹…1ğ›¿ğ‘‹ğ‘Œm\geq\Omega\left(\log(1/\delta)\cdot|X||Y|\right), we can distinguish between the cases |Xâˆ©Y|=0ğ‘‹ğ‘Œ0|X\cap Y|=0 and |Xâˆ©Y|â‰¥1ğ‘‹ğ‘Œ1|X\cap Y|\geq 1, using the criterion of whether xTâ€‹ysuperscriptğ‘¥ğ‘‡ğ‘¦x^{T}y is smaller or greater than 2â€‹mâ€‹logâ¡(2/Î´)2ğ‘š2ğ›¿\sqrt{2m\log(2/\delta)}.

###### Proof.

Let v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d} be characteristic vectors for the sets X,YâŠ†[d]

ğ‘‹ğ‘Œ
delimited-[]ğ‘‘X,Y\subseteq[d].
First, if |Xâˆ©Y|=0ğ‘‹ğ‘Œ0|X\cap Y|=0, their MAP-B bundles x=signâ¡(Sâ€‹v)ğ‘¥signğ‘†ğ‘£x=\operatorname{{\text{sign}}}(Sv) and y=signâ¡(Sâ€‹w)ğ‘¦signğ‘†ğ‘¤y=\operatorname{{\text{sign}}}(Sw) are independent, and for any coordinate â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m]:

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[xâ„“â€‹yâ„“]=Prâ¡[xâ„“â€‹yâ„“=1]âˆ’Prâ¡[xâ„“â€‹yâ„“=âˆ’1]=0ğ”¼delimited-[]subscriptğ‘¥â„“subscriptğ‘¦â„“Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1Prsubscriptğ‘¥â„“subscriptğ‘¦â„“10{\mathbb{E}}[x\_{\ell}y\_{\ell}]=\Pr[x\_{\ell}y\_{\ell}=1]-\Pr[x\_{\ell}y\_{\ell}=-1]=0 |  |

Using Theorem [29](#Thmtheorem29 "Theorem 29. â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), we conclude that with probability 1âˆ’Î´21ğ›¿21-\frac{\delta}{2}, we satisfy xâŠ¤â€‹yâ‰¤2â€‹logâ¡(2/Î´)â‹…msuperscriptğ‘¥topğ‘¦â‹…22ğ›¿ğ‘šx^{\top}y\leq\sqrt{2\log(2/\delta)\cdot m}.

Now, suppose |Xâˆ©Y|=1ğ‘‹ğ‘Œ1|X\cap Y|=1.
Then, we can use eâˆ—superscriptğ‘’e^{\*} to denote the standard basis vector that represents the element in their intersection.
Let x=signâ¡(Sâ€‹v)ğ‘¥signğ‘†ğ‘£x=\operatorname{{\text{sign}}}(Sv) and y=signâ¡(Sâ€‹w)ğ‘¦signğ‘†ğ‘¤y=\operatorname{{\text{sign}}}(Sw) be the MAP-B bundles representing Xğ‘‹X and Yğ‘ŒY.
(Here, Sğ‘†S is a random sign matrix; see Definition [2](#Thmtheorem2 "Definition 2. â€£ Bundling and Set Intersection â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").)

Since all coordinates within xğ‘¥x are independent of each other (and likewise for yğ‘¦y), it suffices to understand the distribution of a single coordinate.
Fix â„“âˆˆ[m]â„“delimited-[]ğ‘š\ell\in[m]. We will study the quantities Prâ¡[xâ„“â€‹yâ„“=1]Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1\Pr[x\_{\ell}y\_{\ell}=1] and Prâ¡[xâ„“â€‹yâ„“=âˆ’1]Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1\Pr[x\_{\ell}y\_{\ell}=-1] to eventually obtain a concentration bound for xâŠ¤â€‹ysuperscriptğ‘¥topğ‘¦x^{\top}y.

Let Z(X)=(Sâ€‹eâˆ—)â„“+âˆ‘iâˆˆXâˆ–YZi(X)superscriptğ‘ğ‘‹subscriptğ‘†superscriptğ‘’â„“subscriptğ‘–ğ‘‹ğ‘Œsuperscriptsubscriptğ‘ğ‘–ğ‘‹Z^{(X)}=(Se^{\*})\_{\ell}+\sum\_{i\in X\setminus Y}Z\_{i}^{(X)}, where the {Zi(X)}i=1msuperscriptsubscriptsuperscriptsubscriptğ‘ğ‘–ğ‘‹ğ‘–1ğ‘š\{Z\_{i}^{(X)}\}\_{i=1}^{m} are independent Rademacher variables coming from the â„“â„“\ell-th coordinates of the atomic vectors that were bundled to form Xğ‘‹X.
Define Z(Y)superscriptğ‘ğ‘ŒZ^{(Y)} similarly for Yğ‘ŒY, and let Xâ€²=Z(X)âˆ’(Sâ€‹eâˆ—)â„“superscriptğ‘‹â€²superscriptğ‘ğ‘‹subscriptğ‘†superscriptğ‘’â„“X^{\prime}=Z^{(X)}-(Se^{\*})\_{\ell} and Yâ€²=Z(Y)âˆ’(Sâ€‹eâˆ—)â„“superscriptğ‘Œâ€²superscriptğ‘ğ‘Œsubscriptğ‘†superscriptğ‘’â„“Y^{\prime}=Z^{(Y)}-(Se^{\*})\_{\ell}.

First, assume |Xâˆ–Y|ğ‘‹ğ‘Œ|X\setminus Y| and |Yâˆ–X|ğ‘Œğ‘‹|Y\setminus X| are both even. The other cases follow similarly; the only change to track is that when |Xâˆ–Y|ğ‘‹ğ‘Œ|X\setminus Y| (or |Yâˆ–X|ğ‘Œğ‘‹|Y\setminus X|) is odd, Z(X)superscriptğ‘ğ‘‹Z^{(X)} (resp. Z(Y)superscriptğ‘ğ‘ŒZ^{(Y)}) could be 00, and we have a 1212\frac{1}{2} chance of Z(X)superscriptğ‘ğ‘‹Z^{(X)} (resp. Z(Y)superscriptğ‘ğ‘ŒZ^{(Y)}) being positive and a 1212\frac{1}{2} chance it is negative.

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[xâ„“=yâ„“=1]Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1\displaystyle\Pr[x\_{\ell}=y\_{\ell}=1] | =Prâ¡[Z(X)=Z(Y)=1]absentPrsuperscriptğ‘ğ‘‹superscriptğ‘ğ‘Œ1\displaystyle=\Pr[Z^{(X)}=Z^{(Y)}=1] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Prâ¡[Xâ€²â‰¥0,Yâ€²â‰¥0]â‹…Prâ¡[(Sâ€‹eâˆ—)â„“=1]+Prâ¡[Xâ€²â‰¤1,Yâ€²â‰¤1]â‹…Prâ¡[(Sâ€‹eâˆ—)â„“=âˆ’1]absentâ‹…Prsuperscriptğ‘‹â€²0superscriptğ‘Œâ€²0Prsubscriptğ‘†superscriptğ‘’â„“1â‹…Prsuperscriptğ‘‹â€²1superscriptğ‘Œâ€²1Prsubscriptğ‘†superscriptğ‘’â„“1\displaystyle=\Pr[X^{\prime}\geq 0,Y^{\prime}\geq 0]\cdot\Pr[(Se^{\*})\_{\ell}=1]+\Pr[X^{\prime}\leq 1,Y^{\prime}\leq 1]\cdot\Pr[(Se^{\*})\_{\ell}=-1] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =Prâ¡[Xâ€²â‰¥0]â‹…Prâ¡[Yâ€²â‰¥0]absentâ‹…Prsuperscriptğ‘‹â€²0Prsuperscriptğ‘Œâ€²0\displaystyle=\Pr[X^{\prime}\geq 0]\cdot\Pr[Y^{\prime}\geq 0] |  |

We obtain the following equations similarly, again when |Xâˆ–Y|ğ‘‹ğ‘Œ|X\setminus Y| and |Yâˆ–X|ğ‘Œğ‘‹|Y\setminus X| are even.

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[xâ„“=1,yâ„“=âˆ’1]Prsubscriptğ‘¥â„“1subscriptğ‘¦â„“1\displaystyle\Pr[x\_{\ell}=1,y\_{\ell}=-1] | =Prâ¡[Xâ€²â‰¥0]â‹…Prâ¡[Yâ€²<0]absentâ‹…Prsuperscriptğ‘‹â€²0Prsuperscriptğ‘Œâ€²0\displaystyle=\Pr[X^{\prime}\geq 0]\cdot\Pr[Y^{\prime}<0] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[xâ„“=âˆ’1,yâ„“=1]Prsubscriptğ‘¥â„“1subscriptğ‘¦â„“1\displaystyle\Pr[x\_{\ell}=-1,y\_{\ell}=1] | =Prâ¡[Xâ€²<0]â‹…Prâ¡[Yâ€²â‰¥0]absentâ‹…Prsuperscriptğ‘‹â€²0Prsuperscriptğ‘Œâ€²0\displaystyle=\Pr[X^{\prime}<0]\cdot\Pr[Y^{\prime}\geq 0] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[xâ„“=yâ„“=âˆ’1]Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1\displaystyle\Pr[x\_{\ell}=y\_{\ell}=-1] | =Prâ¡[Xâ€²<0]â‹…Prâ¡[Yâ€²<0]absentâ‹…Prsuperscriptğ‘‹â€²0Prsuperscriptğ‘Œâ€²0\displaystyle=\Pr[X^{\prime}<0]\cdot\Pr[Y^{\prime}<0] |  |

Combining these terms, the quantity Prâ¡[xâ„“â€‹yâ„“=1]âˆ’Prâ¡[xâ„“â€‹yâ„“=âˆ’1]Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1\Pr[x\_{\ell}y\_{\ell}=1]-\Pr[x\_{\ell}y\_{\ell}=-1] is equal to:

|  |  |  |  |
| --- | --- | --- | --- |
|  | (Prâ¡[Xâ€²â‰¥0]âˆ’Prâ¡[Xâ€²<0])â‹…(Prâ¡[Yâ€²â‰¥0]âˆ’Prâ¡[Yâ€²<0])=Prâ¡[Xâ€²=0]â‹…Prâ¡[Yâ€²=0]â‹…Prsuperscriptğ‘‹â€²0Prsuperscriptğ‘‹â€²0Prsuperscriptğ‘Œâ€²0Prsuperscriptğ‘Œâ€²0â‹…Prsuperscriptğ‘‹â€²0Prsuperscriptğ‘Œâ€²0\displaystyle\left(\Pr[X^{\prime}\geq 0]-\Pr[X^{\prime}<0]\right)\cdot\left(\Pr[Y^{\prime}\geq 0]-\Pr[Y^{\prime}<0]\right)=\Pr[X^{\prime}=0]\cdot\Pr[Y^{\prime}=0] |  | (7) |

Again using the fact that (2â€‹pp)â€‹122â€‹p=1Ï€â€‹pâ€‹(1+Oâ€‹(1/p))=2Ï€â€‹nâ€‹(1+Oâ€‹(1/n))binomial2ğ‘ğ‘1superscript22ğ‘1ğœ‹ğ‘1ğ‘‚1ğ‘2ğœ‹ğ‘›1ğ‘‚1ğ‘›\binom{2p}{p}\frac{1}{2^{2p}}=\frac{1}{\sqrt{\pi p}}(1+O(1/p))=\sqrt{\frac{2}{\pi n}}(1+O(1/n)) (which was also used in the membership test), we have Prâ¡[xâ„“â€‹yâ„“=1]âˆ’Prâ¡[xâ„“â€‹yâ„“=âˆ’1]â‰¥Î©â€‹(1|X|â‹…|Y|)Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1Prsubscriptğ‘¥â„“subscriptğ‘¦â„“1Î©1â‹…ğ‘‹ğ‘Œ\Pr[x\_{\ell}y\_{\ell}=1]-\Pr[x\_{\ell}y\_{\ell}=-1]\geq\Omega\left(\frac{1}{\sqrt{|X|\cdot|Y|}}\right).

Define pâ‰¡Câ€²â‹…1|X|â‹…|Y|ğ‘â‹…superscriptğ¶â€²1â‹…ğ‘‹ğ‘Œp\equiv C^{\prime}\cdot\frac{1}{\sqrt{|X|\cdot|Y|}}, so Prâ¡[xâ„“â€‹yâ„“=1]â‰¥1+p2Prsubscriptğ‘¥â„“subscriptğ‘¦â„“11ğ‘2\Pr[x\_{\ell}y\_{\ell}=1]\geq\frac{1+p}{2}.
Applying the Chernoff bound for a sum of mğ‘šm Rademachers, we have:

|  |  |  |
| --- | --- | --- |
|  | Pr[(xâŠ¤yâ‰¥m2+pâ€‹m2âˆ’2â€‹logâ¡(2/Î´)â‹…m]â‰¥1âˆ’Î´2\displaystyle\Pr\left[(x^{\top}y\geq\frac{m}{2}+\frac{pm}{2}-\sqrt{2\log(2/\delta)\cdot m}\right]\geq 1-\frac{\delta}{2} |  |

In order to distinguish between the two cases, we require pâ€‹m2â‰¥2â€‹2â€‹logâ¡(2/Î´)â‹…mğ‘ğ‘š22â‹…22ğ›¿ğ‘š\frac{pm}{2}\geq 2\sqrt{2\log(2/\delta)\cdot m}, so we need to choose mâ‰¥Î©â€‹(logâ¡(2/Î´)p2)ğ‘šÎ©2ğ›¿superscriptğ‘2m\geq\Omega\left(\frac{\log(2/\delta)}{p^{2}}\right).
âˆ

###### Remark 41.

If we have |X|=nğ‘‹ğ‘›|X|=n and |Y|=1ğ‘Œ1|Y|=1, and enforce a failure probability of Î´dğ›¿ğ‘‘\frac{\delta}{d} (so that we can union bound over all atomic vectors that represent [d]delimited-[]ğ‘‘[d]), we recover the result of Lemma [6.1](#S6.SS1 "6.1 Bundling â€£ 6 Analysis of MAP-B â€£ Capacity Analysis of Vector Symbolic Architectures").

### 6.2 Rotations

Here we consider membership testing, leveraging TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures") in a simple way.

###### Theorem (Restatement of Theorem [18](#Thmtheorem18 "Theorem 18. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Given a sign matrix SâˆˆIâ€‹RmÃ—dğ‘†superscriptIRğ‘šğ‘‘S\in\operatorname{{\mathrm{I\!R}}}^{m\times d} and rotation matrix RâˆˆIâ€‹RmÃ—mğ‘…superscriptIRğ‘šğ‘šR\in\operatorname{{\mathrm{I\!R}}}^{m\times m}, and integer length Lğ¿L.
Recall (Def.Â [8](#Thmtheorem8 "Definition 8. â€£ Rotations via JL property. â€£ 2.2 Analysis of MAP-I Using Johnson-Lindenstrauss â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")) that SR,Lâ‰¡[Sâ€‹Râ€‹Sâ€‹R2â€‹Sâ€‹â€¦â€‹RLâˆ’1â€‹S]subscriptğ‘†

ğ‘…ğ¿delimited-[]ğ‘†ğ‘…ğ‘†superscriptğ‘…2ğ‘†â€¦superscriptğ‘…ğ¿1ğ‘†S\_{R,L}\equiv[S\;RS\;R^{2}S\;\ldots R^{L-1}S].
For a sequence of dğ‘‘d-vectors v(0),v(1),â€¦â€‹v(Lâˆ’1)âˆˆ{0,1}d

subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1
superscript01ğ‘‘v\_{(0)},v\_{(1)},\ldots v\_{(L-1)}\in\{0,1\}^{d},
let vâ‰¡[v(0)â€‹v(1)â€‹â€¦â€‹v(Lâˆ’1)]ğ‘£delimited-[]subscriptğ‘£0subscriptğ‘£1â€¦subscriptğ‘£ğ¿1v\equiv[v\_{(0)}\;v\_{(1)}\;\ldots v\_{(L-1)}], let x=signâ¡(SR,Lâ€‹v)ğ‘¥signsubscriptğ‘†

ğ‘…ğ¿ğ‘£x=\operatorname{{\text{sign}}}(S\_{R,L}v), and let n=â€–vâ€–1ğ‘›subscriptnormğ‘£1n=\|v\|\_{1}.
Then there is m=Oâ€‹(Lâ€‹nâ€‹logâ¡(Lâ€‹d/Î´))ğ‘šğ‘‚ğ¿ğ‘›ğ¿ğ‘‘ğ›¿m=O(Ln\log(Ld/\delta)) such that with failure probability at most Î´ğ›¿\delta,
jâˆˆ[Lâ€‹d]ğ‘—delimited-[]ğ¿ğ‘‘j\in[Ld] has jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) if and only if xâŠ¤â€‹Sâˆ—,j%dâ‰¥2â€‹mâ€‹logâ¡(Lâ€‹d/Î´)x^{\top}S\_{\*,j\_{{\scriptscriptstyle\%}d}}\geq 2\sqrt{m\log(Ld/\delta)},
where j%dâ‰¡1+(jâˆ’1)moddj\_{{\scriptscriptstyle\%}d}\equiv 1+(j-1)\mod d.

###### Proof.

Consider

|  |  |  |
| --- | --- | --- |
|  | xâŠ¤â€‹Sâˆ—,j%d=âˆ‘iâˆˆ[m]xiâ€‹Si,j%d=âˆ‘iâˆˆ[m]Si,j%dâ€‹(SR,L)i,âˆ—â€‹v=1+âˆ‘iâˆˆ[m]Si,j%dâ€‹((SR,L)i,âˆ—â€‹vâˆ’Si,j%d).x^{\top}S\_{\*,j\_{{\scriptscriptstyle\%}d}}=\sum\_{i\in[m]}x\_{i}S\_{i,j\_{{\scriptscriptstyle\%}d}}=\sum\_{i\in[m]}S\_{i,j\_{{\scriptscriptstyle\%}d}}(S\_{R,L})\_{i,\*}v=1+\sum\_{i\in[m]}S\_{i,j\_{{\scriptscriptstyle\%}d}}((S\_{R,L})\_{i,\*}v-S\_{i,j\_{{\scriptscriptstyle\%}d}}). |  |

The random variables of Sğ‘†S that appear in Si,j%dâ€‹((SR,L)i,âˆ—â€‹vâˆ’Si,j%d)S\_{i,j\_{{\scriptscriptstyle\%}d}}((S\_{R,L})\_{i,\*}v-S\_{i,j\_{{\scriptscriptstyle\%}d}})
cannot appear in

|  |  |  |
| --- | --- | --- |
|  | Si+L,j%dâ€‹((SR,L)i+L,âˆ—â€‹vâˆ’Si+L,j%d),S\_{i+L,j\_{{\scriptscriptstyle\%}d}}((S\_{R,L})\_{i+L,\*}v-S\_{i+L,j\_{{\scriptscriptstyle\%}d}}), |  |

since the appearances of a given Si,jsubscriptğ‘†

ğ‘–ğ‘—S\_{i,j} due to shifting in SR,Lsubscriptğ‘†

ğ‘…ğ¿S\_{R,L} only span Lğ¿L rows.
That is, there are at most Lğ¿L blocks of at least (m/L)âˆ’1ğ‘šğ¿1(m/L)-1 rows such that each block can be analyzed as in TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
We obtain, for a given block of rows, and after taking into account that only (m/L)âˆ’1ğ‘šğ¿1(m/L)-1 rows are in a block, that there is m=Oâ€‹(Lâ€‹nâ€‹logâ¡(d/Î´))ğ‘šğ‘‚ğ¿ğ‘›ğ‘‘ğ›¿m=O(Ln\log(d/\delta)) such that with failure probability Î´ğ›¿\delta, jâˆˆ[d]ğ‘—delimited-[]ğ‘‘j\in[d] has jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) if and only if the vectors x~~ğ‘¥\tilde{x} and S~âˆ—jsubscript~ğ‘†absentğ‘—\tilde{S}\_{\*j} corresponding to the block of rows have x~âŠ¤â€‹S~âˆ—jâ‰¥2â€‹(m/L)â€‹logâ¡(d/Î´)superscript~ğ‘¥topsubscript~ğ‘†absentğ‘—2ğ‘šğ¿ğ‘‘ğ›¿\tilde{x}^{\top}\tilde{S}\_{\*j}\geq 2\sqrt{(m/L)\log(d/\delta)}.
By requiring failure probability at most Î´/Lğ›¿ğ¿\delta/L, satisfied by m=Oâ€‹(Lâ€‹nâ€‹logâ¡(dâ€‹L/Î´))ğ‘šğ‘‚ğ¿ğ‘›ğ‘‘ğ¿ğ›¿m=O(Ln\log(dL/\delta)),
the result follows.
âˆ

### 6.3 Binding

Binding is done in MAP-B the same as in MAP-I, namely, as coordinate-wise product.
Here we also consider membership test in a bundle of bindings, where again we assume that the bundling is done in one step, that is, a sum over the integers followed by the signsign\operatorname{{\text{sign}}} function.

#### 6.3.1 Membership in Key-Value Pairs

We will show the following.

###### Theorem (Restatement of Theorem [20](#Thmtheorem20 "Theorem 20. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Let vâˆˆ{0,1}(d2)ğ‘£superscript01binomialğ‘‘2v\in\{0,1\}^{\binom{d}{2}} be such that x=signâ¡(SâŠ™2â€‹v)ğ‘¥signsuperscriptğ‘†direct-productabsent2ğ‘£x=\operatorname{{\text{sign}}}(S^{\odot 2}v) is a bundle of key-value pairs, as in Def.Â [19](#Thmtheorem19 "Definition 19. â€£ Rotations and Bundles of Bindings â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
Let n=â€–vâ€–1ğ‘›subscriptnormğ‘£1n=\|v\|\_{1}.
Then there is m=Oâ€‹(nâ€‹logâ¡(d/Î´))ğ‘šğ‘‚ğ‘›ğ‘‘ğ›¿m=O(n\log(d/\delta)) such that with failure probability at most Î´ğ›¿\delta, jâˆˆ[(dk)]ğ‘—delimited-[]binomialğ‘‘ğ‘˜j\in[\binom{d}{k}] has jâˆˆsuppâ¡(v)ğ‘—suppğ‘£j\in\operatorname{{\text{supp}}}(v) if and only if xâŠ¤â€‹Sâˆ—jâŠ™2â‰¥2â€‹mâ€‹logâ¡(d/Î´)superscriptğ‘¥topsubscriptsuperscriptğ‘†direct-productabsent2absentğ‘—2ğ‘šğ‘‘ğ›¿x^{\top}S^{\odot 2}\_{\*j}\geq 2\sqrt{m\log(d/\delta)}.

The conclusion of the theorem is much the same as that of TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").
This is not a coincidence: the analysis of key-value pairs reduces to the same setting as that earlier lemma.

###### Proof.

For jâˆˆ[(d2)]ğ‘—delimited-[]binomialğ‘‘2j\in[\binom{d}{2}], let wâ€‹(j)âˆˆW,qâ€‹(j)âˆˆQformulae-sequenceğ‘¤ğ‘—ğ‘Šğ‘ğ‘—ğ‘„w(j)\in W,q(j)\in Q be the indices such that Sâˆ—,jâŠ™2=Sâˆ—,wâ€‹(j)âˆ˜Sâˆ—,qâ€‹(j)subscriptsuperscriptğ‘†direct-productabsent2

ğ‘—subscriptğ‘†

ğ‘¤ğ‘—subscriptğ‘†

ğ‘ğ‘—S^{\odot 2}\_{\*,j}=S\_{\*,w(j)}\circ S\_{\*,q(j)}.
Let j^âˆˆsuppâ¡(v)^ğ‘—suppğ‘£\hat{j}\in\operatorname{{\text{supp}}}(v). We have signâ¡(xâŠ¤â€‹Sâˆ—j^âŠ™2)=signâ¡(1+(SâŠ™2â€‹vâˆ’Sâˆ—,j^âŠ™2)âŠ¤â€‹Sâˆ—j^âŠ™2)signsuperscriptğ‘¥topsubscriptsuperscriptğ‘†direct-productabsent2absent^ğ‘—sign1superscriptsuperscriptğ‘†direct-productabsent2ğ‘£subscriptsuperscriptğ‘†direct-productabsent2

^ğ‘—topsubscriptsuperscriptğ‘†direct-productabsent2absent^ğ‘—\operatorname{{\text{sign}}}(x^{\top}S^{\odot 2}\_{\*\hat{j}})=\operatorname{{\text{sign}}}(1+(S^{\odot 2}v-S^{\odot 2}\_{\*,\hat{j}})^{\top}S^{\odot 2}\_{\*\hat{j}}), and

|  |  |  |
| --- | --- | --- |
|  | SâŠ™2â€‹vâˆ’Sâˆ—,j^âŠ™2=âˆ‘jâ‰ j^Sâˆ—,qâ€‹(j)âˆ˜Sâˆ—,wâ€‹(j).superscriptğ‘†direct-productabsent2ğ‘£subscriptsuperscriptğ‘†direct-productabsent2  ^ğ‘—subscriptğ‘—^ğ‘—subscriptğ‘†  ğ‘ğ‘—subscriptğ‘†  ğ‘¤ğ‘—S^{\odot 2}v-S^{\odot 2}\_{\*,\hat{j}}=\sum\_{j\neq\hat{j}}S\_{\*,q(j)}\circ S\_{\*,w(j)}. |  |

Since each Sâˆ—,qâ€‹(j)subscriptğ‘†

ğ‘ğ‘—S\_{\*,q(j)} appears only once in the sum, the summands are independent sign vectors.
(Whatever the relations among the wâ€‹(j)ğ‘¤ğ‘—w(j).)
So xâŠ¤â€‹Sâˆ—,j^âŠ™2superscriptğ‘¥topsubscriptsuperscriptğ‘†direct-productabsent2

^ğ‘—x^{\top}S^{\odot 2}\_{\*,\hat{j}} satisfies the same conditions as does the same expression in the proof of TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), as does xâŠ¤â€‹Sâˆ—,jâ€²âŠ™2superscriptğ‘¥topsubscriptsuperscriptğ‘†direct-productabsent2

superscriptğ‘—â€²x^{\top}S^{\odot 2}\_{\*,j^{\prime}} for jâ€²âˆ‰suppâ¡(v)superscriptğ‘—â€²suppğ‘£j^{\prime}\notin\operatorname{{\text{supp}}}(v).
Therefore the same conditions on mğ‘šm imply the same results on failure probability as in TheoremÂ [16](#Thmtheorem16 "Theorem 16. â€£ 2.4 Analysis of MAP-B â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), and the lemma follows.
âˆ

## 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration

We will analyze the VSA dimension needed for reliably estimating the size of the intersection of sets represented by Bloom filters (Â§[7.1](#S7.SS1 "7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) and Counting Bloom filters (Â§[7.2](#S7.SS2 "7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")).
In the latter, we actually consider a generalization to weighted sets.

### 7.1 Bloom Filters

In the VSA model described in this section, the atomic vectors are xâˆˆ{0,1}mğ‘¥superscript01ğ‘šx\in\{0,1\}^{m} where for some kğ‘˜k, â€–xâ€–1â‰¤ksubscriptnormğ‘¥1ğ‘˜\|x\|\_{1}\leq k, with the nonzero entries chosen randomly.
As discussed in Def.Â [21](#Thmtheorem21 "Definition 21. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures"), an atomic vector Bâˆ—jsubscriptğµabsentğ‘—B\_{\*j} is created by performing kğ‘˜k trials, in each trial picking iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m] uniformly at random and setting Biâ€‹jâ†1â†subscriptğµğ‘–ğ‘—1B\_{ij}\leftarrow 1.
(It is possible to pick the same iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m] twice, in which case we only perform the update once.)
Bundling will be done with disjunction, so a set with characteristic vector vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d} is represented as 1âˆ§Bâ€‹v1ğµğ‘£1\wedge Bv, meaning that the coordinate-wise minimum of Bâ€‹vğµğ‘£Bv with 1 is taken.

This representation, and the resulting membership testing, has long been studied as used as *Bloom filters*, with many variations, including applications to *private* set intersection estimation.
However, the narrow question of how to use dot products of Bloom filter representations (or other simple vector operations) to estimate set intersection size, is less well developed.
It is outlined briefly in [broder\_network\_2004], and discussed in [swamidass\_mathematical\_2007].
An analysis is given in [papapetrou\_cardinality\_2010], where the assumption is made that the entries of Bâ€‹vğµğ‘£Bv are independent of each other. 222This is a good approximation, but the approximation is not rigorously substantiated, so the results are correct only up to that assumption. See also [bose\_false-positive\_2008] regarding difficulties in the analysis of Bloom filters.
We will bound the error in estimating set intersections using Bloom filters in Theorem [22](#Thmtheorem22 "Theorem 22. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

A key quantity for our analysis is the number of nonzeros in Bâ€‹vğµğ‘£Bv as a function of â€–vâ€–0subscriptnormğ‘£0\|v\|\_{0}, when vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d}.
We will let â€–xâ€–0subscriptnormğ‘¥0\|x\|\_{0} denote the number of nonzeros of xğ‘¥x, so â€–1âˆ§Bâ€‹vâ€–1=â€–Bâ€‹vâ€–0subscriptnorm1ğµğ‘£1subscriptnormğµğ‘£0\|1\wedge Bv\|\_{1}=\|Bv\|\_{0}.
This includes real numbers yğ‘¦y, so â€–yâ€–0subscriptnormğ‘¦0\|y\|\_{0} is one when yâ‰ 0ğ‘¦0y\neq 0, and 0 otherwise.

###### Lemma 42.

For vâˆˆ{0,1}dğ‘£superscript01ğ‘‘v\in\{0,1\}^{d}, let nâ‰¡â€–vâ€–0ğ‘›subscriptnormğ‘£0n\equiv\|v\|\_{0}. Define Îºâ‰¡â€–Bâ€‹vâ€–0ğœ…subscriptnormğµğ‘£0\kappa\equiv\|Bv\|\_{0}, and let pâ„“â‰¡(1âˆ’1/m)kâ€‹â„“subscriptğ‘â„“superscript11ğ‘šğ‘˜â„“p\_{\ell}\equiv(1-1/m)^{k\ell}.
Then ğ”¼â€‹[Îº]=mâ€‹(1âˆ’pn)ğ”¼delimited-[]ğœ…ğ‘š1subscriptğ‘ğ‘›{\mathbb{E}}[\kappa]=m(1-p\_{n}).
Moreover, letting m~â‰¡âˆ’1/logâ¡(1âˆ’1/m)~ğ‘š111ğ‘š{\tilde{m}}\equiv-1/\log(1-1/m),

|  |  |  |  |
| --- | --- | --- | --- |
|  | 1âˆ’kâ€‹â„“mâˆ’1â‰¤pâ„“=expâ¡(âˆ’kâ€‹â„“/m~)â‰¤expâ¡(âˆ’kâ€‹â„“/m)1ğ‘˜â„“ğ‘š1subscriptğ‘â„“ğ‘˜â„“~ğ‘šğ‘˜â„“ğ‘š1-\frac{k\ell}{m-1}\leq p\_{\ell}=\exp(-k\ell/{\tilde{m}})\leq\exp(-k\ell/m) |  | (8) |

Letting hm,kâ€‹(z)â‰¡âˆ’m~kâ€‹logâ¡(1âˆ’zm)subscriptâ„

ğ‘šğ‘˜ğ‘§~ğ‘šğ‘˜1ğ‘§ğ‘šh\_{m,k}(z)\equiv\frac{-{\tilde{m}}}{k}\log(1-\frac{z}{m}), we have hm,kâ€‹(ğ”¼â€‹[Îº])=hm,kâ€‹(mâ€‹(1âˆ’pn))=nsubscriptâ„

ğ‘šğ‘˜ğ”¼delimited-[]ğœ…subscriptâ„

ğ‘šğ‘˜ğ‘š1subscriptğ‘ğ‘›ğ‘›h\_{m,k}({\mathbb{E}}[\kappa])=h\_{m,k}(m(1-p\_{n}))=n.

Here, we can think of hm,ksubscriptâ„

ğ‘šğ‘˜h\_{m,k} as an estimator for â€–vâ€–0subscriptnormğ‘£0\|v\|\_{0}, accounting for collisions in Bâ€‹vğµğ‘£Bv.
It is not unbiased, as we do not have ğ”¼â€‹[hm,kâ€‹(Îº)]=nğ”¼delimited-[]subscriptâ„

ğ‘šğ‘˜ğœ…ğ‘›{\mathbb{E}}[h\_{m,k}(\kappa)]=n, but hm,kâ€‹(Îº)subscriptâ„

ğ‘šğ‘˜ğœ…h\_{m,k}(\kappa) will still be a *good* estimator if Îºğœ…\kappa concentrates; luckily for us, it does, as shown below.

The definitions of m~~ğ‘š{\tilde{m}} may also seem a bit curious; we use the following well-known inequalities.

|  |  |  |  |
| --- | --- | --- | --- |
|  | logâ¡(1+x)â‰¤xâ€‹forâ€‹allâ€‹xâˆ’logâ¡(1âˆ’x)â‰¤x1âˆ’xâ€‹forâ€‹x<11ğ‘¥ğ‘¥forallğ‘¥1ğ‘¥ğ‘¥1ğ‘¥forğ‘¥1\begin{split}\log(1+x)&\leq x\mathrm{\ for\ all\ }x\\ -\log(1-x)&\leq\frac{x}{1-x}\mathrm{\ for\ }x<1\end{split} |  | (9) |

These imply

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 1mâ‰¤âˆ’logâ¡(1âˆ’1m)1ğ‘š11ğ‘š\displaystyle\frac{1}{m}\leq-\log(1-\frac{1}{m}) | â‰¤1/m1âˆ’1/m=1mâˆ’1,andâ€‹soformulae-sequenceabsent1ğ‘š11ğ‘š1ğ‘š1andso\displaystyle\leq\frac{1/m}{1-1/m}=\frac{1}{m-1},\mathrm{\ and\ so} |  | (10) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | mâˆ’1â‰¤m~ğ‘š1~ğ‘š\displaystyle m-1\leq{\tilde{m}} | â‰¤mabsentğ‘š\displaystyle\leq m |  | (11) |

###### of LemmaÂ [42](#Thmtheorem42 "Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures").

Observe that for each of nğ‘›n vectors Bâˆ—jsubscriptğµabsentğ‘—B\_{\*j}, there will be kğ‘˜k independent trials generating random iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m], so for (Bâ€‹v)isubscriptğµğ‘£ğ‘–(Bv)\_{i} to be zero, all kâ€‹nğ‘˜ğ‘›kn independent trials need to miss indexÂ iğ‘–i.
This happens for a single trial with probability 1âˆ’1/m11ğ‘š1-1/m, and so the probability that all kâ€‹nğ‘˜ğ‘›kn trials miss iğ‘–i is (1âˆ’1/m)kâ€‹nsuperscript11ğ‘šğ‘˜ğ‘›(1-1/m)^{kn}.
It follows that the expected number of nonzeros

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[Îº]=ğ”¼â€‹[â€–Bâ€‹vâ€–0]=ğ”¼â€‹[âˆ‘iâˆˆ[m]â€–Biâ£âˆ—â€‹vâ€–0]=âˆ‘iâˆˆ[m]ğ”¼â€‹[â€–Biâ£âˆ—â€‹vâ€–0]=mâ€‹(1âˆ’(1âˆ’1/m)kâ€‹n)=mâ€‹(1âˆ’pn),ğ”¼delimited-[]ğœ…ğ”¼delimited-[]subscriptnormğµğ‘£0ğ”¼delimited-[]subscriptğ‘–delimited-[]ğ‘šsubscriptnormsubscriptğµ  ğ‘–ğ‘£0subscriptğ‘–delimited-[]ğ‘šğ”¼delimited-[]subscriptnormsubscriptğµ  ğ‘–ğ‘£0ğ‘š1superscript11ğ‘šğ‘˜ğ‘›ğ‘š1subscriptğ‘ğ‘›{\mathbb{E}}[\kappa]={\mathbb{E}}[\|Bv\|\_{0}]={\mathbb{E}}[\sum\_{i\in[m]}\|B\_{i\*}v\|\_{0}]=\sum\_{i\in[m]}{\mathbb{E}}[\|B\_{i\*}v\|\_{0}]=m(1-(1-1/m)^{kn})=m(1-p\_{n}), |  |

as claimed.
To show ([8](#S7.E8 "In Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")), we use ([9](#S7.E9 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) and ([10](#S7.E10 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")), which imply

|  |  |  |
| --- | --- | --- |
|  | 1âˆ’kâ€‹â„“mâˆ’1â‰¤expâ¡(âˆ’kâ€‹â„“/(mâˆ’1))â‰¤(1âˆ’1m)kâ€‹â„“=pâ„“â‰¤expâ¡(âˆ’kâ€‹â„“/m),1ğ‘˜â„“ğ‘š1ğ‘˜â„“ğ‘š1superscript11ğ‘šğ‘˜â„“subscriptğ‘â„“ğ‘˜â„“ğ‘š1-\frac{k\ell}{m-1}\leq\exp(-k\ell/(m-1))\leq\left(1-\frac{1}{m}\right)^{k\ell}=p\_{\ell}\leq\exp(-k\ell/m), |  |

as claimed. The last claim is immediate.
âˆ

###### Theorem (Restatement of Theorem [22](#Thmtheorem22 "Theorem 22. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Let v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d} represent sets X,Y

ğ‘‹ğ‘ŒX,Y respectively, and define the following counts:

|  |  |  |
| --- | --- | --- |
|  | nâ‰¡|Xâˆ©Y|=vâ‹…w,nvâ‰¡|Xâˆ–Y|=â€–vâ€–0âˆ’n,nwâ‰¡|Yâˆ–X|=â€–wâ€–0âˆ’nformulae-sequenceğ‘›ğ‘‹ğ‘Œâ‹…ğ‘£ğ‘¤subscriptğ‘›ğ‘£ğ‘‹ğ‘Œsubscriptnormğ‘£0ğ‘›subscriptğ‘›ğ‘¤ğ‘Œğ‘‹subscriptnormğ‘¤0ğ‘›n\equiv|X\cap Y|=v\cdot w,\;\;\;\;\;\;n\_{v}\equiv|X\setminus Y|=\|v\|\_{0}-n,\;\;\;\;\;\;n\_{w}\equiv|Y\setminus X|=\|w\|\_{0}-n |  |

Let x=1âˆ§Bâ€‹vğ‘¥1ğµğ‘£x=1\wedge Bv and y=1âˆ§Bâ€‹wğ‘¦1ğµğ‘¤y=1\wedge Bw, where Bâˆˆ{0,1}mÃ—dğµsuperscript01ğ‘šğ‘‘B\in\{0,1\}^{m\times d} is a sparse binary matrix.

Assume WLOG nwâ‰¥nvsubscriptğ‘›ğ‘¤subscriptğ‘›ğ‘£n\_{w}\geq n\_{v}.
Then for Î´âˆˆ(0,1)ğ›¿01\delta\in(0,1) and Îµ>0ğœ€0{\varepsilon}>0, there are k=Oâ€‹(Îµâˆ’1â€‹logâ¡(1/Î´))ğ‘˜ğ‘‚superscriptğœ€11ğ›¿k=O({\varepsilon}^{-1}\log(1/\delta))
and m=Oâ€‹(kâ€‹Îµâˆ’1â€‹(nvâ€‹nw+n2+Îµâ€‹(n+nw)))ğ‘šğ‘‚ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤superscriptğ‘›2ğœ€ğ‘›subscriptğ‘›ğ‘¤m=O(k{\varepsilon}^{-1}(n\_{v}n\_{w}+n^{2}+{\varepsilon}(n+n\_{w}))) such that hm,kâ€‹(xâ‹…y)=nÂ±Ïµsubscriptâ„

ğ‘šğ‘˜â‹…ğ‘¥ğ‘¦plus-or-minusğ‘›italic-Ïµh\_{m,k}(x\cdot y)=n\pm\epsilon with failure probability Î´ğ›¿\delta. Here, hm,kâ€‹(z)subscriptâ„

ğ‘šğ‘˜ğ‘§h\_{m,k}(z) (see LemmaÂ [42](#Thmtheorem42 "Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) maps the Bloom filter output 1âˆ§Bâ€‹z1ğµğ‘§1\wedge Bz to an estimate of â€–zâ€–0subscriptnormğ‘§0\|z\|\_{0}.

When Îµ<1/2ğœ€12{\varepsilon}<1/2, the integrality of nğ‘›n implies an exact result.
Thus, the theorem implies that when nğ‘›n and nvsubscriptğ‘›ğ‘£n\_{v} are Oâ€‹(1)ğ‘‚1O(1), m=Oâ€‹(kâ€‹nw)ğ‘šğ‘‚ğ‘˜subscriptğ‘›ğ‘¤m=O(kn\_{w}) and k=Oâ€‹(logâ¡(1/Î´))ğ‘˜ğ‘‚1ğ›¿k=O(\log(1/\delta)) suffice.
This includes the case of membership testing, where nv=1subscriptğ‘›ğ‘£1n\_{v}=1.

The theorem also allows Îµ>1ğœ€1{\varepsilon}>1, including Îµ=Îµ~â€‹nğœ€~ğœ€ğ‘›{\varepsilon}={\tilde{\varepsilon}}n, which allows us to estimate nğ‘›n up to relative error Îµğœ€{\varepsilon} rather than additive error Îµğœ€{\varepsilon}.
In this case, m=Oâ€‹(kâ€‹Îµ~âˆ’1â€‹(nvâ€‹nw/n+n)+kâ€‹nw)ğ‘šğ‘‚ğ‘˜superscript~ğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘›ğ‘›ğ‘˜subscriptğ‘›ğ‘¤m=O(k{\tilde{\varepsilon}}^{-1}(n\_{v}n\_{w}/n+n)+kn\_{w}) and k=Oâ€‹(maxâ¡{1,Îµ~âˆ’1â€‹nâˆ’1â€‹logâ¡(1/Î´)})ğ‘˜ğ‘‚1superscript~ğœ€1superscriptğ‘›11ğ›¿k=O(\max\{1,{\tilde{\varepsilon}}^{-1}n^{-1}\log(1/\delta)\}) suffice.

###### Proof.

Let vc=vâˆ˜wsuperscriptğ‘£ğ‘ğ‘£ğ‘¤v^{c}=v\circ w, where âˆ˜\circ denotes element-wise product, so n=â€–vcâ€–0ğ‘›subscriptnormsuperscriptğ‘£ğ‘0n=\|v^{c}\|\_{0}, and let

|  |  |  |
| --- | --- | --- |
|  | Îºâˆ©=â€–Bâ€‹vcâ€–0.subscriptğœ…subscriptnormğµsuperscriptğ‘£ğ‘0\kappa\_{\cap}=\|Bv^{c}\|\_{0}. |  |

Let xc=1âˆ§Bâ€‹vcsuperscriptğ‘¥ğ‘1ğµsuperscriptğ‘£ğ‘x^{c}=1\wedge Bv^{c}, x~=xâˆ’xc~ğ‘¥ğ‘¥superscriptğ‘¥ğ‘{\tilde{x}}=x-x^{c}, y~=yâˆ’xc~ğ‘¦ğ‘¦superscriptğ‘¥ğ‘{\tilde{y}}=y-x^{c}, and let

|  |  |  |
| --- | --- | --- |
|  | ÎºÎ”â‰¡x~â‹…y~=xâ‹…yâˆ’Îºâˆ©,subscriptğœ…Î”â‹…~ğ‘¥~ğ‘¦â‹…ğ‘¥ğ‘¦subscriptğœ…\kappa\_{\Delta}\equiv{\tilde{x}}\cdot{\tilde{y}}=x\cdot y-\kappa\_{\cap}, |  |

noting that x~â‹…xc=0â‹…~ğ‘¥superscriptğ‘¥ğ‘0{\tilde{x}}\cdot x^{c}=0 and y~â‹…xc=0â‹…~ğ‘¦superscriptğ‘¥ğ‘0{\tilde{y}}\cdot x^{c}=0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | x~â‹…y~â‹…~ğ‘¥~ğ‘¦\displaystyle{\tilde{x}}\cdot{\tilde{y}} | =xâ‹…yâˆ’xcâ‹…xâˆ’xcâ‹…y+xcâ‹…xcabsentâ‹…ğ‘¥ğ‘¦â‹…superscriptğ‘¥ğ‘ğ‘¥â‹…superscriptğ‘¥ğ‘ğ‘¦â‹…superscriptğ‘¥ğ‘superscriptğ‘¥ğ‘\displaystyle=x\cdot y-x^{c}\cdot x-x^{c}\cdot y+x^{c}\cdot x^{c} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =xâ‹…yâˆ’(xcâ‹…x~+xcâ‹…xc)âˆ’(xcâ‹…y~+xcâ‹…xc)+xcâ‹…xcabsentâ‹…ğ‘¥ğ‘¦â‹…superscriptğ‘¥ğ‘~ğ‘¥â‹…superscriptğ‘¥ğ‘superscriptğ‘¥ğ‘â‹…superscriptğ‘¥ğ‘~ğ‘¦â‹…superscriptğ‘¥ğ‘superscriptğ‘¥ğ‘â‹…superscriptğ‘¥ğ‘superscriptğ‘¥ğ‘\displaystyle=x\cdot y-(x^{c}\cdot{\tilde{x}}+x^{c}\cdot x^{c})-(x^{c}\cdot{\tilde{y}}+x^{c}\cdot x^{c})+x^{c}\cdot x^{c} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =xâ‹…yâˆ’xcâ‹…xcabsentâ‹…ğ‘¥ğ‘¦â‹…superscriptğ‘¥ğ‘superscriptğ‘¥ğ‘\displaystyle=x\cdot y-x^{c}\cdot x^{c} |  |

In other words, we can rewrite xâ‹…y=Îºâ‰¡Îºâˆ©+ÎºÎ”â‹…ğ‘¥ğ‘¦ğœ…subscriptğœ…subscriptğœ…Î”x\cdot y=\kappa\equiv\kappa\_{\cap}+\kappa\_{\Delta}, where Îºâˆ©subscriptğœ…\kappa\_{\cap} counts the 1s that xğ‘¥x and yğ‘¦y have in common due to elements in suppâ¡(v)âˆ©suppâ¡(w)suppğ‘£suppğ‘¤\operatorname{{\text{supp}}}(v)\cap\operatorname{{\text{supp}}}(w), while ÎºÎ”subscriptğœ…Î”\kappa\_{\Delta} counts the 1s common to x,y

ğ‘¥ğ‘¦x,y due to elements corresponding to the symmetric difference suppâ¡(|vâˆ’w|)=suppâ¡(v)â€‹Î”â€‹suppâ¡(w)suppğ‘£ğ‘¤suppğ‘£Î”suppğ‘¤\operatorname{{\text{supp}}}(|v-w|)=\operatorname{{\text{supp}}}(v)\Delta\operatorname{{\text{supp}}}(w), that are not already counted in Îºâˆ©subscriptğœ…\kappa\_{\cap}.

Recall that we defined pâ„“â‰¡(1âˆ’1/m)kâ€‹â„“subscriptğ‘â„“superscript11ğ‘šğ‘˜â„“p\_{\ell}\equiv(1-1/m)^{k\ell} in Lemma [42](#Thmtheorem42 "Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures").
Then,

|  |  |  |
| --- | --- | --- |
|  | pnâ‰¡1âˆ’1mâ€‹ğ”¼â€‹[Îºâˆ©]=1âˆ’1mâ€‹ğ”¼â€‹[â€–Bâ€‹vâ€–0],pnvâ‰¡1âˆ’1mâ€‹ğ”¼â€‹[â€–Bâ€‹vâ€–0],pnwâ‰¡1âˆ’1mâ€‹ğ”¼â€‹[â€–Bâ€‹wâ€–0]formulae-sequencesubscriptğ‘ğ‘›11ğ‘šğ”¼delimited-[]subscriptğœ…11ğ‘šğ”¼delimited-[]subscriptnormğµğ‘£0formulae-sequencesubscriptğ‘subscriptğ‘›ğ‘£11ğ‘šğ”¼delimited-[]subscriptnormğµğ‘£0subscriptğ‘subscriptğ‘›ğ‘¤11ğ‘šğ”¼delimited-[]subscriptnormğµğ‘¤0p\_{n}\equiv 1-\frac{1}{m}{\mathbb{E}}[\kappa\_{\cap}]=1-\frac{1}{m}{\mathbb{E}}[\|Bv\|\_{0}],\;\;\;\;p\_{n\_{v}}\equiv 1-\frac{1}{m}{\mathbb{E}}[\|Bv\|\_{0}],\;\;\;\;p\_{n\_{w}}\equiv 1-\frac{1}{m}{\mathbb{E}}[\|Bw\|\_{0}] |  |

Using LemmaÂ [42](#Thmtheorem42 "Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures") and ([8](#S7.E8 "In Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")), and letting pvâ€‹wâ‰¡(1âˆ’pnv)â€‹(1âˆ’pnw)subscriptğ‘ğ‘£ğ‘¤1subscriptğ‘subscriptğ‘›ğ‘£1subscriptğ‘subscriptğ‘›ğ‘¤p\_{vw}\equiv(1-p\_{n\_{v}})(1-p\_{n\_{w}}),

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[Îºâˆ©]=mâ€‹(1âˆ’pn)ğ”¼â€‹[ÎºÎ”]=mâ€‹pnâ€‹pvâ€‹w,andâ€‹pvâ€‹wâ‰¤kâ€‹nvmâˆ’1â‹…kâ€‹nwmâˆ’1=k2â€‹nvâ€‹nwm2â€‹(1+Oâ€‹(1/m)).formulae-sequenceğ”¼delimited-[]subscriptğœ…ğ‘š1subscriptğ‘ğ‘›ğ”¼delimited-[]subscriptğœ…Î”ğ‘šsubscriptğ‘ğ‘›subscriptğ‘ğ‘£ğ‘¤andsubscriptğ‘ğ‘£ğ‘¤â‹…ğ‘˜subscriptğ‘›ğ‘£ğ‘š1ğ‘˜subscriptğ‘›ğ‘¤ğ‘š1superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤superscriptğ‘š21ğ‘‚1ğ‘š\begin{split}{\mathbb{E}}[\kappa\_{\cap}]&=m(1-p\_{n})\\ {\mathbb{E}}[\kappa\_{\Delta}]&=mp\_{n}p\_{vw},\mathrm{\ and\ }p\_{vw}\leq\frac{kn\_{v}}{m-1}\cdot\frac{kn\_{w}}{m-1}=\frac{k^{2}n\_{v}n\_{w}}{m^{2}}(1+O(1/m)).\end{split} |  | (12) |

where the latter is due to the fact that the probability that given entries x~isubscript~ğ‘¥ğ‘–{\tilde{x}}\_{i} and y~isubscript~ğ‘¦ğ‘–{\tilde{y}}\_{i} contribute to x~â‹…y~â‹…~ğ‘¥~ğ‘¦{\tilde{x}}\cdot{\tilde{y}} is the probability that (a) the nğ‘›n entries of vcsuperscriptğ‘£ğ‘v^{c} yield Biâ£âˆ—â€‹vc=0subscriptğµ

ğ‘–superscriptğ‘£ğ‘0B\_{i\*}v^{c}=0, and (b) that both entries x~isubscript~ğ‘¥ğ‘–{\tilde{x}}\_{i} and y~isubscript~ğ‘¦ğ‘–{\tilde{y}}\_{i} are nonzero.
Note that the three events in (a) and (b) are independent, since suppâ¡(vc)suppsuperscriptğ‘£ğ‘\operatorname{{\text{supp}}}(v^{c}), suppâ¡(vâˆ’vc)suppğ‘£superscriptğ‘£ğ‘\operatorname{{\text{supp}}}(v-v^{c}), and suppâ¡(wâˆ’vc)suppğ‘¤superscriptğ‘£ğ‘\operatorname{{\text{supp}}}(w-v^{c}) are disjoint.

Suppose, for some Îµâˆ©,ÎµT>0

subscriptğœ€subscriptğœ€ğ‘‡
0{\varepsilon}\_{\cap},{\varepsilon}\_{T}>0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Îºâˆ©â‰¥ğ”¼â€‹[Îºâˆ©]âˆ’Îµâˆ©Îºâ‰¤ğ”¼â€‹[Îº]+ÎµT,subscriptğœ…ğ”¼delimited-[]subscriptğœ…subscriptğœ€ğœ…ğ”¼delimited-[]ğœ…subscriptğœ€ğ‘‡\begin{split}\kappa\_{\cap}&\geq{\mathbb{E}}[\kappa\_{\cap}]-{\varepsilon}\_{\cap}\\ \kappa&\leq{\mathbb{E}}[\kappa]+{\varepsilon}\_{T},\end{split} |  | (13) |

which holds with small failure probability, as shown below.

First, using these assumptions on Îºâˆ©subscriptğœ…\kappa\_{\cap} and Îºğœ…\kappa, we establish a lower bound on hm,kâ€‹(Îº)subscriptâ„

ğ‘šğ‘˜ğœ…h\_{m,k}(\kappa).
Since ÎºÎ”â‰¥0subscriptğœ…Î”0\kappa\_{\Delta}\geq 0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | âˆ’km~â€‹hm,kâ€‹(Îº)ğ‘˜~ğ‘šsubscriptâ„  ğ‘šğ‘˜ğœ…\displaystyle-\frac{k}{{\tilde{m}}}h\_{m,k}(\kappa) | =logâ¡(1âˆ’Îºm)=logâ¡(1âˆ’Îºâˆ©+ÎºÎ”m)absent1ğœ…ğ‘š1subscriptğœ…subscriptğœ…Î”ğ‘š\displaystyle=\log(1-\frac{\kappa}{m})=\log(1-\frac{\kappa\_{\cap}+\kappa\_{\Delta}}{m}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤logâ¡(1âˆ’Îºâˆ©m)absent1subscriptğœ…ğ‘š\displaystyle\leq\log(1-\frac{\kappa\_{\cap}}{m}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤logâ¡(1âˆ’ğ”¼â€‹[Îºâˆ©]âˆ’Îµâˆ©m)absent1ğ”¼delimited-[]subscriptğœ…subscriptğœ€ğ‘š\displaystyle\leq\log(1-\frac{{\mathbb{E}}[\kappa\_{\cap}]-{\varepsilon}\_{\cap}}{m}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =logâ¡(pn+Îµâˆ©m)absentsubscriptğ‘ğ‘›subscriptğœ€ğ‘š\displaystyle=\log(p\_{n}+\frac{{\varepsilon}\_{\cap}}{m}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =logâ¡(pn)+logâ¡(1+Îµâˆ©mâ€‹pn)absentsubscriptğ‘ğ‘›1subscriptğœ€ğ‘šsubscriptğ‘ğ‘›\displaystyle=\log(p\_{n})+\log(1+\frac{{\varepsilon}\_{\cap}}{mp\_{n}}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤logâ¡(pn)+Îµâˆ©mâ€‹pnabsentsubscriptğ‘ğ‘›subscriptğœ€ğ‘šsubscriptğ‘ğ‘›\displaystyle\leq\log(p\_{n})+\frac{{\varepsilon}\_{\cap}}{mp\_{n}} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤âˆ’km~â€‹(nâˆ’Îµâˆ©kâ€‹pn),Â usingÂ â€‹(â€‹[11](#S7.E11 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")â€‹)â€‹Â and the definition ofÂ â€‹pâ„“â€‹, and soabsent  ğ‘˜~ğ‘šğ‘›subscriptğœ€ğ‘˜subscriptğ‘ğ‘›Â usingÂ italic-([11](#S7.E11 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")italic-)Â and the definition ofÂ subscriptğ‘â„“, and so\displaystyle\leq-\frac{k}{{\tilde{m}}}(n-\frac{{\varepsilon}\_{\cap}}{kp\_{n}}),\text{ using }\eqref{eq tm}\text{ and the definition of }p\_{\ell}\text{, and so} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | hm,kâ€‹(Îº)subscriptâ„  ğ‘šğ‘˜ğœ…\displaystyle h\_{m,k}(\kappa) | â‰¥nâˆ’Îµâˆ©kâ€‹pn.absentğ‘›subscriptğœ€ğ‘˜subscriptğ‘ğ‘›\displaystyle\geq n-\frac{{\varepsilon}\_{\cap}}{kp\_{n}}. |  |

If we assume that mâ‰¥2â€‹kâ€‹n+1ğ‘š2ğ‘˜ğ‘›1m\geq 2kn+1, then pnâ‰¥1/2subscriptğ‘ğ‘›12p\_{n}\geq 1/2.
We have

|  |  |  |  |
| --- | --- | --- | --- |
|  | hm,kâ€‹(Îº)âˆ’nâ‰¥âˆ’Îµâˆ©kâ€‹pnâ‰¥âˆ’2â€‹Îµâˆ©k,subscriptâ„  ğ‘šğ‘˜ğœ…ğ‘›subscriptğœ€ğ‘˜subscriptğ‘ğ‘›2subscriptğœ€ğ‘˜h\_{m,k}(\kappa)-n\geq-\frac{{\varepsilon}\_{\cap}}{kp\_{n}}\geq-\frac{2{\varepsilon}\_{\cap}}{k}, |  | (14) |

Again, using our assumptions on the sizes of Îºâˆ©subscriptğœ…\kappa\_{\cap} and Îºğœ…\kappa, we can obtain an upper bound on hm,kâ€‹(Îº)subscriptâ„

ğ‘šğ‘˜ğœ…h\_{m,k}(\kappa)

|  |  |  |  |
| --- | --- | --- | --- |
|  | hm,kâ€‹(Îº)subscriptâ„  ğ‘šğ‘˜ğœ…\displaystyle h\_{m,k}(\kappa) | =âˆ’m~kâ€‹logâ¡(1âˆ’Îºm)absent~ğ‘šğ‘˜1ğœ…ğ‘š\displaystyle=\frac{-{\tilde{m}}}{k}\log(1-\frac{\kappa}{m}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤âˆ’m~kâ€‹logâ¡(1âˆ’ğ”¼â€‹[Îº]+ÎµTm)absent~ğ‘šğ‘˜1ğ”¼delimited-[]ğœ…subscriptğœ€ğ‘‡ğ‘š\displaystyle\leq\frac{-{\tilde{m}}}{k}\log(1-\frac{{\mathbb{E}}[\kappa]+{\varepsilon}\_{T}}{m}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =âˆ’m~kâ€‹logâ¡(pnâˆ’pnâ€‹pvâ€‹wâˆ’ÎµTm)absent~ğ‘šğ‘˜subscriptğ‘ğ‘›subscriptğ‘ğ‘›subscriptğ‘ğ‘£ğ‘¤subscriptğœ€ğ‘‡ğ‘š\displaystyle=\frac{-{\tilde{m}}}{k}\log(p\_{n}-p\_{n}p\_{vw}-\frac{{\varepsilon}\_{T}}{m}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =nâˆ’m~kâ€‹logâ¡(1âˆ’pvâ€‹wâˆ’ÎµTmâ€‹pn)absentğ‘›~ğ‘šğ‘˜1subscriptğ‘ğ‘£ğ‘¤subscriptğœ€ğ‘‡ğ‘šsubscriptğ‘ğ‘›\displaystyle=n-\frac{{\tilde{m}}}{k}\log(1-p\_{vw}-\frac{{\varepsilon}\_{T}}{mp\_{n}}) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤nâˆ’mkâ€‹logâ¡(1âˆ’pvâ€‹wâˆ’ÎµTmâ€‹pn)â€‹Â usingÂ â€‹(â€‹[11](#S7.E11 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")â€‹)absentğ‘›ğ‘šğ‘˜1subscriptğ‘ğ‘£ğ‘¤subscriptğœ€ğ‘‡ğ‘šsubscriptğ‘ğ‘›Â usingÂ italic-([11](#S7.E11 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")italic-)\displaystyle\leq n-\frac{m}{k}\log(1-p\_{vw}-\frac{{\varepsilon}\_{T}}{mp\_{n}})\text{ using }\eqref{eq tm} |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | â‰¤n+mkâ€‹pvâ€‹w+mkâ€‹ÎµTmâ€‹pnâ€‹(1âˆ’pvâ€‹w),usingâ€‹(â€‹[9](#S7.E9 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")â€‹)absent  ğ‘›ğ‘šğ‘˜subscriptğ‘ğ‘£ğ‘¤ğ‘šğ‘˜subscriptğœ€ğ‘‡ğ‘šsubscriptğ‘ğ‘›1subscriptğ‘ğ‘£ğ‘¤usingitalic-([9](#S7.E9 "In 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")italic-)\displaystyle\leq n+\frac{m}{k}p\_{vw}+\frac{m}{k}\frac{{\varepsilon}\_{T}}{mp\_{n}(1-p\_{vw})},\mathrm{\ using\ }\eqref{eq log ineq} |  | (15) |

Assume that

|  |  |  |  |
| --- | --- | --- | --- |
|  | mâ‰¥maxâ¡{kâ€‹2â€‹nvâ€‹nw+1,2â€‹kâ€‹n+1}.ğ‘šğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤12ğ‘˜ğ‘›1m\geq\max\{k\sqrt{2n\_{v}n\_{w}}+1,2kn+1\}. |  | (16) |

which includes the prior assumption on mğ‘šm.
Then using ([8](#S7.E8 "In Lemma 42. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) and ([12](#S7.E12 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")),

|  |  |  |
| --- | --- | --- |
|  | 1âˆ’pvâ€‹wâ‰¥1âˆ’kâ€‹nvmâˆ’1â‹…kâ€‹nwmâˆ’1â‰¥1/21subscriptğ‘ğ‘£ğ‘¤1â‹…ğ‘˜subscriptğ‘›ğ‘£ğ‘š1ğ‘˜subscriptğ‘›ğ‘¤ğ‘š1121-p\_{vw}\geq 1-\frac{kn\_{v}}{m-1}\cdot\frac{kn\_{w}}{m-1}\geq 1/2 |  |

so pnâ€‹(1âˆ’pvâ€‹w)â‰¥1/4subscriptğ‘ğ‘›1subscriptğ‘ğ‘£ğ‘¤14p\_{n}(1-p\_{vw})\geq 1/4.
Therefore, from ([15](#S7.E15 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")),

|  |  |  |
| --- | --- | --- |
|  | kmâ€‹(hm,kâ€‹(Îº)âˆ’n)â‰¤pvâ€‹w+ÎµTmâ€‹pnâ€‹(1âˆ’pvâ€‹w)â‰¤pvâ€‹w+4â€‹ÎµTm,ğ‘˜ğ‘šsubscriptâ„  ğ‘šğ‘˜ğœ…ğ‘›subscriptğ‘ğ‘£ğ‘¤subscriptğœ€ğ‘‡ğ‘šsubscriptğ‘ğ‘›1subscriptğ‘ğ‘£ğ‘¤subscriptğ‘ğ‘£ğ‘¤4subscriptğœ€ğ‘‡ğ‘š\frac{k}{m}(h\_{m,k}(\kappa)-n)\leq p\_{vw}+\frac{{\varepsilon}\_{T}}{mp\_{n}(1-p\_{vw})}\leq p\_{vw}+\frac{4{\varepsilon}\_{T}}{m}, |  |

and so

|  |  |  |  |
| --- | --- | --- | --- |
|  | hm,kâ€‹(Îº)âˆ’nâ‰¤[kâ€‹nvâ€‹nwm+4â€‹ÎµTk]â€‹(1+Oâ€‹(1/m)),usingâ€‹(â€‹[12](#S7.E12 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")â€‹).subscriptâ„  ğ‘šğ‘˜ğœ…ğ‘›  delimited-[]ğ‘˜subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘š4subscriptğœ€ğ‘‡ğ‘˜1ğ‘‚1ğ‘šusingitalic-([12](#S7.E12 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")italic-)h\_{m,k}(\kappa)-n\leq\left[\frac{kn\_{v}n\_{w}}{m}+\frac{4{\varepsilon}\_{T}}{k}\right](1+O(1/m)),\mathrm{\ using}\eqref{eq kappas}. |  | (17) |

Both ([14](#S7.E14 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) and ([17](#S7.E17 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) control how close hm,kâ€‹(Îº)subscriptâ„

ğ‘šğ‘˜ğœ…h\_{m,k}(\kappa) is to nğ‘›n, but they rely on the assumptions in ([13](#S7.E13 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")).
We now need to bound Prâ¡[Îºâˆ©âˆ’ğ”¼â€‹[Îºâˆ©]â‰¤âˆ’Îµâˆ©]Prsubscriptğœ…ğ”¼delimited-[]subscriptğœ…subscriptğœ€\Pr[\kappa\_{\cap}-{\mathbb{E}}[\kappa\_{\cap}]\leq-{\varepsilon}\_{\cap}] and
Prâ¡[Îºâˆ’ğ”¼â€‹[Îº]â‰¥ÎµT]Prğœ…ğ”¼delimited-[]ğœ…subscriptğœ€ğ‘‡\Pr[\kappa-{\mathbb{E}}[\kappa]\geq{\varepsilon}\_{T}], so that ([13](#S7.E13 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) holds with high probability.

Recall that Îºâˆ©=â€–Bâ€‹vcâ€–0subscriptğœ…subscriptnormğµsuperscriptğ‘£ğ‘0\kappa\_{\cap}=\|Bv^{c}\|\_{0}.
We can express Îºâˆ©subscriptğœ…\kappa\_{\cap} as Îºâˆ©â€‹(X1,X2,â€¦,Xkâ€‹n)subscriptğœ…subscriptğ‘‹1subscriptğ‘‹2â€¦subscriptğ‘‹ğ‘˜ğ‘›\kappa\_{\cap}(X\_{1},X\_{2},\ldots,X\_{kn}), where each Xâ„“subscriptğ‘‹â„“X\_{\ell} makes a random choice iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m] and sets Biâ£âˆ—â€‹vcsubscriptğµ

ğ‘–superscriptğ‘£ğ‘B\_{i\*}v^{c} to one; such choices are made kğ‘˜k times for each of the nğ‘›n entries of vcsuperscriptğ‘£ğ‘v^{c} that are equal to one.
To apply TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), bounds on Bâ€‹(Îºâˆ©)ğµsubscriptğœ…B(\kappa\_{\cap}) and the Variâ€‹(Îºâˆ©)subscriptVarğ‘–subscriptğœ…{\textbf{Var}}\_{i}(\kappa\_{\cap}) are needed.

Given choices for all other Xâ„“â€²subscriptğ‘‹superscriptâ„“â€²X\_{\ell^{\prime}}, a choice iğ‘–i for Xâ„“subscriptğ‘‹â„“X\_{\ell} changes Îºâˆ©subscriptğœ…\kappa\_{\cap} if and only if given those other choices, Biâ£âˆ—â€‹vsubscriptğµ

ğ‘–ğ‘£B\_{i\*}v is equal to zero.
The only effect of these other choices is the number of bins already with ones, that is, the number of iâ€²superscriptğ‘–â€²i^{\prime} with Biâ€²â£âˆ—â€‹vc=1subscriptğµ

superscriptğ‘–â€²superscriptğ‘£ğ‘1B\_{i^{\prime}\*}v^{c}=1.
Given that rğ‘Ÿr bins have ones, the expected value of Îºâˆ©subscriptğœ…\kappa\_{\cap} with respect to the random choice Xâ„“subscriptğ‘‹â„“X\_{\ell} is 1âˆ’r/m1ğ‘Ÿğ‘š1-r/m, and the most Îºâˆ©subscriptğœ…\kappa\_{\cap} can differ from this is 1âˆ’r/mâ‰¤11ğ‘Ÿğ‘š11-r/m\leq 1, since it can hit one of those rğ‘Ÿr bins that are already one.
The variance Varâ„“â€‹(Îºâˆ©)subscriptVarâ„“subscriptğœ…{\textbf{Var}}\_{\ell}(\kappa\_{\cap}) is r/mâˆ’(r/m)2â‰¤r/mâ‰¤(kâ€‹nâˆ’1)/mğ‘Ÿğ‘šsuperscriptğ‘Ÿğ‘š2ğ‘Ÿğ‘šğ‘˜ğ‘›1ğ‘šr/m-(r/m)^{2}\leq r/m\leq(kn-1)/m, the variance of a Bernoulli random variable with probability 1âˆ’r/m1ğ‘Ÿğ‘š1-r/m of being one, and zero otherwise.
Thus Ïƒ~â€‹(Îºâˆ©)â‰¤(kâ€‹n)2/m~ğœsubscriptğœ…superscriptğ‘˜ğ‘›2ğ‘š{\tilde{\sigma}}(\kappa\_{\cap})\leq(kn)^{2}/m.333Put in a common setting, the bound of [broder\_network\_2004] corresponds to putting into the tail estimate denominator a value of kâ€‹nâ‰¥(kâ€‹n)2/mğ‘˜ğ‘›superscriptğ‘˜ğ‘›2ğ‘škn\geq(kn)^{2}/m for mâ‰¥kâ€‹nğ‘šğ‘˜ğ‘›m\geq kn, and the bound of [kamath\_tail\_1995] quoted in [bose\_false-positive\_2008] corresponds to mâ‰¥(kâ€‹n)2/mğ‘šsuperscriptğ‘˜ğ‘›2ğ‘šm\geq(kn)^{2}/m for mâ‰¥kâ€‹nğ‘šğ‘˜ğ‘›m\geq kn.
From TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), if Îµâˆ©=kâ€‹Îµ/4subscriptğœ€ğ‘˜ğœ€4{\varepsilon}\_{\cap}=k{\varepsilon}/4 for given Îµ>0ğœ€0{\varepsilon}>0, then

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[Îºâˆ©âˆ’ğ”¼â€‹[Îºâˆ©]â‰¤âˆ’Îµâˆ©]Prsubscriptğœ…ğ”¼delimited-[]subscriptğœ…subscriptğœ€\displaystyle\Pr[\kappa\_{\cap}-{\mathbb{E}}[\kappa\_{\cap}]\leq-{\varepsilon}\_{\cap}] | â‰¤expâ¡(âˆ’2â€‹Îµâˆ©2Ïƒ~â€‹(Îºâˆ©)+Îµâˆ©â€‹Bâ€‹(Îºâˆ©)/3)â‰¤expâ¡(âˆ’2â€‹Îµâˆ©2(kâ€‹n)2/m+Îµâˆ©/3)absent2superscriptsubscriptğœ€2~ğœsubscriptğœ…subscriptğœ€ğµsubscriptğœ…32superscriptsubscriptğœ€2superscriptğ‘˜ğ‘›2ğ‘šsubscriptğœ€3\displaystyle\leq\exp\left(-\frac{2{\varepsilon}\_{\cap}^{2}}{{\tilde{\sigma}}(\kappa\_{\cap})+{\varepsilon}\_{\cap}B(\kappa\_{\cap})/3}\right)\leq\exp\left(-\frac{2{\varepsilon}\_{\cap}^{2}}{(kn)^{2}/m+{\varepsilon}\_{\cap}/3}\right) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =expâ¡(âˆ’2â€‹(kâ€‹Îµ/4)2(kâ€‹n)2/m+(kâ€‹Îµ/4)/3)=expâ¡(âˆ’Îµ28â€‹n2/m+2â€‹Îµ/3â€‹k).absent2superscriptğ‘˜ğœ€42superscriptğ‘˜ğ‘›2ğ‘šğ‘˜ğœ€43superscriptğœ€28superscriptğ‘›2ğ‘š2ğœ€3ğ‘˜\displaystyle=\exp\left(-\frac{2(k{\varepsilon}/4)^{2}}{(kn)^{2}/m+(k{\varepsilon}/4)/3}\right)=\exp\left(-\frac{{\varepsilon}^{2}}{8n^{2}/m+2{\varepsilon}/3k}\right). |  | (18) |

Leaving aside for the moment the values needed for mğ‘šm and kğ‘˜k, we consider next
Prâ¡[Îºâˆ’ğ”¼â€‹[Îº]â‰¥ÎµT]Prğœ…ğ”¼delimited-[]ğœ…subscriptğœ€ğ‘‡\Pr[\kappa-{\mathbb{E}}[\kappa]\geq{\varepsilon}\_{T}].
Here from Îº=Îºâˆ©+ÎºÎ”ğœ…subscriptğœ…subscriptğœ…Î”\kappa=\kappa\_{\cap}+\kappa\_{\Delta}, we can regard Îºğœ…\kappa as the function of 2â€‹kâ€‹n+2â€‹kâ€‹nv+2â€‹kâ€‹nw2ğ‘˜ğ‘›2ğ‘˜subscriptğ‘›ğ‘£2ğ‘˜subscriptğ‘›ğ‘¤2kn+2kn\_{v}+2kn\_{w} random variables, of which the first 2â€‹kâ€‹n2ğ‘˜ğ‘›2kn, from Îºâˆ©subscriptğœ…\kappa\_{\cap}, have Ïƒ~~ğœ{\tilde{\sigma}} contribution at most (kâ€‹n)2/msuperscriptğ‘˜ğ‘›2ğ‘š(kn)^{2}/m and Bâ‰¤1ğµ1B\leq 1.
The next 2â€‹kâ€‹nv2ğ‘˜subscriptğ‘›ğ‘£2kn\_{v}, representing the choices made that result in x~~ğ‘¥{\tilde{x}}, each have the property that their mean and variance, as a function of the choices of all the other variables, depend only on the number of ones in y~~ğ‘¦{\tilde{y}}: the minimum mean is 1âˆ’kâ€‹nw1ğ‘˜subscriptğ‘›ğ‘¤1-kn\_{w}, so the contribution to BğµB is at most 1âˆ’kâ€‹nwâ‰¤11ğ‘˜subscriptğ‘›ğ‘¤11-kn\_{w}\leq 1; the maximum variance is
(kâ€‹nw/m)â€‹(1âˆ’(kâ€‹nw/m))â‰¤kâ€‹nw/mğ‘˜subscriptğ‘›ğ‘¤ğ‘š1ğ‘˜subscriptğ‘›ğ‘¤ğ‘šğ‘˜subscriptğ‘›ğ‘¤ğ‘š(kn\_{w}/m)(1-(kn\_{w}/m))\leq kn\_{w}/m.
There are kâ€‹nvğ‘˜subscriptğ‘›ğ‘£kn\_{v} such variables, so the contribution to Ïƒ~~ğœ{\tilde{\sigma}} is (kâ€‹nv)â€‹(kâ€‹nw/m)ğ‘˜subscriptğ‘›ğ‘£ğ‘˜subscriptğ‘›ğ‘¤ğ‘š(kn\_{v})(kn\_{w}/m).
Similarly, the last kâ€‹nwğ‘˜subscriptğ‘›ğ‘¤kn\_{w} random choices have Bâ‰¤1ğµ1B\leq 1 and contribution to Ïƒ~~ğœ{\tilde{\sigma}} of (kâ€‹nw)â€‹(kâ€‹nv/m)ğ‘˜subscriptğ‘›ğ‘¤ğ‘˜subscriptğ‘›ğ‘£ğ‘š(kn\_{w})(kn\_{v}/m).
So Bâ€‹(Îº)â‰¤1ğµğœ…1B(\kappa)\leq 1, and Ïƒ~â€‹(Îº)â‰¤k2â€‹(n2+2â€‹nvâ€‹nw)/m~ğœğœ…superscriptğ‘˜2superscriptğ‘›22subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘š{\tilde{\sigma}}(\kappa)\leq k^{2}(n^{2}+2n\_{v}n\_{w})/m.
If ÎµT=kâ€‹Îµ/4subscriptğœ€ğ‘‡ğ‘˜ğœ€4{\varepsilon}\_{T}=k{\varepsilon}/4, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[Îºâˆ’ğ”¼â€‹[Îº]â‰¥ÎµT]Prğœ…ğ”¼delimited-[]ğœ…subscriptğœ€ğ‘‡\displaystyle\Pr[\kappa-{\mathbb{E}}[\kappa]\geq{\varepsilon}\_{T}] | â‰¤expâ¡(âˆ’2â€‹ÎµT2Ïƒ~â€‹(Îº)+ÎµTâ€‹Bâ€‹(Îº)/3)â‰¤expâ¡(âˆ’2â€‹ÎµT2k2â€‹(n2+2â€‹nvâ€‹nw)/m+ÎµT/3)absent2superscriptsubscriptğœ€ğ‘‡2~ğœğœ…subscriptğœ€ğ‘‡ğµğœ…32superscriptsubscriptğœ€ğ‘‡2superscriptğ‘˜2superscriptğ‘›22subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘šsubscriptğœ€ğ‘‡3\displaystyle\leq\exp\left(-\frac{2{\varepsilon}\_{T}^{2}}{{\tilde{\sigma}}(\kappa)+{\varepsilon}\_{T}B(\kappa)/3}\right)\leq\exp\left(-\frac{2{\varepsilon}\_{T}^{2}}{k^{2}(n^{2}+2n\_{v}n\_{w})/m+{\varepsilon}\_{T}/3}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =expâ¡(âˆ’2â€‹(kâ€‹Îµ/4)2k2â€‹(n2+2â€‹nvâ€‹nw)/m+(kâ€‹Îµ/4)/3)absent2superscriptğ‘˜ğœ€42superscriptğ‘˜2superscriptğ‘›22subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘šğ‘˜ğœ€43\displaystyle=\exp\left(-\frac{2(k{\varepsilon}/4)^{2}}{k^{2}(n^{2}+2n\_{v}n\_{w})/m+(k{\varepsilon}/4)/3}\right) |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =expâ¡(âˆ’Îµ28â€‹(n2+2â€‹nvâ€‹nw)/m+2â€‹Îµ/3â€‹k).absentsuperscriptğœ€28superscriptğ‘›22subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘š2ğœ€3ğ‘˜\displaystyle=\exp\left(-\frac{{\varepsilon}^{2}}{8(n^{2}+2n\_{v}n\_{w})/m+2{\varepsilon}/3k}\right). |  | (19) |

If ([7.1](#S7.Ex148 "Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) yields a bound of Î´/2ğ›¿2\delta/2, ([7.1](#S7.Ex147 "Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) will too, and the total failure probability will be at most Î´ğ›¿\delta.

Assume WLOG that nwâ‰¥nvsubscriptğ‘›ğ‘¤subscriptğ‘›ğ‘£n\_{w}\geq n\_{v}.
From ([17](#S7.E17 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")), for the mean of Îºğœ…\kappa to be at most Îµğœ€{\varepsilon}, we must have mâ‰¥kâ€‹nvâ€‹nw/2â€‹Îµğ‘šğ‘˜subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤2ğœ€m\geq kn\_{v}n\_{w}/2{\varepsilon}.
This implies that in ([7.1](#S7.Ex148 "Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")), 8â€‹(n2+2â€‹nvâ€‹nw)/m+2â€‹Îµ/3â€‹kâ‰¤8â€‹n2/m+c1â€‹Îµ/k8superscriptğ‘›22subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘š2ğœ€3ğ‘˜8superscriptğ‘›2ğ‘šsubscriptğ‘1ğœ€ğ‘˜8(n^{2}+2n\_{v}n\_{w})/m+2{\varepsilon}/3k\leq 8n^{2}/m+c\_{1}{\varepsilon}/k, for c1=32+23subscriptğ‘13223c\_{1}=32+\frac{2}{3}.
For 8â€‹n2/m8superscriptğ‘›2ğ‘š8n^{2}/m to not dominate c1â€‹Îµ/ksubscriptğ‘1ğœ€ğ‘˜c\_{1}{\varepsilon}/k in the sum 8â€‹n2/m+c1â€‹Îµ/k8superscriptğ‘›2ğ‘šsubscriptğ‘1ğœ€ğ‘˜8n^{2}/m+c\_{1}{\varepsilon}/k, we need mâ‰¥8â€‹kâ€‹c1â€‹n2/Îµğ‘š8ğ‘˜subscriptğ‘1superscriptğ‘›2ğœ€m\geq 8kc\_{1}n^{2}/{\varepsilon}, yielding
2â€‹c1â€‹Îµ/k2subscriptğ‘1ğœ€ğ‘˜2c\_{1}{\varepsilon}/k in the denominator, so that under these assumptions regardingÂ mğ‘šm,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Prâ¡[ÎºÎ”âˆ’ğ”¼â€‹[ÎºÎ”]â‰¥Îµ]Prsubscriptğœ…Î”ğ”¼delimited-[]subscriptğœ…Î”ğœ€\displaystyle\Pr[\kappa\_{\Delta}-{\mathbb{E}}[\kappa\_{\Delta}]\geq{\varepsilon}] | â‰¤expâ¡(âˆ’Îµ28â€‹(n2+2â€‹nvâ€‹nw)/m+2â€‹Îµ/3â€‹k)absentsuperscriptğœ€28superscriptğ‘›22subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘š2ğœ€3ğ‘˜\displaystyle\leq\exp\left(-\frac{{\varepsilon}^{2}}{8(n^{2}+2n\_{v}n\_{w})/m+2{\varepsilon}/3k}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤expâ¡(âˆ’Îµ22â€‹c1â€‹Îµ/k)=expâ¡(âˆ’kâ€‹Îµ/2â€‹c1)â‰¤Î´/2â€‹forâ€‹k=2â€‹c1â€‹logâ¡(2/Î´)/Îµ.absentsuperscriptğœ€22subscriptğ‘1ğœ€ğ‘˜ğ‘˜ğœ€2subscriptğ‘1ğ›¿2forğ‘˜2subscriptğ‘12ğ›¿ğœ€\displaystyle\leq\exp\left(-\frac{{\varepsilon}^{2}}{2c\_{1}{\varepsilon}/k}\right)=\exp(-k{\varepsilon}/2c\_{1})\leq\delta/2\mathrm{\ for\ }k=2c\_{1}\log(2/\delta)/{\varepsilon}. |  |

With a similar bound for Prâ¡[Îºâˆ’ğ”¼â€‹[Îº]â‰¤âˆ’Îµ]Prğœ…ğ”¼delimited-[]ğœ…ğœ€\Pr[\kappa-{\mathbb{E}}[\kappa]\leq-{\varepsilon}], via ([14](#S7.E14 "In Proof. â€£ 7.1 Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")),
we have that mâ‰¥kÎµâ€‹(nvâ€‹nw/2+8â€‹c1â€‹n2+Îµâ€‹(n+nw))ğ‘šğ‘˜ğœ€subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤28subscriptğ‘1superscriptğ‘›2ğœ€ğ‘›subscriptğ‘›ğ‘¤m\geq\frac{k}{{\varepsilon}}(n\_{v}n\_{w}/2+8c\_{1}n^{2}+{\varepsilon}(n+n\_{w})) with k=2â€‹c1â€‹logâ¡(2/Î´)/Îµğ‘˜2subscriptğ‘12ğ›¿ğœ€k=2c\_{1}\log(2/\delta)/{\varepsilon} suffices to obtain hm,kâ€‹(xâ‹…y)=nÂ±Îµsubscriptâ„

ğ‘šğ‘˜â‹…ğ‘¥ğ‘¦plus-or-minusğ‘›ğœ€h\_{m,k}(x\cdot y)=n\pm{\varepsilon} with failure probability Î´ğ›¿\delta.
The result follows.
âˆ

### 7.2 Counting Bloom Filters

In another sparse binary model, bundling is done by addition in instead of disjunction, so a bundle is simply Bâ€‹vğµğ‘£Bv instead of 1âˆ§Bâ€‹v1ğµğ‘£1\wedge Bv.
In the data structures literature, this is a *counting* variant of a Bloom filter.
Here BğµB is chosen to be sparse in a slightly different way than for Bloom filters:
each atomic vector Bâˆ—jsubscriptğµabsentğ‘—B\_{\*j} for jâˆˆ[m]ğ‘—delimited-[]ğ‘šj\in[m] has all vectors with kğ‘˜k ones equally likely, or equivalently, is created by starting from a vector of all zeros, in each trial picking iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m] uniformly at random, setting Biâ€‹jâ†’1â†’subscriptğµğ‘–ğ‘—1B\_{ij}\rightarrow 1, until there are kğ‘˜k nonzeros.

When the sparsity is block-structured, that is, an atomic mğ‘šm-vector has mğ‘šm divisible byÂ kğ‘˜k, and there areÂ kğ‘˜k blocks each with exactly one nonzero entry, then the resulting bundling is called a *count-min sketch* in the data structures literature, and the Sparse Block Codes model in the VSA literature.
See [cormode\_improved\_2005] and [laiho\_high-dimensional\_2015] respectively for more information.

[cormode\_improved\_2005] showed that dot product estimation for two bundles can be done as a nonlinear operation: taking dot products of corresponding blocks and then the minimum of these kğ‘˜k dot products.
The resulting estimate Xğ‘‹X of vâ‹…wâ‹…ğ‘£ğ‘¤v\cdot w using Bâ€‹vğµğ‘£Bv and Bâ€‹wğµğ‘¤Bw has vâ‹…wâ‰¤Xâ‰¤vâ‹…w+Îµâ‹…ğ‘£ğ‘¤ğ‘‹â‹…ğ‘£ğ‘¤ğœ€v\cdot w\leq X\leq v\cdot w+{\varepsilon} with failure probability Î´ğ›¿\delta, for m=kâ€‹mâ€²ğ‘šğ‘˜superscriptğ‘šâ€²m=km^{\prime} where k=Oâ€‹(logâ¡(1/Î´))ğ‘˜ğ‘‚1ğ›¿k=O(\log(1/\delta)) and
mâ€²=Oâ€‹(â€–vâ€–1â€‹â€–wâ€–1/Îµ)superscriptğ‘šâ€²ğ‘‚subscriptnormğ‘£1subscriptnormğ‘¤1ğœ€m^{\prime}=O(\|v\|\_{1}\|w\|\_{1}/{\varepsilon}).
For v,wâˆˆ{0,1}d

ğ‘£ğ‘¤
superscript01ğ‘‘v,w\in\{0,1\}^{d}, the dimension mğ‘šm needed for estimating set intersection size has a smaller dependence on Îµğœ€{\varepsilon}, but possibly worse dependence on â€–vâ€–1subscriptnormğ‘£1\|v\|\_{1}, â€–wâ€–1subscriptnormğ‘¤1\|w\|\_{1}, and vâ‹…wâ‹…ğ‘£ğ‘¤v\cdot w
than what we showed for Bloom filters.
This is because â€–vâ€–1â€‹â€–wâ€–1=(nv+n)â€‹(nw+n)â‰¥nvâ€‹nw+n2subscriptnormğ‘£1subscriptnormğ‘¤1subscriptğ‘›ğ‘£ğ‘›subscriptğ‘›ğ‘¤ğ‘›subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤superscriptğ‘›2\|v\|\_{1}\|w\|\_{1}=(n\_{v}+n)(n\_{w}+n)\geq n\_{v}n\_{w}+n^{2}, where nğ‘›n, nvsubscriptğ‘›ğ‘£n\_{v}, and nwsubscriptğ‘›ğ‘¤n\_{w} are defined in Theorem [22](#Thmtheorem22 "Theorem 22. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures").

Beyond the setting above, vğ‘£v and wğ‘¤w may have entries that are nonnegative integers, corresponding to multi-sets (sets where each element appears with some multiplicity).
Dot products for such multi-sets have applications in database operations.
However, one could also consider an analog of set intersection for multi-sets where the multiplicity of an element in the intersection is the minimum of its multiplicities in the two intersected multi-sets.
The size of the intersection, defined in this way, can also be estimated using bundles of sparse binary atomic vectors.
This operation will be analyzed next.
For x,yâˆˆIâ€‹Rm

ğ‘¥ğ‘¦
superscriptIRğ‘šx,y\in\operatorname{{\mathrm{I\!R}}}^{m}, let xâˆ§yğ‘¥ğ‘¦x\wedge y denote the vector zğ‘§z with zi=minâ¡{xi,yi}subscriptğ‘§ğ‘–subscriptğ‘¥ğ‘–subscriptğ‘¦ğ‘–z\_{i}=\min\{x\_{i},y\_{i}\}.
As discussed, on nonnegative vectors, we define the operation
xâˆ§â‹…yâ‰¡â€–xâˆ§yâ€–1=âˆ‘iâˆˆ[m]minâ¡{xi,yi}fragmentsfragmentsâ‹…ğ‘¥ğ‘¦subscriptnormğ‘¥ğ‘¦1subscriptğ‘–delimited-[]ğ‘šsubscriptğ‘¥ğ‘–subscriptğ‘¦ğ‘–x\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}y\equiv\|x\wedge y\|\_{1}=\sum\_{i\in[m]}\min\{x\_{i},y\_{i}\}.
Note that â€–xâˆ’yâ€–1=â€–xâ€–1+â€–yâ€–1âˆ’2â€‹(xâˆ§â‹…y)subscriptnormğ‘¥ğ‘¦1subscriptnormğ‘¥1subscriptnormğ‘¦12fragmentsfragmentsâ‹…ğ‘¥ğ‘¦\|x-y\|\_{1}=\|x\|\_{1}+\|y\|\_{1}-2(x\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}y), analogous to
â€–xâˆ’yâ€–22=â€–xâ€–22+â€–yâ€–22âˆ’2â€‹(xâ‹…y)superscriptsubscriptnormğ‘¥ğ‘¦22superscriptsubscriptnormğ‘¥22superscriptsubscriptnormğ‘¦222â‹…ğ‘¥ğ‘¦\|x-y\|\_{2}^{2}=\|x\|\_{2}^{2}+\|y\|\_{2}^{2}-2(x\cdot y).

###### Theorem (Restatement of Theorem [23](#Thmtheorem23 "Theorem 23. â€£ 2.5 Sparse Binary Bundling and Bloom Filter Analysis â€£ 2 Technical Overview and Statements of Results â€£ Capacity Analysis of Vector Symbolic Architectures")).

Let v,wâˆˆâ„â‰¥0d

ğ‘£ğ‘¤
superscriptsubscriptâ„absent0ğ‘‘v,w\in{\mathbb{R}}\_{\geq 0}^{d}. Let Kbâ‰¡â€–vâˆ’wâ€–âˆâ‰¤maxâ¡{â€–vâ€–âˆ,â€–wâ€–âˆ}subscriptğ¾ğ‘subscriptnormğ‘£ğ‘¤subscriptnormğ‘£subscriptnormğ‘¤K\_{b}\equiv\|v-w\|\_{\infty}\leq\max\{\|v\|\_{\infty},\|w\|\_{\infty}\}, and define:

|  |  |  |
| --- | --- | --- |
|  | nâ‰¡vâˆ§â‹…w,nvâ‰¡â€–vâ€–1âˆ’n,nwâ‰¡â€–wâ€–1âˆ’n,formulae-sequenceğ‘›fragmentsfragmentsâ‹…ğ‘£ğ‘¤formulae-sequencesubscriptğ‘›ğ‘£subscriptnormğ‘£1ğ‘›subscriptğ‘›ğ‘¤subscriptnormğ‘¤1ğ‘›n\equiv v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w,\;\;\;\;\;\;n\_{v}\equiv\|v\|\_{1}-n,\;\;\;\;\;\;n\_{w}\equiv\|w\|\_{1}-n, |  |

Let x=Bâ€‹vğ‘¥ğµğ‘£x=Bv and y=Bâ€‹wğ‘¦ğµğ‘¤y=Bw, where Bâˆˆ{0,1}mÃ—dğµsuperscript01ğ‘šğ‘‘B\in\{0,1\}^{m\times d} is a sparse binary matrix.
Then, for Î´âˆˆ(0,1)ğ›¿01\delta\in(0,1) and Îµ>0ğœ€0{\varepsilon}>0, there are
k=Oâ€‹(Kbâ€‹Îµâˆ’1â€‹logâ¡(1/Î´))ğ‘˜ğ‘‚subscriptğ¾ğ‘superscriptğœ€11ğ›¿k=O(K\_{b}{\varepsilon}^{-1}\log(1/\delta)) and m=12â€‹Ï€2â€‹kâ€‹Îµâˆ’1â€‹nvâ€‹nw=Oâ€‹(Kbâ€‹Îµâˆ’2â€‹nvâ€‹nwâ€‹logâ¡(1/Î´))ğ‘š12superscriptğœ‹2ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘‚subscriptğ¾ğ‘superscriptğœ€2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤1ğ›¿m=12\pi^{2}k{\varepsilon}^{-1}n\_{v}n\_{w}=O(K\_{b}{\varepsilon}^{-2}n\_{v}n\_{w}\log(1/\delta)) such that

|  |  |  |
| --- | --- | --- |
|  | 1kâ€‹(xâˆ§â‹…y)âˆ’(vâˆ§â‹…w)âˆˆ[0,Ïµ)1ğ‘˜fragmentsfragmentsâ‹…ğ‘¥ğ‘¦fragmentsfragmentsâ‹…ğ‘£ğ‘¤0italic-Ïµ\frac{1}{k}(x\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}y)-(v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w)\in[0,\epsilon) |  |

with failure probability at mostÂ Î´ğ›¿\delta.
Since nv+nw=â€–vâˆ’wâ€–1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤subscriptnormğ‘£ğ‘¤1n\_{v}+n\_{w}=\|v-w\|\_{1}, m=Oâ€‹(Kbâ€‹Îµâˆ’2â€‹â€–vâˆ’wâ€–12â€‹logâ¡(1/Î´))ğ‘šğ‘‚subscriptğ¾ğ‘superscriptğœ€2superscriptsubscriptnormğ‘£ğ‘¤121ğ›¿m=O(K\_{b}{\varepsilon}^{-2}\|v-w\|\_{1}^{2}\log(1/\delta)) also suffices (using the AM-GM inequality on nvâ€‹nwsubscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤n\_{v}n\_{w}).
If â€–vâ€–1,â€–wâ€–1

subscriptnormğ‘£1subscriptnormğ‘¤1\|v\|\_{1},\|w\|\_{1} are stored, then â€–vâˆ’wâ€–1subscriptnormğ‘£ğ‘¤1\|v-w\|\_{1} can be estimated up to additive Îµğœ€{\varepsilon} with the sameÂ mğ‘šm.

###### Proof.

Let v~â‰¡vâˆ’(vâˆ§w)~ğ‘£ğ‘£ğ‘£ğ‘¤{\tilde{v}}\equiv v-(v\wedge w), w~â‰¡wâˆ’(vâˆ§w)~ğ‘¤ğ‘¤ğ‘£ğ‘¤{\tilde{w}}\equiv w-(v\wedge w) and x~â‰¡Bâ€‹v~~ğ‘¥ğµ~ğ‘£{\tilde{x}}\equiv B{\tilde{v}}, y~â‰¡Bâ€‹w~~ğ‘¦ğµ~ğ‘¤{\tilde{y}}\equiv B{\tilde{w}}.
Note that nv=â€–v~â€–1subscriptğ‘›ğ‘£subscriptnorm~ğ‘£1n\_{v}=\|{\tilde{v}}\|\_{1}, nw=â€–w~â€–1subscriptğ‘›ğ‘¤subscriptnorm~ğ‘¤1n\_{w}=\|{\tilde{w}}\|\_{1}.
Using minâ¡{c+a,c+b}=c+minâ¡{a,b}ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘\min\{c+a,c+b\}=c+\min\{a,b\}, we have

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | 1kâ€‹(xâˆ§â‹…y)1ğ‘˜fragmentsfragmentsâ‹…ğ‘¥ğ‘¦\displaystyle\frac{1}{k}(x\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}y) | =1kâ€‹(Bâ€‹vâˆ§â‹…Bâ€‹w)absent1ğ‘˜fragmentsfragmentsâ‹…ğµğ‘£ğµğ‘¤\displaystyle=\frac{1}{k}(Bv\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}Bw) |  | (24) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =1kâ€‹(Bâ€‹(vâˆ§w)+Bâ€‹v~)âˆ§â‹…(Bâ€‹(vâˆ§w)+Bâ€‹w~)absentfragmentsfragmentsâ‹…1ğ‘˜ğµğ‘£ğ‘¤ğµ~ğ‘£ğµğ‘£ğ‘¤ğµ~ğ‘¤\displaystyle=\frac{1}{k}(B(v\wedge w)+B{\tilde{v}})\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}(B(v\wedge w)+B{\tilde{w}}) |  | (27) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =1kâ€‹1â†’mâŠ¤â€‹Bâ€‹(vâˆ§w)+1kâ€‹(Bâ€‹v~âˆ§â‹…Bâ€‹w~)absent1ğ‘˜superscriptsubscriptâ†’1ğ‘štopğµğ‘£ğ‘¤1ğ‘˜fragmentsfragmentsâ‹…ğµ~ğ‘£ğµ~ğ‘¤\displaystyle=\frac{1}{k}\vec{1}\_{m}^{\top}B(v\wedge w)+\frac{1}{k}(B{\tilde{v}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}B{\tilde{w}}) |  | (30) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =vâˆ§â‹…w+1kâ€‹(x~âˆ§â‹…y~).absentfragmentsfragmentsâ‹…ğ‘£ğ‘¤1ğ‘˜fragmentsfragmentsâ‹…~ğ‘¥~ğ‘¦\displaystyle=v\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}w+\frac{1}{k}({\tilde{x}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}}). |  | (35) |

It remains to bound 1kâ€‹(x~âˆ§â‹…y~)1ğ‘˜fragmentsfragmentsâ‹…~ğ‘¥~ğ‘¦\frac{1}{k}({\tilde{x}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}}).
We have v~âˆ˜w~=0~ğ‘£~ğ‘¤0{\tilde{v}}\circ{\tilde{w}}=0, so for every iâˆˆ[m]ğ‘–delimited-[]ğ‘ši\in[m], Biâ£âˆ—â€‹v~subscriptğµ

ğ‘–~ğ‘£B\_{i\*}{\tilde{v}} is independent of Biâ£âˆ—â€‹w~subscriptğµ

ğ‘–~ğ‘¤B\_{i\*}{\tilde{w}}.
Therefore,

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[x~iâˆ§y~iâ‰¥z]=Prâ¡[x~iâ‰¥z]â€‹Prâ¡[y~iâ‰¥z]Prsubscript~ğ‘¥ğ‘–subscript~ğ‘¦ğ‘–ğ‘§Prsubscript~ğ‘¥ğ‘–ğ‘§Prsubscript~ğ‘¦ğ‘–ğ‘§\Pr[{\tilde{x}}\_{i}\wedge{\tilde{y}}\_{i}\geq z]=\Pr[{\tilde{x}}\_{i}\geq z]\Pr[{\tilde{y}}\_{i}\geq z] |  |

Since â€–v~â€–1=nvsubscriptnorm~ğ‘£1subscriptğ‘›ğ‘£\|{\tilde{v}}\|\_{1}=n\_{v}, ğ”¼â€‹[x~i]=kâ€‹nv/mğ”¼delimited-[]subscript~ğ‘¥ğ‘–ğ‘˜subscriptğ‘›ğ‘£ğ‘š{\mathbb{E}}[{\tilde{x}}\_{i}]=kn\_{v}/m, and so by Markovâ€™s inequality Prâ¡[x~iâ‰¥z]â‰¤kâ€‹nv/(zâ€‹m)Prsubscript~ğ‘¥ğ‘–ğ‘§ğ‘˜subscriptğ‘›ğ‘£ğ‘§ğ‘š\Pr[{\tilde{x}}\_{i}\geq z]\leq kn\_{v}/(zm).
Similarly, Prâ¡[y~iâ‰¥z]â‰¤kâ€‹nw/(zâ€‹m)Prsubscript~ğ‘¦ğ‘–ğ‘§ğ‘˜subscriptğ‘›ğ‘¤ğ‘§ğ‘š\Pr[{\tilde{y}}\_{i}\geq z]\leq kn\_{w}/(zm).
Using the identity ğ”¼â€‹[Y]=âˆ‘zâ‰¥1Prâ¡[Yâ‰¥z]ğ”¼delimited-[]ğ‘Œsubscriptğ‘§1Prğ‘Œğ‘§{\mathbb{E}}[Y]=\sum\_{z\geq 1}\Pr[Y\geq z],

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[x~iâˆ§y~i]ğ”¼delimited-[]subscript~ğ‘¥ğ‘–subscript~ğ‘¦ğ‘–\displaystyle{\mathbb{E}}[{\tilde{x}}\_{i}\wedge{\tilde{y}}\_{i}] | =âˆ‘zâ‰¥1Prâ¡[x~iâˆ§y~iâ‰¥z]=âˆ‘zâ‰¥1Prâ¡[x~iâ‰¥z]â€‹Prâ¡[y~iâ‰¥z]absentsubscriptğ‘§1Prsubscript~ğ‘¥ğ‘–subscript~ğ‘¦ğ‘–ğ‘§subscriptğ‘§1Prsubscript~ğ‘¥ğ‘–ğ‘§Prsubscript~ğ‘¦ğ‘–ğ‘§\displaystyle=\sum\_{z\geq 1}\Pr[{\tilde{x}}\_{i}\wedge{\tilde{y}}\_{i}\geq z]=\sum\_{z\geq 1}\Pr[{\tilde{x}}\_{i}\geq z]\Pr[{\tilde{y}}\_{i}\geq z] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤âˆ‘zâ‰¥1(kâ€‹nv/(mâ€‹z))â€‹(kâ€‹nw/(mâ€‹z))=Î¶â€‹(2)â‹…k2â€‹nvâ€‹nwm2=Ï€26â‹…k2â€‹nvâ€‹nwm2,absentsubscriptğ‘§1ğ‘˜subscriptğ‘›ğ‘£ğ‘šğ‘§ğ‘˜subscriptğ‘›ğ‘¤ğ‘šğ‘§â‹…ğœ2superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤superscriptğ‘š2â‹…superscriptğœ‹26superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤superscriptğ‘š2\displaystyle\leq\sum\_{z\geq 1}(kn\_{v}/(mz))(kn\_{w}/(mz))=\zeta(2)\cdot\frac{k^{2}n\_{v}n\_{w}}{m^{2}}=\frac{\pi^{2}}{6}\cdot\frac{k^{2}n\_{v}n\_{w}}{m^{2}}, |  |

where Î¶â€‹(2)=âˆ‘zâ‰¥11/z2ğœ2subscriptğ‘§11superscriptğ‘§2\zeta(2)=\sum\_{z\geq 1}1/z^{2} is the Riemann zeta function.
Thus

|  |  |  |  |
| --- | --- | --- | --- |
|  | ğ”¼â€‹[x~âˆ§â‹…y~]â‰¤Ï€26â‹…k2â€‹nvâ€‹nwm.ğ”¼delimited-[]fragmentsfragmentsâ‹…~ğ‘¥~ğ‘¦â‹…superscriptğœ‹26superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘š{\mathbb{E}}[{\tilde{x}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}}]\leq\frac{\pi^{2}}{6}\cdot\frac{k^{2}n\_{v}n\_{w}}{m}. |  | (36) |

It remains to show that x~âˆ§â‹…y~fragmentsfragmentsâ‹…~ğ‘¥~ğ‘¦{\tilde{x}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}} concentrates.
We will use the Bernstein form of McDiarmidâ€™s inequality (TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures")), showing concentration of a function fâ€‹(X)ğ‘“ğ‘‹f(X).
Here Xâˆˆ[m]ntğ‘‹superscriptdelimited-[]ğ‘šsubscriptğ‘›ğ‘¡X\in[m]^{n\_{t}} for ntâ‰¡kâ€‹â€–v~+w~â€–0â‰¤kâ€‹(nv+nw)subscriptğ‘›ğ‘¡ğ‘˜subscriptnorm~ğ‘£~ğ‘¤0ğ‘˜subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤n\_{t}\equiv k\|{\tilde{v}}+{\tilde{w}}\|\_{0}\leq k(n\_{v}+n\_{w}), and each Xrsubscriptğ‘‹ğ‘ŸX\_{r}, for râˆˆ[nt]ğ‘Ÿdelimited-[]subscriptğ‘›ğ‘¡r\in[n\_{t}], maps to a column jğ‘—j of BğµB where v~j+w~j>0subscript~ğ‘£ğ‘—subscript~ğ‘¤ğ‘—0{\tilde{v}}\_{j}+{\tilde{w}}\_{j}>0, and for random i=Xrâˆˆ[m]ğ‘–subscriptğ‘‹ğ‘Ÿdelimited-[]ğ‘ši=X\_{r}\in[m], Biâ€‹jsubscriptğµğ‘–ğ‘—B\_{ij} is incremented by one.
The function fâ€‹(X)ğ‘“ğ‘‹f(X) is then fâ€‹(X)=Bâ€‹v~âˆ§â‹…Bâ€‹w~ğ‘“ğ‘‹fragmentsfragmentsâ‹…ğµ~ğ‘£ğµ~ğ‘¤f(X)=B{\tilde{v}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}B{\tilde{w}}, where BğµB is determined by Xğ‘‹X.
To use TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), we need to bound Ïƒ~â€‹(f)~ğœğ‘“{\tilde{\sigma}}(f) and Bâ€‹(f)ğµğ‘“B(f) of that theorem, bounding the effects of changes of single entries of Xğ‘‹X.

Suppose Bâ€²superscriptğµâ€²B^{\prime} is the result of the choices of Xğ‘‹X, for all entries except for entry Xrsubscriptğ‘‹ğ‘ŸX\_{r}, where Xrsubscriptğ‘‹ğ‘ŸX\_{r} maps to column jğ‘—j, and to a random Iâˆˆ[m]ğ¼delimited-[]ğ‘šI\in[m].
Then the resulting B=Bâ€²+eIâ€‹ejâŠ¤ğµsuperscriptğµâ€²subscriptğ‘’ğ¼superscriptsubscriptğ‘’ğ‘—topB=B^{\prime}+e\_{I}e\_{j}^{\top}, where ejâˆˆ{0,1}dsubscriptğ‘’ğ‘—superscript01ğ‘‘e\_{j}\in\{0,1\}^{d} (with the 111 in the jğ‘—j position) and eIâˆˆ{0,1}msubscriptğ‘’ğ¼superscript01ğ‘še\_{I}\in\{0,1\}^{m} (with the 111 in the Iğ¼I position) are natural basis vectors, and
Bâ€‹v=Bâ€²â€‹v+eIâ€‹ejâŠ¤â€‹v=Bâ€²â€‹v+vjâ€‹eIğµğ‘£superscriptğµâ€²ğ‘£subscriptğ‘’ğ¼superscriptsubscriptğ‘’ğ‘—topğ‘£superscriptğµâ€²ğ‘£subscriptğ‘£ğ‘—subscriptğ‘’ğ¼Bv=B^{\prime}v+e\_{I}e\_{j}^{\top}v=B^{\prime}v+v\_{j}e\_{I}.

Here giâ€‹(X,y)subscriptğ‘”ğ‘–ğ‘‹ğ‘¦g\_{i}(X,y) of TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures") corresponds to
gâ€‹(Bâ€²,j,I)=(Bâ€²+eIâ€‹ejâŠ¤)â€‹v~âˆ§â‹…(Bâ€²+eIâ€‹ejâŠ¤)â€‹w~ğ‘”superscriptğµâ€²ğ‘—ğ¼fragmentsfragmentsâ‹…superscriptğµâ€²subscriptğ‘’ğ¼superscriptsubscriptğ‘’ğ‘—top~ğ‘£superscriptğµâ€²subscriptğ‘’ğ¼superscriptsubscriptğ‘’ğ‘—top~ğ‘¤g(B^{\prime},j,I)=(B^{\prime}+e\_{I}e\_{j}^{\top}){\tilde{v}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}(B^{\prime}+e\_{I}e\_{j}^{\top}){\tilde{w}},
and we need to bound, over all Bâ€²superscriptğµâ€²B^{\prime} and jğ‘—j, Variâ€‹[gâ€‹(Bâ€²,j,i)]subscriptVarğ‘–delimited-[]ğ‘”superscriptğµâ€²ğ‘—ğ‘–{\textbf{Var}}\_{i}[g(B^{\prime},j,i)] and
maxi|g(Bâ€²,j,i)âˆ’ğ”¼iâ€²g(Bâ€²,j,iâ€²)]|\max\_{i}|g(B^{\prime},j,i)-{\mathbb{E}}\_{i^{\prime}}g(B^{\prime},j,i^{\prime})]|.
Again noting that because addition distributes over minimization, we can let
xâ€²â‰¡Bâ€²â€‹v~âˆ’(Bâ€²â€‹v~âˆ§Bâ€²â€‹w~)superscriptğ‘¥â€²superscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘¤x^{\prime}\equiv B^{\prime}{\tilde{v}}-(B^{\prime}{\tilde{v}}\wedge B^{\prime}{\tilde{w}}) and yâ€²â‰¡Bâ€²â€‹w~âˆ’(Bâ€²â€‹v~âˆ§Bâ€²â€‹w~)superscriptğ‘¦â€²superscriptğµâ€²~ğ‘¤superscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘¤y^{\prime}\equiv B^{\prime}{\tilde{w}}-(B^{\prime}{\tilde{v}}\wedge B^{\prime}{\tilde{w}}), and write

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | gâ€‹(Bâ€²,j,I)ğ‘”superscriptğµâ€²ğ‘—ğ¼\displaystyle g(B^{\prime},j,I) | =(Bâ€²â€‹v~+eIâ€‹v~j)âˆ§â‹…(Bâ€²â€‹w~+eIâ€‹w~j)absentfragmentsfragmentsâ‹…superscriptğµâ€²~ğ‘£subscriptğ‘’ğ¼subscript~ğ‘£ğ‘—superscriptğµâ€²~ğ‘¤subscriptğ‘’ğ¼subscript~ğ‘¤ğ‘—\displaystyle=(B^{\prime}{\tilde{v}}+e\_{I}{\tilde{v}}\_{j})\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}(B^{\prime}{\tilde{w}}+e\_{I}{\tilde{w}}\_{j}) |  | (39) |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =[(Bâ€²â€‹v~)I+v~j]âˆ§[(Bâ€²â€‹w~)Iâˆ’w~j]+âˆ‘iâ‰ I(Bâ€²â€‹v~âˆ§Bâ€²â€‹w~)iabsentdelimited-[]subscriptsuperscriptğµâ€²~ğ‘£ğ¼subscript~ğ‘£ğ‘—delimited-[]subscriptsuperscriptğµâ€²~ğ‘¤ğ¼subscript~ğ‘¤ğ‘—subscriptğ‘–ğ¼subscriptsuperscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘¤ğ‘–\displaystyle=[(B^{\prime}{\tilde{v}})\_{I}+{\tilde{v}}\_{j}]\wedge[(B^{\prime}{\tilde{w}})\_{I}-{\tilde{w}}\_{j}]+\sum\_{i\neq I}(B^{\prime}{\tilde{v}}\wedge B^{\prime}{\tilde{w}})\_{i} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =[(Bâ€²â€‹v~)I+v~jâˆ’((Bâ€²â€‹v~)Iâˆ§(Bâ€²â€‹w~)I)]absentdelimited-[]subscriptsuperscriptğµâ€²~ğ‘£ğ¼subscript~ğ‘£ğ‘—subscriptsuperscriptğµâ€²~ğ‘£ğ¼subscriptsuperscriptğµâ€²~ğ‘¤ğ¼\displaystyle=[(B^{\prime}{\tilde{v}})\_{I}+{\tilde{v}}\_{j}-((B^{\prime}{\tilde{v}})\_{I}\wedge(B^{\prime}{\tilde{w}})\_{I})] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | âˆ§[(Bâ€²â€‹w~)I+w~jâˆ’((Bâ€²â€‹v~)Iâˆ§(Bâ€²â€‹w~)I)]delimited-[]subscriptsuperscriptğµâ€²~ğ‘¤ğ¼subscript~ğ‘¤ğ‘—subscriptsuperscriptğµâ€²~ğ‘£ğ¼subscriptsuperscriptğµâ€²~ğ‘¤ğ¼\displaystyle\;\;\;\;\;\;\;\;\wedge[(B^{\prime}{\tilde{w}})\_{I}+{\tilde{w}}\_{j}-((B^{\prime}{\tilde{v}})\_{I}\wedge(B^{\prime}{\tilde{w}})\_{I})] |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | +((Bâ€²â€‹v~)Iâˆ§(Bâ€²â€‹w~)I)+âˆ‘iâ‰ I(Bâ€²â€‹v~âˆ§Bâ€²â€‹w~)isubscriptsuperscriptğµâ€²~ğ‘£ğ¼subscriptsuperscriptğµâ€²~ğ‘¤ğ¼subscriptğ‘–ğ¼subscriptsuperscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘¤ğ‘–\displaystyle\;\;\;\;\;\;\;\;+((B^{\prime}{\tilde{v}})\_{I}\wedge(B^{\prime}{\tilde{w}})\_{I})+\sum\_{i\neq I}(B^{\prime}{\tilde{v}}\wedge B^{\prime}{\tilde{w}})\_{i} |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =(xIâ€²+v~j)âˆ§(yIâ€²+w~j)+(Bâ€²â€‹v~âˆ§â‹…Bâ€²â€‹w~)absentsubscriptsuperscriptğ‘¥â€²ğ¼subscript~ğ‘£ğ‘—subscriptsuperscriptğ‘¦â€²ğ¼subscript~ğ‘¤ğ‘—fragmentsfragmentsâ‹…superscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘¤\displaystyle=(x^{\prime}\_{I}+{\tilde{v}}\_{j})\wedge(y^{\prime}\_{I}+{\tilde{w}}\_{j})+(B^{\prime}{\tilde{v}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}B^{\prime}{\tilde{w}}) |  | (42) |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  |  | =(Bâ€²â€‹v~âˆ§â‹…Bâ€²â€‹w~)+Î²Iâ€‹j,absentfragmentsfragmentsâ‹…superscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘¤subscriptğ›½ğ¼ğ‘—\displaystyle=(B^{\prime}{\tilde{v}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}B^{\prime}{\tilde{w}})+\beta\_{Ij}, |  | (45) |

where Î²Iâ€‹jâ‰¡(xIâ€²+v~j)âˆ§(yIâ€²+w~j)subscriptğ›½ğ¼ğ‘—subscriptsuperscriptğ‘¥â€²ğ¼subscript~ğ‘£ğ‘—subscriptsuperscriptğ‘¦â€²ğ¼subscript~ğ‘¤ğ‘—\beta\_{Ij}\equiv(x^{\prime}\_{I}+{\tilde{v}}\_{j})\wedge(y^{\prime}\_{I}+{\tilde{w}}\_{j}).

Since the choices of Iğ¼I and jğ‘—j donâ€™t affect (Bâ€²â€‹v~âˆ§â‹…Bâ€²â€‹w~)fragmentsfragmentsâ‹…superscriptğµâ€²~ğ‘£superscriptğµâ€²~ğ‘¤(B^{\prime}{\tilde{v}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}B^{\prime}{\tilde{w}}), only Î²Iâ€‹jsubscriptğ›½ğ¼ğ‘—\beta\_{Ij} affects Ïƒ~â€‹(f)~ğœğ‘“{\tilde{\sigma}}(f) and Bâ€‹(f)ğµğ‘“B(f).
As v~âˆ˜w~=0~ğ‘£~ğ‘¤0{\tilde{v}}\circ{\tilde{w}}=0, we first assume that v~j>w~j=0subscript~ğ‘£ğ‘—subscript~ğ‘¤ğ‘—0{\tilde{v}}\_{j}>{\tilde{w}}\_{j}=0.
Under that assumption, since xâ€²âˆ˜yâ€²=0superscriptğ‘¥â€²superscriptğ‘¦â€²0x^{\prime}\circ y^{\prime}=0, either Î²Iâ€‹j=0subscriptğ›½ğ¼ğ‘—0\beta\_{Ij}=0 or
Î²Iâ€‹j=yIâ€²âˆ§v~jsubscriptğ›½ğ¼ğ‘—subscriptsuperscriptğ‘¦â€²ğ¼subscript~ğ‘£ğ‘—\beta\_{Ij}=y^{\prime}\_{I}\wedge{\tilde{v}}\_{j}, and so â€–Î²âˆ—jâ€–âˆâ‰¤â€–v~â€–âˆsubscriptnormsubscriptğ›½absentğ‘—subscriptnorm~ğ‘£\|\beta\_{\*j}\|\_{\infty}\leq\|{\tilde{v}}\|\_{\infty} for allÂ jğ‘—j.

Allowing for the possibility that w~j>v~j=0subscript~ğ‘¤ğ‘—subscript~ğ‘£ğ‘—0{\tilde{w}}\_{j}>{\tilde{v}}\_{j}=0 and that sometimes Î²iâ€‹j=0subscriptğ›½ğ‘–ğ‘—0\beta\_{ij}=0, we have

|  |  |  |  |
| --- | --- | --- | --- |
|  | Bâ€‹(f)=ğµğ‘“absent\displaystyle B(f)= | maxBâ€²,j,i|g(Bâ€²,j,i)âˆ’ğ”¼Iâ€²g(Bâ€²,j,Iâ€²)]|\displaystyle\max\_{B^{\prime},j,i}|g(B^{\prime},j,i)-{\mathbb{E}}\_{I^{\prime}}g(B^{\prime},j,I^{\prime})]| |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | =\displaystyle= | maxBâ€²,j,i|Î²iâ€‹jâˆ’ğ”¼Iâ€²Î²Iâ€²â€‹j]|from([45](#S7.E45 "In Proof. â€£ 7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures"))\displaystyle\max\_{B^{\prime},j,i}|\beta\_{ij}-{\mathbb{E}}\_{I^{\prime}}\beta\_{I^{\prime}j}]|\qquad\mathrm{\ from\ \eqref{eq g fac}} |  |
|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | â‰¤\displaystyle\leq | maxâ¡{â€–v~â€–âˆ,â€–w~â€–âˆ}=â€–vâˆ’wâ€–âˆ=Kb.subscriptnorm~ğ‘£subscriptnorm~ğ‘¤subscriptnormğ‘£ğ‘¤subscriptğ¾ğ‘\displaystyle\max\{\|{\tilde{v}}\|\_{\infty},\|{\tilde{w}}\|\_{\infty}\}=\|v-w\|\_{\infty}=K\_{b}. |  | (46) |

Also, under the assumption for given jâˆˆ[d]ğ‘—delimited-[]ğ‘‘j\in[d] that v~j>w~j=0subscript~ğ‘£ğ‘—subscript~ğ‘¤ğ‘—0{\tilde{v}}\_{j}>{\tilde{w}}\_{j}=0,

|  |  |  |  |
| --- | --- | --- | --- |
|  | Varrâ€‹(f)=subscriptVarğ‘Ÿğ‘“absent\displaystyle{\textbf{Var}}\_{r}(f)= | supBâ€²ğ”¼I[(Î²Iâ€‹jâˆ’ğ”¼Iâ€²Î²Iâ€²â€‹j])2]â‰¤supBâ€²ğ”¼I[Î²Iâ€‹j2]â‰¤supBâ€²ğ”¼I[(yIâ€²âˆ§v~j)2]usingv~j>w~j=0\displaystyle\sup\_{B^{\prime}}{\mathbb{E}}\_{I}[(\beta\_{Ij}-{\mathbb{E}}\_{I^{\prime}}\beta\_{I^{\prime}j}])^{2}]\leq\sup\_{B^{\prime}}{\mathbb{E}}\_{I}[\beta\_{Ij}^{2}]\leq\sup\_{B^{\prime}}{\mathbb{E}}\_{I}[(y^{\prime}\_{I}\wedge{\tilde{v}}\_{j})^{2}]\mathrm{\ using\ }{\tilde{v}}\_{j}>{\tilde{w}}\_{j}=0 |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | â‰¤\displaystyle\leq | supBâ€²v~jâ€‹ğ”¼Iâ€‹[yIâ€²âˆ§v~j]â‰¤supBâ€²v~jâ€‹ğ”¼Iâ€‹[yIâ€²]=supBâ€²v~jâ€‹â€–yâ€²â€–1/msubscriptsupremumsuperscriptğµâ€²subscript~ğ‘£ğ‘—subscriptğ”¼ğ¼delimited-[]subscriptsuperscriptğ‘¦â€²ğ¼subscript~ğ‘£ğ‘—subscriptsupremumsuperscriptğµâ€²subscript~ğ‘£ğ‘—subscriptğ”¼ğ¼delimited-[]subscriptsuperscriptğ‘¦â€²ğ¼subscriptsupremumsuperscriptğµâ€²subscript~ğ‘£ğ‘—subscriptnormsuperscriptğ‘¦â€²1ğ‘š\displaystyle\sup\_{B^{\prime}}{\tilde{v}}\_{j}{\mathbb{E}}\_{I}[y^{\prime}\_{I}\wedge{\tilde{v}}\_{j}]\leq\sup\_{B^{\prime}}{\tilde{v}}\_{j}{\mathbb{E}}\_{I}[y^{\prime}\_{I}]=\sup\_{B^{\prime}}{\tilde{v}}\_{j}\|y^{\prime}\|\_{1}/m |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  | â‰¤\displaystyle\leq | kâ€‹v~jâ€‹â€–w~â€–1/m.ğ‘˜subscript~ğ‘£ğ‘—subscriptnorm~ğ‘¤1ğ‘š\displaystyle k{\tilde{v}}\_{j}\|{\tilde{w}}\|\_{1}/m. |  |

Combining this with an analogous expression when w~j>v~j=0subscript~ğ‘¤ğ‘—subscript~ğ‘£ğ‘—0{\tilde{w}}\_{j}>{\tilde{v}}\_{j}=0, and summing over all Xrsubscriptğ‘‹ğ‘ŸX\_{r},

|  |  |  |  |
| --- | --- | --- | --- |
|  | Ïƒ~â€‹(f)â‰¤2â€‹k2â€‹â€–v~â€–1â€‹â€–w~â€–1/m=2â€‹k2â€‹nvâ€‹nw/m.~ğœğ‘“2superscriptğ‘˜2subscriptnorm~ğ‘£1subscriptnorm~ğ‘¤1ğ‘š2superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘š{\tilde{\sigma}}(f)\leq 2k^{2}\|{\tilde{v}}\|\_{1}\|{\tilde{w}}\|\_{1}/m=2k^{2}n\_{v}n\_{w}/m. |  | (47) |

We can now apply TheoremÂ [28](#Thmtheorem28 "Theorem 28 ([ying_mcdiarmids_2004]). â€£ 3 Preliminaries and Concentration Inequalities â€£ Capacity Analysis of Vector Symbolic Architectures"), scaling by kğ‘˜k as in the theorem, and using
k=2â€‹Kb3â€‹Îµâˆ’1â€‹logâ¡(1/Î´)ğ‘˜2subscriptğ¾ğ‘3superscriptğœ€11ğ›¿k=\frac{2K\_{b}}{3}{\varepsilon}^{-1}\log(1/\delta) and m=12â€‹Ï€2â€‹kâ€‹Îµâˆ’1â€‹nvâ€‹nw=8â€‹Ï€2â€‹Îµâˆ’2â€‹nvâ€‹nwâ€‹logâ¡(1/Î´)ğ‘š12superscriptğœ‹2ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤8superscriptğœ‹2superscriptğœ€2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤1ğ›¿m=12\pi^{2}k{\varepsilon}^{-1}n\_{v}n\_{w}=8\pi^{2}{\varepsilon}^{-2}n\_{v}n\_{w}\log(1/\delta), to obtain

|  |  |  |  |
| --- | --- | --- | --- |
|  | Pr[x~\displaystyle\Pr[{\tilde{x}} | âˆ§â‹…y~>ğ”¼[x~âˆ§â‹…y~]+kÎµ/2]â‰¤exp(âˆ’2â€‹(k2â€‹Îµ2/4)Ïƒ~â€‹(f)+kâ€‹Îµâ€‹Bâ€‹(f)/6)\displaystyle\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}}>{\mathbb{E}}[{\tilde{x}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}}]+k{\varepsilon}/2]\leq\exp\left(-\frac{2(k^{2}{\varepsilon}^{2}/4)}{{\tilde{\sigma}}(f)+k{\varepsilon}B(f)/6}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤expâ¡(âˆ’k2â€‹Îµ2/2(2â€‹k2â€‹nvâ€‹nw/m)+kâ€‹Îµâ€‹Kb/6)fromâ€‹(â€‹[47](#S7.E47 "In Proof. â€£ 7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")â€‹),(â€‹[46](#S7.E46 "In Proof. â€£ 7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")â€‹)absent  superscriptğ‘˜2superscriptğœ€222superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘šğ‘˜ğœ€subscriptğ¾ğ‘6from([47](#S7.E47 "In Proof. â€£ 7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures"))([46](#S7.E46 "In Proof. â€£ 7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures"))\displaystyle\leq\exp\left(-\frac{k^{2}{\varepsilon}^{2}/2}{(2k^{2}n\_{v}n\_{w}/m)+k{\varepsilon}K\_{b}/6}\right)\qquad\mathrm{\ from\ \eqref{eq tsig count},\eqref{eq B count}} |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | =expâ¡(âˆ’Îµ24â€‹nvâ€‹nw/m+kâˆ’1â€‹Îµâ€‹Kb/3)=expâ¡(âˆ’Îµ2nvâ€‹nw/(3â€‹Ï€2â€‹Îµâˆ’2â€‹nvâ€‹nwâ€‹logâ¡(1/Î´))+Îµ2/2â€‹logâ¡(1/Î´))absentsuperscriptğœ€24subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘šsuperscriptğ‘˜1ğœ€subscriptğ¾ğ‘3superscriptğœ€2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤3superscriptğœ‹2superscriptğœ€2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤1ğ›¿superscriptğœ€221ğ›¿\displaystyle=\exp\left(-\frac{{\varepsilon}^{2}}{4n\_{v}n\_{w}/m+k^{-1}{\varepsilon}K\_{b}/3}\right)=\exp\left(-\frac{{\varepsilon}^{2}}{n\_{v}n\_{w}/(3\pi^{2}{\varepsilon}^{-2}n\_{v}n\_{w}\log(1/\delta))+{\varepsilon}^{2}/2\log(1/\delta)}\right) |  |
|  |  |  |  |
| --- | --- | --- | --- |
|  |  | â‰¤expâ¡(âˆ’Îµ2Îµ2/2â€‹logâ¡(1/Î´)+Îµ2/2â€‹logâ¡(1/Î´))=Î´.absentsuperscriptğœ€2superscriptğœ€221ğ›¿superscriptğœ€221ğ›¿ğ›¿\displaystyle\leq\exp\left(-\frac{{\varepsilon}^{2}}{{\varepsilon}^{2}/2\log(1/\delta)+{\varepsilon}^{2}/2\log(1/\delta)}\right)=\delta. |  |

We also need ([36](#S7.E36 "In Proof. â€£ 7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) to bound

|  |  |  |
| --- | --- | --- |
|  | ğ”¼â€‹[x~âˆ§â‹…y~]â‰¤Ï€26â‹…k2â€‹nvâ€‹nwm=Ï€26â‹…k2â€‹nvâ€‹nw12â€‹Ï€2â€‹kâ€‹Îµâˆ’1â€‹nvâ€‹nw=kâ€‹Îµ/2.ğ”¼delimited-[]fragmentsfragmentsâ‹…~ğ‘¥~ğ‘¦â‹…superscriptğœ‹26superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘šâ‹…superscriptğœ‹26superscriptğ‘˜2subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤12superscriptğœ‹2ğ‘˜superscriptğœ€1subscriptğ‘›ğ‘£subscriptğ‘›ğ‘¤ğ‘˜ğœ€2{\mathbb{E}}[{\tilde{x}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}}]\leq\frac{\pi^{2}}{6}\cdot\frac{k^{2}n\_{v}n\_{w}}{m}=\frac{\pi^{2}}{6}\cdot\frac{k^{2}n\_{v}n\_{w}}{12\pi^{2}k{\varepsilon}^{-1}n\_{v}n\_{w}}=k{\varepsilon}/2. |  |

Putting these together,

|  |  |  |
| --- | --- | --- |
|  | Prâ¡[x~âˆ§â‹…y~â‰¥kâ€‹Îµ]â‰¤Î´,Prfragmentsfragmentsâ‹…~ğ‘¥~ğ‘¦ğ‘˜ğœ€ğ›¿\Pr[{\tilde{x}}\mathbin{\ooalign{\hfil$\wedge$\hfil\cr\hfil$\cdot$\hfil\crcr}}{\tilde{y}}\geq k{\varepsilon}]\leq\delta, |  |

which with ([35](#S7.E35 "In Proof. â€£ 7.2 Counting Bloom Filters â€£ 7 Sparse Binary Bundling and Bloom Filter Analysis via Concentration â€£ Capacity Analysis of Vector Symbolic Architectures")) implies the result.
âˆ

## References

* [1]

  D.Â Kleyko, E.Â Osipov, D.Â DeÂ Silva, U.Â Wiklund, V.Â Vyatkin, and D.Â Alahakoon,
  â€œDistributed representation of n-gram statistics for boosting
  self-organizing maps with hyperdimensional computing,â€ in Perspectives
  of System Informatics: 12th International Andrei P. Ershov Informatics
  Conference, PSI 2019, Novosibirsk, Russia, July 2â€“5, 2019, Revised Selected
  Papers 12, pp.Â 64â€“79, Springer, 2019.
* [2]

  P.Â Alonso, K.Â Shridhar, D.Â Kleyko, E.Â Osipov, and M.Â Liwicki, â€œHyperembed:
  Tradeoffs between resources and performance in nlp tasks with
  hyperdimensional computing enabled embedding of n-gram statistics,â€ in 2021 International Joint Conference on Neural Networks (IJCNN), pp.Â 1â€“9,
  IEEE, 2021.
* [3]

  D.Â Kleyko, E.Â Osipov, M.Â BjÃ¶rk, H.Â Toresson, and A.Â Ã–berg,
  â€œFly-the-bee: A game imitating concept learning in bees,â€ Procedia
  Computer Science, vol.Â 71, pp.Â 25â€“30, 2015.
* [4]

  D.Â Kleyko, E.Â Osipov, R.Â W. Gayler, A.Â I. Khan, and A.Â G. Dyer, â€œImitation of
  honey beesâ€™ concept learning processes using vector symbolic
  architectures,â€ Biologically Inspired Cognitive Architectures,
  vol.Â 14, pp.Â 57â€“72, 2015.
* [5]

  P.Â Kanerva, J.Â Kristoferson, and A.Â Holst, â€œRandom indexing of text samples
  for latent semantic analysis,â€ in Proceedings of the Annual Meeting of
  the Cognitive Science Society, vol.Â 22, 2000.
* [6]

  M.Â Sahlgren, â€œAn introduction to random indexing,â€ in Methods and
  applications of semantic indexing workshop at the 7th international
  conference on terminology and knowledge engineering, 2005.
* [7]

  M.Â N. Jones and D.Â J. Mewhort, â€œRepresenting word meaning and order
  information in a composite holographic lexicon.,â€ Psychological
  review, vol.Â 114, no.Â 1, p.Â 1, 2007.
* [8]

  D.Â Kleyko, E.Â Osipov, and U.Â Wiklund, â€œVector-based analysis of the similarity
  between breathing and heart rate during paced deep breathing,â€ in 2018
  Computing in Cardiology Conference (CinC), vol.Â 45, pp.Â 1â€“4, IEEE, 2018.
* [9]

  D.Â Kleyko, E.Â Osipov, and U.Â Wiklund, â€œA hyperdimensional computing framework
  for analysis of cardiorespiratory synchronization during paced deep
  breathing,â€ IEEE Access, vol.Â 7, pp.Â 34403â€“34415, 2019.
* [10]

  A.Â Burrello, K.Â Schindler, L.Â Benini, and A.Â Rahimi, â€œHyperdimensional
  computing with local binary patterns: One-shot learning of seizure onset and
  identification of ictogenic brain regions using short-time ieeg recordings,â€
  IEEE Transactions on Biomedical Engineering, vol.Â 67, no.Â 2,
  pp.Â 601â€“613, 2019.
* [11]

  J.Â I. Quiroz-Mercado, R.Â BarrÃ³n-FernÃ¡ndez, and M.Â A.
  RamÃ­rez-Salinas, â€œSemantic similarity estimation using vector symbolic
  architectures,â€ IEEE Access, vol.Â 8, pp.Â 109120â€“109132, 2020.
* [12]

  K.Â Schlegel, P.Â Neubert, and P.Â Protzel, â€œA comparison of vector symbolic
  architectures,â€ Artificial Intelligence Review, vol.Â 55, no.Â 6,
  pp.Â 4523â€“4555, 2022.
* [13]

  D.Â Kleyko, D.Â A. Rachkovskij, E.Â Osipov, and A.Â Rahimi, â€œA Survey on
  Hyperdimensional Computing aka Vector Symbolic Architectures,
  Part I: Models and Data Transformations,â€ Nov. 2021.
  arXiv:2111.06077 [cs].
* [14]

  A.Â Thomas, B.Â Khaleghi, G.Â K. Jha, S.Â Dasgupta, N.Â Himayat, R.Â Iyer, N.Â Jain,
  and T.Â Rosing, â€œStreaming Encoding Algorithms for Scalable
  Hyperdimensional Computing,â€ Sept. 2022.
  arXiv:2209.09868 [cs].
* [15]

  D.Â P. Woodruff, â€œComputational Advertising: Techniques for Targeting
  Relevant Ads,â€ Foundations and TrendsÂ® in Theoretical Computer
  Science, vol.Â 10, no.Â 1-2, pp.Â 1â€“157, 2014.
* [16]

  R.Â Oâ€™Donnell, Analysis of boolean functions.
  Cambridge University Press, 2014.
* [17]

  B.Â H. Bloom, â€œSpace/time trade-offs in hash coding with allowable errors,â€
  Communications of the ACM, vol.Â 13, no.Â 7, pp.Â 422â€“426, 1970.
  Publisher: ACM New York, NY, USA.
* [18]

  A.Â Thomas, S.Â Dasgupta, and T.Â Rosing, â€œA Theoretical Perspective on
  Hyperdimensional Computing,â€ Journal of Artificial Intelligence
  Research, vol.Â 72, pp.Â 215â€“249, Oct. 2021.
* [19]

  D.Â Kleyko, A.Â Rahimi, D.Â A. Rachkovskij, E.Â Osipov, and J.Â M. Rabaey,
  â€œClassification and Recall With Binary Hyperdimensional Computing:
  Tradeoffs in Choice of Density and Mapping Characteristics,â€ IEEE Transactions on Neural Networks and Learning Systems, vol.Â 29,
  pp.Â 5880â€“5898, Dec. 2018.
  Conference Name: IEEE Transactions on Neural Networks and Learning
  Systems.
* [20]

  W.Â B. Johnson, â€œExtensions of Lipschitz mappings into a Hilbert space,â€
  Contemp. Math., vol.Â 26, pp.Â 189â€“206, 1984.
* [21]

  D.Â Achlioptas, â€œDatabase-friendly random projections:
  Johnson-Lindenstrauss with binary coins,â€ Journal of computer and
  System Sciences, vol.Â 66, no.Â 4, pp.Â 671â€“687, 2003.
  Publisher: Elsevier.
* [22]

  R.Â W. Gayler, â€œMultiplicative binding, representation operators & analogy
  (workshop poster),â€ 1998.
* [23]

  K.Â Nakano, â€œAssociatron-A Model of Associative Memory,â€ IEEE
  Transactions on Systems, Man, and Cybernetics, vol.Â SMC-2, pp.Â 380â€“388,
  July 1972.
  Conference Name: IEEE Transactions on Systems, Man, and Cybernetics.
* [24]

  T.Â Kohonen, â€œCorrelation matrix memories,â€ IEEE transactions on
  computers, vol.Â 100, no.Â 4, pp.Â 353â€“359, 1972.
  Publisher: IEEE.
* [25]

  J.Â A. Anderson, â€œA simple neural network generating an interactive memory,â€
  Mathematical biosciences, vol.Â 14, no.Â 3-4, pp.Â 197â€“220, 1972.
  Publisher: Elsevier.
* [26]

  J.Â J. Hopfield, â€œNeural networks and physical systems with emergent collective
  computational abilities.,â€ Proceedings of the national academy of
  sciences, vol.Â 79, no.Â 8, pp.Â 2554â€“2558, 1982.
  Publisher: National Acad Sciences.
* [27]

  V.Â I. Gritsenko, D.Â A. Rachkovskij, A.Â A. Frolov, R.Â Gayler, D.Â Kleyko, and
  E.Â Osipov, â€œNeural Distributed Autoassociative Memories: A
  Survey,â€ Cybernetics and Computer Engineering, vol.Â 2017, pp.Â 5â€“35,
  June 2017.
  arXiv:1709.00848 [cs].
* [28]

  A.Â Broder and M.Â Mitzenmacher, â€œNetwork applications of bloom filters: A
  survey,â€ Internet mathematics, vol.Â 1, no.Â 4, pp.Â 485â€“509, 2004.
  Publisher: Taylor & Francis.
* [29]

  Y.Â Ying, â€œMcDiarmidâ€™s inequalities of Bernstein and Bennett forms,â€
  City University of Hong Kong, p.Â 318, 2004.
* [30]

  A.Â Thomas, S.Â Dasgupta, and T.Â Rosing, â€œTheoretical Foundations of
  Hyperdimensional Computing,â€ Journal of Artificial Intelligence
  Research, vol.Â 72, pp.Â 215â€“249, 2021.
* [31]

  S.Â Kent, Multiplicative coding and factorization in vector symbolic models
  of cognition.
  University of California, Berkeley, 2020.
* [32]

  D.Â M. Kane and J.Â Nelson, â€œSparser Johnson-Lindenstrauss transforms,â€
  Journal of the ACM (JACM), vol.Â 61, no.Â 1, pp.Â 1â€“23, 2014.
* [33]

  M.Â B. Cohen, T.Â Jayram, and J.Â Nelson, â€œSimple analyses of the sparse
  Johnson-Lindenstrauss transform,â€ in 1st Symposium on Simplicity in
  Algorithms (SOSA 2018), Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik,
  2018.
* [34]

  C.Â Boutsidis and A.Â Gittens, â€œImproved matrix algorithms via the subsampled
  randomized hadamard transform,â€ SIAM Journal on Matrix Analysis and
  Applications, vol.Â 34, no.Â 3, pp.Â 1301â€“1340, 2013.
* [35]

  F.Â Krahmer and R.Â Ward, â€œNew and improved Johnsonâ€“Lindenstrauss
  embeddings via the restricted isometry property,â€ SIAM Journal on
  Mathematical Analysis, vol.Â 43, no.Â 3, pp.Â 1269â€“1281, 2011.
* [36]

  R.Â Vershynin, High-dimensional probability: An introduction with
  applications in data science, vol.Â 47.
  Cambridge university press, 2018.
* [37]

  R.Â McEliece, E.Â Posner, E.Â Rodemich, and S.Â Venkatesh, â€œThe capacity of the
  Hopfield associative memory,â€ IEEE Transactions on Information
  Theory, vol.Â 33, pp.Â 461â€“482, July 1987.
  Conference Name: IEEE Transactions on Information Theory.
* [38]

  P.Â Smolensky, â€œTensor product variable binding and the representation of
  symbolic structures in connectionist systems,â€ Artificial
  Intelligence, vol.Â 46, pp.Â 159â€“216, Nov. 1990.
* [39]

  E.Â P. Frady, D.Â Kleyko, and F.Â T. Sommer, â€œVariable Binding for Sparse
  Distributed Representations: Theory and Applications,â€ IEEE
  Transactions on Neural Networks and Learning Systems, pp.Â 1â€“14, 2021.
  Conference Name: IEEE Transactions on Neural Networks and Learning
  Systems.
* [40]

  D.Â Krotov and J.Â J. Hopfield, â€œDense associative memory for pattern
  recognition,â€ Advances in neural information processing systems,
  vol.Â 29, 2016.
* [41]

  M.Â Demircigil, J.Â Heusel, M.Â LÃ¶we, S.Â Upgang, and F.Â Vermet, â€œOn a Model of
  Associative Memory with Huge Storage Capacity,â€ Journal of
  Statistical Physics, vol.Â 168, pp.Â 288â€“299, July 2017.
* [42]

  M.Â Rudelson and R.Â Vershynin, â€œHanson-wright inequality and sub-gaussian
  concentration,â€ Electronic Communications in Probability, vol.Â 18,
  pp.Â 1â€“9, 2013.
  Publisher: Institute of Mathematical Statistics and Bernoulli
  Society.
* [43]

  S.Â J. Swamidass and P.Â Baldi, â€œMathematical Correction for Fingerprint
  Similarity Measures to Improve Chemical Retrieval,â€ Journal
  of Chemical Information and Modeling, vol.Â 47, pp.Â 952â€“964, May 2007.
  Publisher: American Chemical Society.
* [44]

  O.Â Papapetrou, W.Â Siberski, and W.Â Nejdl, â€œCardinality estimation and dynamic
  length adaptation for bloom filters,â€ Distributed and Parallel
  Databases, vol.Â 28, no.Â 2, pp.Â 119â€“156, 2010.
  Publisher: Springer.
* [45]

  P.Â Bose, H.Â Guo, E.Â Kranakis, A.Â Maheshwari, P.Â Morin, J.Â Morrison, M.Â Smid,
  and Y.Â Tang, â€œOn the false-positive rate of Bloom filters,â€ Information Processing Letters, vol.Â 108, no.Â 4, pp.Â 210â€“213, 2008.
  Publisher: Elsevier.
* [46]

  A.Â Kamath, R.Â Motwani, K.Â Palem, and P.Â Spirakis, â€œTail bounds for occupancy
  and the satisfiability threshold conjecture,â€ Random Structures &
  Algorithms, vol.Â 7, no.Â 1, pp.Â 59â€“80, 1995.
  Publisher: Wiley Online Library.
* [47]

  G.Â Cormode and S.Â Muthukrishnan, â€œAn improved data stream summary: the
  count-min sketch and its applications,â€ Journal of Algorithms,
  vol.Â 55, pp.Â 58â€“75, Apr. 2005.
* [48]

  M.Â Laiho, J.Â H. Poikonen, P.Â Kanerva, and E.Â Lehtonen, â€œHigh-dimensional
  computing with sparse vectors,â€ in 2015 IEEE Biomedical Circuits
  and Systems Conference (BioCAS), pp.Â 1â€“4, IEEE, 2015.
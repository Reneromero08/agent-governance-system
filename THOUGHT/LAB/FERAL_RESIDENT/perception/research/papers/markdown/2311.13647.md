maketitle thanks aketitle

# Introduction

Language models are autoregressive, outputting the probability of each next token in a sequence conditioned on the preceeding text. This distribution is used to generate future tokens in the sequence. Can this distribution also be used to reconstruct the prompt?

In most contexts, this question is pointless, since we have already conditioned on this information. However, increasingly language models are being offered "as a service" where the user may have access to the outputs, but not all of the true prompt. In this context, it may be of interest to users to know the prompt and, perhaps, for the service provider to protect it. This goal has been the focus of "jailbreaking" approaches that attempt to use the forward text generation of the model to reveal the prompt.

We formalize this problem of prompt reconstruction as *language model inversion*, recovering the input prompt conditioned on the language model's next-token probabilities. Interestingly, work in computer vision has shown that probability predictions of image classifiers retain a surprising amount of detail [@dosovitskiy2016inverting], so it is plausible that this also holds for language models. We propose an architecture that predicts prompts by"unrolling" the distribution vector into a sequence that can be processed effectively by a pretrained encoder-decoder language model. This method shows for the first time that language model predictions are mostly invertible: in many cases, we are able to recover very similar inputs to the original, sometimes getting the input text back exactly.

We additionally explore the feasibility of prompt recovery across a spectrum of real-world access patterns: full next-token probability outputs, top-K probabilities, probabilities per token upon request, and discrete sampling. We find that even in the case where we are only able to observe text output from the model (no probabilities), we can recover enough of the probability distribution to reconstruct the prompt.

Our results show that systems that offer text-only access to a language model reveal information about their prompts. With enough queries, we can extract next-token probabilities at a given position, which can be used to reconstruct the input. Unlike text-based jailbreaks, our dense distribution inversion is less inhibited by post-pretraining reinforcement learning techniques such as RLHF to align the model. We also show that our inversion techniques transfer between models of the same family, and are not affected by language model scaling.

<figure id="fig:overview" data-latex-placement="h">
<embed src="figs/00_overview.pdf" />
<figcaption>Under the assumption that a language model is offered as a service with a hidden prefix prompt that produces next-word probabilities, the system is trained from samples to invert the language model, i.e. to recover the prompt given language model probabilities for the next token. </figcaption>
</figure>

# Related work

**Inverting deep embeddings.** Several lines of work in computer vision have shown that inputs can be approximately reconstructed from the logits of an image classifier [@mahendran2014UnderstandingDI; @dosovitskiy2016inverting; @teterwak2021understanding] or from a self-supervised representation vector [@bordes2021highfissl]. Some recent work [@takahashi2023breaching] has shown that outputs of computer vision models may reveal private information when shared in a federated learning setup. There is also work on inverting representations in NLP: @song2020informationfromembeddings [@li2023sentence; @morris2023vec2text] investigate the privacy leakage of text embeddings from encoder models. @morris2023vec2text succeeds in recovering full text sequences from their embeddings by conditioning the encoder of an encoder-decoder Transformer for inversion. Ours is the first work to inversion directly from the probability outputs of language models.

**Model inversion and membership inference.** Given an output of a model, *model inversion* aims to construct an input that produces that output. This problem was investigated for simple regression classifiers in [@fredrikson2014privacy; @frederikson2015modelinversion] and extended to neural face-recognition classifiers in [@zhang2020secret]. In some cases, model inversion can help recover training data. For example, in face-recognition classifiers each class corresponds to a single person, thus any image recovered by model inversion is visually similar to the training images for the same class label. [@zhang2022textrevealer] used model inversion techniques to recover memorized training data from pretrained language models. A related problem is *membership inference*: given a data point, determine whether it was part of the model's training data or not [@shokri2017membership]. @duan2023privacy demonstrated membership inference for in-context learning.

Prompt inversion is a form of model inversion, but we work with significantly more complex language models, where dimensionality of inputs is much higher than in the classifiers studied in prior model-inversion work. Instead of recovering information about the training data, we aim to recover the specific prompt given to the model and filter out information related to the training data.

**Model stealing.** As language models become more and more valuable, they are hidden behind increasingly stringent safeguards. Research into 'model stealing' aims to explore how models themselves can be replicated via API queries [@tramèr2016stealing]. Stealing NLP models has been demonstrated in many domains: linear text-based classification [@lowd2005spam], language classification [@pal2019aff; @krishna2020thieves], machine translation @wallace2021imitation, and even text retreival [@dziedzic2023sentence]. Recent work @gudibande2023false suggests that this form of imitation may create models that replicate surface-level syntax but do not learn more complex attributes like knowledge or factuality. Different than these works, we do not focus on reconstructing model weights from third-party model outputs, but finding a hidden prompt from outputs of a third-party model.

# Prompt Reconstruction

Language models give the probability of the next token conditioned on the tokens that came before it, i.e. $\mathbf{v} = p(x_{T+1} \mid x_{1}, ..., x_{T}; \theta)$, where $\mathbf{v} \in \Delta^{|\mathcal{V}|-1}$ gives the probability of each of $|\mathcal{V}|$ possible next tokens. Generally these models have relatively large vocabulary sizes; the vocabulary $\mathcal{V}$ may contain tens or hundreds of thousands of elements.

## Logits contain residual information {#subsec:logits-residual-info}

We construct a simple experiment to demonstrate the amount of information LM logits may convey about the input. Given 100 text inputs from Wikipedia, we substitute a single word in the first sentence with a synonym[^2]. Let $\hat{x}_{s}$ be the synonym of word $x_{s}$. To measure the change in language model output between the original sequence (containing $x_s$) and the new sequence (containing $\hat{x_{s}}$), we compute two quantities: the KL divergence between the probability output of $p$ for the original and synonym-swapped sequences, and the bit-level Hamming Distance between the two distributions when represented at 16-bit precision.

::: wrapfigure
r0.5 ![image](figs/01_kl_bits.pdf){width="\\linewidth"}
:::

We plot KL and bitwise Hamming Distance relative to the position of the synonym swap in [\[fig:kl_bits\]](#fig:kl_bits){reference-type="ref+Label" reference="fig:kl_bits"}. If LMs did not contain residual information about previous words, we would expect bitwise distance to decay to zero as we move away from the position of the swap. However, we observe that bits remain: although the vector $\textbf{v}$ is only used to predict the next token, it clearly contains residual information about the prompt tokens $x_{1},..., x_{T}$. Since KL puts most of its weight on the highest-likelihood tokens, it can decay to zero, while much of the information remains in the low-probability tokens.

## Prompt Reconstruction

We now consider the problem of inverting the process: given the probability vector, we attempt to produce the prompt that led to these next-token probabilities. Given some unseen model $f : \mathcal{V}^{T} \rightarrow \Delta^{|\mathcal{V}|-1}$ which gives next-token probabilities, we would like to learn to invert this function from samples: pairs of text prefixes and their associated next-token probability vectors $(x_{1:T}^1, \mathbf{v}^1) \ldots (x_{1:T}^J, \mathbf{v}^J)$.

#### Inverting from outputs?

Besides inverting from the probability vector, natural procedure to consider is predicting the prompt directly from the output of the language model. For example, given the model output "Bogota", we may predict the input "What is the capital of Columbia?". We hypothesize that a single logit vector contains much more detailed information about the prompt then a single sequence sampled from the argmax of these vectors. However, we consider this scenario in our *Sample inverter* baseline described in [6](#sec:experimental_design){reference-type="ref+Label" reference="sec:experimental_design"}.

#### Prompt datasets.

We construct Instructions-2M, a meta-dataset consisting of 2.33M instructions including user and system prompts for a wide variety of different problems. This includes prompts from Supernatural Instructions [@wang-etal-2022-super], Self Instruct [@wang-etal-2023-self-instruct], Alpaca [@alpaca], Dolly[^3], ShareGPT[^4], Unnatural Instructions [@honovich-etal-2023-unnatural], ChatBot Arena [^5], Stable Diffusion Dataset[^6], WizardLM instructions [@xu2023wizardlm; @luo2023wizardcoder], GPTeacher[^7], T0 [@chung2022scaling], and LaMini instruction [@lamini-lm]. In addition we collect out-of-domain prompts to test the ability of the model to generalize in topical area.

#### Assumptions of our threat model.

We motivate this problem by the prevalence of language models as a service. In these use cases we assume that an unknown prefix sequence, known as the *prompt*, is prepended to the user input. We consider varying levels of model access: full distributional access, partial distributional access (top-K or by request), text output with user-defined logit bias, and text output access only. We assume no access to the model weights or activations.

# Method: Learning to Invert Probabilities {#sec:method}

Our proposed approach is to learn a conditional language model that maps from next-token probabilities back to tokens: $p(x_{1:T} \mid  \mathbf{v})$. We parameterize this distribution using a pretrained Transformer language model and train on samples from the unconditional model. Following work from @dumoulin2018feature-wise on feature-level conditioning, we use the cross-attention in an encoder-decoder Transformer to condition on the next-token vector.

Since our encoder model is pretrained on text (we utilize T5), we must reformat $\mathbf{v}$ to be fed to a language encoder. The simplest method is to project $\mathbf{v}$ to $\mathbb{R}^{d}$ and feed it as an input hidden vector. However, given the large size of the vocabulary $|\mathcal{V}|$ and the fact that it has been passed through a softmax, this would cause a large reduction in rank and a loss of information[^8]. We instead 'unroll' the vector into a sequence of pseudo-embeddings $\mathbf{c}_i \in \mathbb{R}^{d}$, so that we can condition transformer outputs on the full probability vector $\mathbf{v}$, $$\begin{eqnarray*}
\mathbf{c}_{i} &=& \text{MLP}_i(\log ( \mathbf{v}_{d (i-1): d i} )) \ \ \forall \  i \in \{ 1 \ldots  \lceil |\mathcal{V}| / d\rceil \}\\
x^*& = & \arg\max_{x} \text{Dec}(x, {\text{Enc}(\mathbf{c})})
\end{eqnarray*}$$ Where $x^*$ is the predicted inversion, $d$ is the embedding dimension, and $\mathbf{v}$ is padded with zeros at the final position. In practice we use $|\mathcal{V}|=32000$ and $d=768$ for all experiments which leads to a fixed-length input sequence of $42$ words.

# Extracting Logits via API

The previous sections assume we have access to the full language model output probability vector. However, many language model platforms limit the information returned from API calls. For example, a well-known service's API only exposes either samples or the top-5 log probabilities, but does not expose all output probabilities for a given input.

We therefore propose a method for extracting next-token probabilities from APIs where the full probability distribution is not immediately available. We take advantage of the fact that even when API services do not return the full probabilities, they typically allow users to add a *logit bias* to adjust the distribution. In addition to providing a logit bias per API call, they typically allow setting the temperature parameter to zero to provide argmax of the distribution.

:::: algorithm
::: algorithmic
:::
::::

The probability of each token can therefore be recovered by finding its difference with the most likely word. We compute this difference by finding the smallest logit bias to make that word most likely. Algorithm [\[alg:dista\]](#alg:dista){reference-type="ref" reference="alg:dista"} shows the approach, which relies on binary search to find the logit bias for each word.

Note that binary search can be conducted independently for each word, enabling full parallelization and requiring only a single logit bias at a time. By running this procedure for each word in the vocabulary, we can then reconstruct the full distribution $\mathbf{v} = \text{softmax}(\text{logits})$. The necessary number of queries to determine the distribution is $|\mathcal{V}|$ times the number of bits required to represent the desired precision.[^9]

# Experimental setup {#sec:experimental_design}

#### Models.

We train models to invert the distribution of Llama-2 (7B) and Llama-2 Chat (7B) [@touvron2023Llama]. We choose this model because, as of the time of publication, it is the best-performing open-source LLM at the 7B parameter scale. We assume full access to the model output probabilities except for during the distribution extraction experiments in [7](#sec:results){reference-type="ref+Label" reference="sec:results"}, in which we set temperature to $0$ and provide a single logit bias argument.

We parameterize the inversion model using the method described in [4](#sec:method){reference-type="ref+Label" reference="sec:method"} and select T5-base [@raffel2020exploring] as our encoder-decoder backbone, which has $222M$ parameters. We set the maximum sequence length to $64$ for all experiments. We train models for $100$ epochs with Adam optimizer with a learning rate of $2e-4$. We use a constant learning rate with linear warmup over the first $25,000$ training steps. We train in bfloat16 precision.

#### Metrics.

We consider several metrics for prompt reconstruction: F1 score at the token level, BLEU score [@papineni2002bleu] as a measure of string overlap, and exact match. We also consider the cosine similarity between the text embeddings of the original and recovered text as a measure of semantic relatedness. For cosine similarity, we use embeddings from the model `text-embeddings-ada-002` available through the OpenAI API [@neelakantan2022text]. For each metric, we report error bounds as standard error of the mean (SEM).

We randomly hold out $1\%$ of the training data for testing. We additionally evaluate on two datasets of human-written prompts: code prompts from Alpaca [@alpaca], and prompts extracted from the helpfulness and harmlessness data collected in @anthropic2022rlhf. Both datasets are drawn from different, more narrow distributions than our all-encompassing training dataset.

#### Baselines.

As we are the first work to consider inverting text directly from language model probabilities, there are no prior baselines to compare to. We therefore develop several baselines:

- *Jailbreak strings.* Human-written sequences that attempt to persuade the language model to divulge information from earlier in the sequence. We aggregate jailbreak strings from a variety of sources, including writing some manually. We only show the top jailbreak string in the tables, and include more results in the appendix. We source $20$ jailbreak strings and test them on all models. For pre-trained Llama models, jailbreak strings are simply appended to the prompt. For chat models, we input the hidden prompt as a system instruction, along with a basic system instruction that instructs the model not to divulge its hidden prompt. We then input the jailbreak string as a user prompt. When reporting results, we report the mean performance of all prompts as well as an oracle figure indicating the best-performing jailbreak string on the test dataset selected after evaluation.

- *GPT-4 Few-shot.* We prompt GPT-4 with examples of the top-K tokens by probability from Llama-2 input predictions. These example input-output pairs are prepended to the top probabilities for the hidden input.

- *Sample inverter.* Instead of inverting from next-token probability, we consider whether we might predict prompts from samples of the text outputs from the LM. To train this model, we sample outputs from Llama-2 7b chat and train a T5-base encoder-decoder to predict the input prompt from a given language model output.

# Results {#sec:results}

::: table*
+:--+:-------------------+:--------------------------+:------------------------+:------------------------+:------------------------+
|   |                    | Instructions-2M                                                                                         |
+---+--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   |                    | BLEU                      | CS                      | Exact                   | Token F1                |
+---+--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Sample inverter    | $25.55_{\pm{0.89}}$       | $90.2_{\pm{0.4}}$       | $0.0_{\pm{0.0}}$        | $65.1_{\pm{1.5}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Few-shot (GPT-3.5) | $4.00_{\pm{0.43}}$        | $77.9_{\pm{0.4}}$       | $0.0_{\pm{0.0}}$        | $19.4_{\pm{0.9}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Few-shot (GPT-4)   | $6.07_{\pm{0.59}}$        | $79.3_{\pm{0.4}}$       | $0.0_{\pm{0.0}}$        | $25.4_{\pm{1.1}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Jailbreak (mean)   | $10.23_{\pm{1.22}}$       | $80.1_{\pm{0.4}}$       | $0.0_{\pm{0.0}}$        | $25.0_{\pm{1.5}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Jailbreak (oracle) | $14.88_{\pm{1.42}}$       | $82.0_{\pm{0.4}}$       | $0.0_{\pm{0.0}}$        | $32.9_{\pm{1.7}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Ours               | $\pmb{58.26_{\pm{1.76}}}$ | $\pmb{93.6_{\pm{0.4}}}$ | $\pmb{23.4_{\pm{2.7}}}$ | $\pmb{75.8_{\pm{1.3}}}$ |
+---+--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Few-shot (GPT-3.5) | $2.73_{\pm{0.29}}$        | $75.3_{\pm{0.3}}$       | $0.0_{\pm{0.0}}$        | $18.6_{\pm{0.9}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Few-shot (GPT-4)   | $3.01_{\pm{0.39}}$        | $74.9_{\pm{0.3}}$       | $0.0_{\pm{0.0}}$        | $18.5_{\pm{1.1}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Jailbreak (mean)   | $13.97_{\pm{1.69}}$       | $83.5_{\pm{0.4}}$       | $5.4_{\pm{1.0}}$        | $21.3_{\pm{2.0}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Jailbreak (oracle) | $54.37_{\pm{2.96}}$       | $88.8_{\pm{0.3}}$       | $\pmb{36.5_{\pm{3.4}}}$ | $68.4_{\pm{2.5}}$       |
|   +--------------------+---------------------------+-------------------------+-------------------------+-------------------------+
|   | Ours               | $\pmb{59.21_{\pm{2.11}}}$ | $\pmb{94.6_{\pm{0.4}}}$ | $26.6_{\pm{2.8}}$       | $\pmb{77.8_{\pm{1.3}}}$ |
+---+--------------------+---------------------------+-------------------------+-------------------------+-------------------------+

[]{#tab:results_main label="tab:results_main"}
:::

::: table*
+:--+:--------------+:--------------------+:------------------+:------------------+:------------------+:--------------------+:------------------+:------------------+:------------------+
|                   | Alpaca Code Generation                                                          | Anthropic HH                                                                    |
+---+---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   |               | BLEU                | CS                | Exact             | Tok F1            | BLEU                | CS                | Exact             | Tok F1            |
+---+---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Few (3.5)     | $6.57_{\pm{0.52}}$  | $79.7_{\pm{0.4}}$ | $0.0_{\pm{0.0}}$  | $28.7_{\pm{1.0}}$ | $2.70_{\pm{0.23}}$  | $75.1_{\pm{0.3}}$ | $0.0_{\pm{0.0}}$  | $14.7_{\pm{0.8}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Few (4)       | $6.83_{\pm{0.44}}$  | $80.3_{\pm{0.4}}$ | $0.0_{\pm{0.0}}$  | $29.8_{\pm{0.9}}$ | $3.36_{\pm{0.29}}$  | $77.3_{\pm{0.4}}$ | $0.0_{\pm{0.0}}$  | $17.5_{\pm{0.9}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Jail (avg)    | $6.07_{\pm{0.48}}$  | $74.7_{\pm{0.5}}$ | $0.0_{\pm{0.0}}$  | $23.8_{\pm{0.8}}$ | $2.43_{\pm{0.23}}$  | $81.1_{\pm{0.4}}$ | $0.0_{\pm{0.0}}$  | $16.4_{\pm{0.6}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Jail (oracle) | $14.19_{\pm{0.85}}$ | $83.5_{\pm{0.4}}$ | $0.0_{\pm{0.0}}$  | $36.8_{\pm{0.9}}$ | $3.01_{\pm{0.27}}$  | $82.3_{\pm{0.4}}$ | $0.0_{\pm{0.0}}$  | $17.7_{\pm{0.7}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Ours          | $44.41_{\pm{1.76}}$ | $93.0_{\pm{0.3}}$ | $8.2_{\pm{1.7}}$  | $73.9_{\pm{1.1}}$ | $25.56_{\pm{1.65}}$ | $90.2_{\pm{0.3}}$ | $6.6_{\pm{160}}$  | $54.2_{\pm{1.5}}$ |
+---+---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Few (3.5)     | $3.53_{\pm{0.32}}$  | $72.1_{\pm{0.5}}$ | $0.0_{\pm{0.0}}$  | $18.6_{\pm{0.9}}$ | $4.39_{\pm{0.39}}$  | $74.3_{\pm{0.3}}$ | $0.0_{\pm{0.0}}$  | $20.0_{\pm{1.1}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Few (4)       | $6.35_{\pm{0.56}}$  | $77.0_{\pm{0.5}}$ | $0.0_{\pm{0.0}}$  | $28.7_{\pm{1.3}}$ | $4.51_{\pm{0.46}}$  | $74.7_{\pm{0.2}}$ | $0.0_{\pm{0.0}}$  | $18.8_{\pm{1.0}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Jail (avg)    | $29.32_{\pm{1.94}}$ | $55.7_{\pm{0.5}}$ | $12.7_{\pm{1.6}}$ | $45.9_{\pm{2.0}}$ | $25.71_{\pm{2.15}}$ | $52.1_{\pm{0.4}}$ | $14.2_{\pm{1.8}}$ | $40.8_{\pm{2.4}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Jail (oracle) | $72.98_{\pm{2.83}}$ | $89.7_{\pm{0.7}}$ | $61.5_{\pm{3.4}}$ | $80.2_{\pm{2.3}}$ | $77.70_{\pm{2.63}}$ | $92.2_{\pm{0.6}}$ | $64.5_{\pm{3.4}}$ | $83.0_{\pm{2.2}}$ |
|   +---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+
|   | Ours          | $46.22{\pm{1.81}}$  | $93.3_{\pm{0.4}}$ | $10.5_{\pm{1.9}}$ | $74.9_{\pm{1.1}}$ | $25.06_{\pm{1.57}}$ | $90.1_{\pm{0.4}}$ | $6.3_{\pm{1.6}}$  | $55.8_{\pm{1.4}}$ |
+---+---------------+---------------------+-------------------+-------------------+-------------------+---------------------+-------------------+-------------------+-------------------+

[]{#tab:results_ood label="tab:results_ood"}
:::

Table [\[tab:results_main\]](#tab:results_main){reference-type="ref" reference="tab:results_main"} shows the main results of the experiments on reversing prompts from the Instructions-2M test set on both a raw LLM and RLHF Chat variant. We find that our method is able to achieve high BLEU score with the true prompts and achieve reasonable high-exact match reproduction. This approach is significantly better than few-shot prompting approaches, even when using GPT-4. The other trained approach (Sample Inverter) has a reasonable BLEU but $0$ exact recoveries. The failure of sample inversion indicates that we are able to extract more usable information about the prompt from the logit vector than from the argmax outputs alone.

Compared to manually written jailbreak strings, our approach is significantly better than the average value, comparable with the oracle jailbreak method. Notably, while the best jailbreak method works well on the raw LM, none of the jailbreak approaches work on the RLHF chat version. We do observe that our method works slightly better on the non-chat model ($59$ vs. $52$ mean BLEU), indicating that the RLHF procedure used to train the chat model may reduce the amount of information from what was initially available in the next-token probabilities.

**Out-of-domain.** Table [\[tab:results_ood\]](#tab:results_ood){reference-type="ref" reference="tab:results_ood"} shows the results when using prompts that are significantly different than the training distribution both in length and in content. For these domains, the model is significantly better than few-shot and jailbreaking on the RLHF model. With the chat model, we also observe that the jailbreak strings are especially ineffective on the Anthropic HH dataset, which contains a large amount of toxic content; this indicates that the chat model is less likely to obey the user's request when toxic content is present in the prompt. For the raw model, the inversion approach is a bit worse than jailbreaking on BLEU.

::: table*
+---------+----------+------------------------+-------------------+-------------------+
| Train   | Test     | Alpaca Code Generation | Anthropic HH      | Instructions-2M   |
+:========+:=========+:======================:+:=================:+:=================:+
| 7b      | 7b       | $76.3_{\pm{1.9}}$      | $56.2_{\pm{2.3}}$ | $77.7_{\pm{2.3}}$ |
|         +----------+------------------------+-------------------+-------------------+
|         | 13b      | $48.4_{\pm{1.4}}$      | $44.3_{\pm{2.2}}$ | $54.9_{\pm{1.9}}$ |
|         +----------+------------------------+-------------------+-------------------+
|         | 70b      | $52.1_{\pm{1.5}}$      | $44.8_{\pm{2.2}}$ | $53.0_{\pm{2.0}}$ |
+---------+----------+------------------------+-------------------+-------------------+
| 7b-chat | 7b-chat  | $76.6_{\pm{1.9}}$      | $55.6_{\pm{2.3}}$ | $75.8_{\pm{2.1}}$ |
|         +----------+------------------------+-------------------+-------------------+
|         | 13b-chat | $37.3_{\pm{1.4}}$      | $32.5_{\pm{2.0}}$ | $43.6_{\pm{1.7}}$ |
|         +----------+------------------------+-------------------+-------------------+
|         | 70b-chat | $36.5_{\pm{1.2}}$      | $32.2_{\pm{1.7}}$ | $43.1_{\pm{1.8}}$ |
+---------+----------+------------------------+-------------------+-------------------+

[]{#tab:transfer label="tab:transfer"}
:::

**API-Based Logits Extraction.** Here we examine our ability to recover the next-token probability distribution. We simulate an API with a 'logit bias' argument and argmax outputs using a local LLAMA-2 model. We visualize results of our technique (blue) vs. a naive Monte Carlo sample baseline (red) in [3](#fig:redaction_by_k){reference-type="ref+Label" reference="fig:redaction_by_k"} (left). Our deterministic algorithm extracts useful logits in fewer queries than the Monte Carlo baseline. This result follows our hypothesis ([3.1](#subsec:logits-residual-info){reference-type="ref+Label" reference="subsec:logits-residual-info"}) that useful information is contained in the probabilities of very unlikely words, which almost never occur during random sampling.

**Transferability.** We next investigate whether inversions transfer to models of different size by evaluating our inversion models trained on the 7B version of Llama-2 on the 13B version and 70B version. Results are shown in [\[tab:transfer\]](#tab:transfer){reference-type="ref+Label" reference="tab:transfer"}. We observe that inversions transfer reasonably well, performing best on code generation, and significantly better between non-RLHF'd models than between the chat models. We speculate that models may need to be further fine-tuned to adapt to different models.

**Inversion and Language Model Scale.** To understand how dependent inversion results are to language model size, we consider inverting different sizes of GPT-2  [@radford2019gpt2] and show results in [\[tab:model_ablations\]](#tab:model_ablations){reference-type="ref+Label" reference="tab:model_ablations"} (Left). Interestingly, the reconstructions perform very similarly (within 1 point of BLEU score) regardless of the size of the language model inverted. The fact that output probabilities contain similar amounts of information even after going through vastly different amounts of processing (dependent on the varying model size) differ from the findings of @dosovitskiy2016inverting who note that more layers of computation make inversion more difficult in CNNs.

## Defending against prompt inversion

Language model providers may be interested in defending prompts from inversion. One simple defense is to add noise to the language model output distribution; instead of providing a deterministic (argmax) output, from which an attacker could trivially reconstruct the output probabilities, language model providers, could instead *sample* from the output distribution.

We consider three different LM sampling mechanisms as defenses against prompt inversion: adjusting the softmax temperature during sampling, adjusting the top-p parameter of nucleus sampling [@holtzman2020curious], and adjusting the total number of tokens considered (top-K). We sample from Llama-2 7b (non-chat) and feed probabilities into our inverter model according to the desired strategy. Results are visualized in [2](#fig:defense){reference-type="ref+Label" reference="fig:defense"}.

In each case, we observe a trade-off between language model fidelity and inversion performance. Interestingly, inversion performs best at temperature value $\tau=1$, and suffers when temperature decreases, as the LM distribution anneals to argmax, as well as when temperature increases, as the distribution collapses to uniform. For both top-p and top-k we note that the model requires almost all of the distribution to perform well, indicating that there is significant information in the tails.

<figure id="fig:defense" data-latex-placement="t">
<img src="figs/05_defense.png" />
<figcaption>Language model providers may sample differently in an effort to protect prompts from inversion. We explore inversion performance under various sampling strategies employed as defenses against inversion attacks: annealing temperature, setting top-K value, and nucleus (top-p) sampling. We consider applying temperature to the softmax both in log space (orange) and probability space (blue).</figcaption>
</figure>

## Analysis

::: table*
  **Original**                                                                                                                                                                 **Reconstruction**
  ------------------------------------------------------------------------------------------------------------------------------------------------------------ --------------- -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  What is the Charles 'Chick' Evans Memorial Scholarship?                                                                                                       $\Rightarrow$  What is the Charles [****]{style="color: maroon"} Scholarship [****]{style="color: maroon"}?
  Is the following sentence grammatically correct? They was playing soccer in the park. OPTIONS: - unacceptable - acceptable                                    $\Rightarrow$  Is the following sentence grammatically correct? They was playing soccer in the park. OPTIONS: - unacceptable - acceptable
  What are the benefits of practicing mindfulness meditation?                                                                                                   $\Rightarrow$  What are the benefits of practicing mindfulness meditation?
  Come up with an essay on the importance of emotions in decision-making. No input                                                                              $\Rightarrow$  [****]{style="color: maroon"} essay [****]{style="color: maroon"} the importance of [****]{style="color: maroon"}. No input
  What are the rules of a sit-and-go poker tournament?                                                                                                          $\Rightarrow$  What are the rules of a [****]{style="color: maroon"} poker tournament?
  What impact do workplace policies have on reducing unconscious bias, and how can they be improved?                                                            $\Rightarrow$  What [****]{style="color: maroon"} impact [****]{style="color: maroon"} on workplace policies [****]{style="color: maroon"}, and how can they be [****]{style="color: maroon"}?
  Given that John Steinbeck's "Of Mice and Men\" was published in 1937, can it be concluded that Steinbeck won the Nobel Prize in Literature that same year?    $\Rightarrow$  Given that [****]{style="color: maroon"} "[****]{style="color: maroon"}\" was [****]{style="color: maroon"} [****]{style="color: maroon"} and published in [****]{style="color: maroon"}, can it be concluded that it won the [****]{style="color: maroon"} in [****]{style="color: maroon"}?

[]{#tab:qualitative_examples label="tab:qualitative_examples"}
:::

**Qualitative examples.** We showcase some randomly-selected qualitative examples from Instructions-2M in [\[tab:qualitative_examples\]](#tab:qualitative_examples){reference-type="ref+Label" reference="tab:qualitative_examples"}. Our inverted prompts are generally on topic and syntactically similar to the originals. Two prompts are perfectly reconstructed. We notice that proper nouns seem difficult; in one example, our model correctly recovers the structure of a question, but mixes up Steinbeck's *Of Mice and Men* with Salinger's *The Catcher in the Rye*[^10]. (One might assume that this information is represented in the probability distribution, but interestingly the raw probabilities do not favor either title.) In all examples, the system correctly identifies whether or not the prompt ends in punctuation.

**Which components of the distribution does the inverter need?** To investigate whether our model focuses most on the largest components of its input, we iteratively remove (set to the mean) $k$ components from the probability vector in both ascending and descending order. We also consider removing all but a random subset of $k$ components from the input. [3](#fig:redaction_by_k){reference-type="ref+Label" reference="fig:redaction_by_k"} highlights the difference in reconstruction performance across levels of component removal. It appears that the model focuses more on the more likely words. In particular, the smallest $k$ probabilities are only slightly more useful than a random $k$. Reconstruction is poor in general until almost the entire distribution is re-included.

<figure id="fig:redaction_by_k" data-latex-placement="t">
<p><img src="figs/04_sampling.png" style="width:45.0%" alt="image" /><img src="figs/02_topk_redaction.png" style="width:45.0%" alt="image" /></p>
<figcaption>(Left) Model performance under our API-based logit recovery technique vs the Monte Carlo baseline. The dotted blue line is given by reconstructing the prompt from the true probability vector. (Right) Model performance across levels of probability vector redaction. We test eliminating all except the top-K probabilities, all except the bottom-K, and all except random K, while varying K from 1 to 32,000 (full input dimensionality).</figcaption>
</figure>

# Conclusion & Future Work

We define the problem of inversion from language model outputs and analyze inversion approaches from an attack and defense perspective. We show that this attack vector can be used to elicit hidden prompts from LM systems, even when we do not have direct access to model output distributions.

*What are the limits of inversion?* Our experiments show that much information about the input can be recovered from language model probabilities, but do not estimate the upper bound. The scaling analysis in [18.1](#sec:ablations){reference-type="ref+Label" reference="sec:ablations"} implies that larger backbone models recover more information, but we do not run any experiments with backbone models larger than hundred-million parameter scale.

*How can we keep our prompts safe?* Our experiments show that when sampling is enabled, we can reconstruct model probability distributions given enough queries to the model. The only foolproof way to protect prompts while providing users access to generate text from a language model is to disable top-logits access (output only text) and set temperature to 0.

*Smarter parameterizations for inversion.* Future work might consider exploiting the fact that inputting a single suffix into a LM outputs multiple next-token predictions, one at each position, not just at the end. Additional research may find that utilizing a parameterization that integrates token embeddings with probability values, so that the inversion model 'knows' which value corresponds which word, could be useful.

# Ethics

Our research on the inversion of language models underscores the ethical implications surrounding the deployment of such models as services, particularly when providers maintain prompts that are valuable or contain personal information. Users of language models may be affected as they rely on these services for various purposes, including content generation and information retrieval. Prompt secrecy can compromise users' trust in the systems they interact with, raising concerns about the transparency and integrity of the services themselves.

Lack of access to the underlying prompts hinders efforts to scrutinize, evaluate, and regulate language models effectively, thereby impeding advancements in the responsible and ethical development of AI technologies. Our research advances the field towards wider access to prompts while highlighting important privacy concerns for language-models-as-a-service providers.

# Reproducibility

Code for reproducing all experiments is available at [anonymous.4open.science/status/language-model-inversion](https://anonymous.4open.science/status/language-model-inversion). Our dataset of prompts will be provided upon paper publication. All experiments are fully reproducible and documented in the Github repository, including all model-training, logit sampling, and evaluation.

# Acknowledgements

JXM is supported by a NSF GRFP. JC is supported by NSF 2242302. AMR is supported by NSF 2242302, NSF CAREER 2037519, IARPA HIATUS, and a Sloan Fellowship. Thanks to the Allen Institute for AI for providing the compute required to train the LLAMA inversion models.

# Baseline: Jailbreak prompts

Jailbreak prompts were manually written by a panel of NLP experts. Prompts were tested with and without newlines prepended and with and without taking the first line of output. [\[tab:all_prompts\]](#tab:all_prompts){reference-type="ref+Label" reference="tab:all_prompts"} contains a list of all jailbreak prompts tested in order of descending effectiveness. A plot of performance by model and dataset is available in [4](#fig:app_prompts_perf){reference-type="ref+Label" reference="fig:app_prompts_perf"}.

<figure id="fig:app_prompts_perf" data-latex-placement="t">
<img src="figs/app_01_prompts_stripplot.png" style="width:50.0%" />
<figcaption>Performance of jailbreak prompts by dataset.</figcaption>
</figure>

::: table*
[]{#tab:all_prompts label="tab:all_prompts"}
:::

::: table*
[]{#tab:all_prompts_2 label="tab:all_prompts_2"}
:::

# Baseline: Few-shot

[\[tab:fewshot_prompt\]](#tab:fewshot_prompt){reference-type="ref+Label" reference="tab:fewshot_prompt"} shows a sample prompt for few-shot prompting an LLM to do inversion from LM probabilities. We choose a few-shot strategy. To format the input for an LLM, we take the top-100 predicted probabilities and subtract unigram probabilities to remove most common words. We show this input to the model along with a sample output. Because this takes many tokens, we only show a total of 3 examples per prompt before providing the log-probabilities for the true sample.

::: table*
+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Prompt | Given the top-K predicted tokens and log-probabilities from a language model, please predict what the input was. Please follow the examples and don't output anything except the predicted input.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Top tokens: { Leon: 11.2398 Da: 9.6961 da: 8.9290 Leo: 8.6994 Leonard: 8.1272 Nob: 7.8001 Was: 7.3815 Vincent: 7.1921 Obviously: 7.1842 Da: 7.0648 Madonna: 6.9382 Mon: 6.7638 Lé: 6.7331 Michel: 6.6347 Diego: 6.5983 Him: 6.5977 Luci: 6.5903 Prima: 6.5503 Giorg: 6.5424 \... Moreover: 5.0031 Natur: 4.9922 Ric: 4.9754 Pope: 4.9442 Cec: 4.9418 clear: 4.9349 wasn: 4.9321 Newton: 4.9319 Jesus: 4.9271 Lee: 4.9231 Bob: 4.9100 Arist: 4.9000 Renaissance: 4.8975 Bern: 4.8926 Vlad: 4.8796 }                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Output: Suppose it's true that The Mona Lisa was painted by Leonardo da Vinci. Then, who painted the Mona Lisa?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Top tokens: { ,: 8.2570 but: 7.4238 they: 5.5620 /: 5.1770 but: 5.1659 ;: 5.1307 .: 4.9385 unless: 4.8892 indeed: 4.8305 ,(: 4.7388 because: 4.3290 except: 4.2364 and: 4.1802 with: 4.1525 AND: 4.1523 \... Genomsnitt: 2.5206 }                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Output: How can diet sodas have zero calories?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | What is the main reason why diet soda is bad for you?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Do those questions have the same meaning?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | OPTIONS:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | \- no                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | \- yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Top tokens: { whether: 11.8282 conclus: 11.2570 definit: 10.4762 from: 9.0172 unless: 8.9301 without: 8.8401 either: 8.8082 yet: 8.7552 based: 8.5534 .: 8.1669 if: 7.8553 because: 7.6823 anything: 7.4641 weather: 7.3586 given: 7.2563 until: 7.2539 due: 7.2475 ,: 7.2354 with: 7.0059 reli: 6.9824 since: 6.9268 posit: 6.8239 for: 6.7511 decis: 6.5534 accur: 6.5436 sole: 6.5126 definitely: 6.4109 anymore: 6.3978 definite: 6.3382 defin: 6.0519 directly: 5.9700 form: 5.8993 necessarily: 5.8884 right: 5.8829 vis: 5.8768 between: 5.7320 just: 5.7161 bec: 5.6957 yes: 5.6823 prem: 5.6057 using: 5.5305 intuit: 5.5000 merely: 5.4670 certain: 5.4666 depending: 5.4145 exactly: 5.3382 statist: 5.2684 purely: 5.2434 what: 5.2341 correctly: 5.1911 determin: 5.1818 through: 5.1817 one: 5.1599 within: 5.1509 conclusion: 5.1501 nor: 5.1132 une: 5.1099 w: 5.0780 concl: 5.0452 empir: 5.0357 alone: 5.0024 regardless: 4.9944 being: 4.9907 clearly: 4.9603 which: 4.9244 immediately: 4.9147 explicitly: 4.9100 confident: 4.9066 enough: 4.8983 wit: 4.8966 convin: 4.8229 knowing: 4.8048 by: 4.7944 aff: 4.7740 till: 4.7308 outside: 4.7040 bases: 4.6989 at: 4.6928 simply: 4.6816 straight: 4.6590 them: 4.6589 but: 4.6522 precisely: 4.6370 blind: 4.5758 positive: 4.5536 direction: 4.5310 only: 4.5170 easily: 4.5093 via: 4.5076 anyway: 4.4790 /: 4.4679 the: 4.4674 apart: 4.4162 ye: 4.4095 much: 4.4033 absolutely: 4.3913 their: 4.3850 jud: 4.3697 :: 4.3651 fro: 4.3244 } |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Output: Premise: Dancer striking a beautiful pose on a basketball court.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | Hypothesis: The dancer is outside.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | .Given the premise, can we conclude the hypothesis?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | OPTIONS:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | \- yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
|        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|        | \- it is not possible to tell                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
+:=======+:===================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+
:::

# Additional analysis

#### Does our model accurately predict length?

We plot the length of prompts vs their reconstructions by our model across datasets in [5](#fig:performance_by_length){reference-type="ref+Label" reference="fig:performance_by_length"}. Our model fits length of prompts in the training distribution (Instructions-2M) well, but struggles on the out-of-distribution datasets, tending to produce reconstructions with far too many tokens. On the Anthropic HH dataset, our method produces $39.5$ tokens on average, while the true prompts have an average of $17.9$ tokens.

<figure id="fig:performance_by_length" data-latex-placement="t">
<img src="figs/03_performance_by_length.png" style="width:50.0%" />
<figcaption>True and reconstructed (red) input lengths. Our model closely models in-distribution length and tends to overpredict for the other two datasets. </figcaption>
</figure>

# Synonym swap experimental details {#app:synonym_swap}

To perform the experiment illustrated in [\[fig:kl_bits\]](#fig:kl_bits){reference-type="ref+Label" reference="fig:kl_bits"}, we sample 100 paragraphs from Wikipedia obtained via the Wikitext dataset [@merity2016pointer]. We prompt GPT-4 with the first ten words of each paragraph prepended by the text *"Please update the sentence by replacing one word sentence with a close synonym. Respond with only the word to swap in the format word1 -\> word2."*. We then extract the word swap from GPT-4's response and apply it to the input to produce the transformed input $\hat{x}$. The language model used for prompting is the 7-billion parameter version of LLAMA-2 (non-chat version).

To measure the change in language model output between the original sequence (containing $x_s$) and the new sequence (containing $\hat{x_{s}}$), we compute two quantities:

$$\text{KL}(x, \hat{x}; T):= \mathbb{D}_{KL}\left[ p(x_{T+1} \mid x_{1}, ..., x_{s}, ..., x_{T}; \theta) \mid \mid p(x_{T+1} \mid x_{1}, ..., \hat{x}_{s}, ... x_{T}; \theta)\right]$$

that is, the KL divergence between the probability output of $p$ for the original and synonym-swapped sequences, and

$$\begin{align*}
\text{Hamming}(x, \hat{x}; T) := \sum_{i} | &\text{bin}_{16}(p(x_{T+1} \mid x_{1}, ..., x_{s}, ..., x_{T}; \theta))_i \\ -\ 
&\text{bin}_{16}(p(x_{T+1} \mid x_{1}, ..., \hat{x}_{s}, ..., x_{T}; \theta))_i|
\end{align*}$$

# Datasets

[\[tab:app_datasets\]](#tab:app_datasets){reference-type="ref+Label" reference="tab:app_datasets"} displays a breakdown of prompt datasets included in the Instructions-2M dataset. Prompts are the concatenation of the user prompt and an optional system prompt. T0 prompts are the longest, with an average of 32.4 words. Lamini prompts make up the majority of the training data, with a total of 1.8M included.

::: table*
  Dataset                        Num. words     Total
  ---------------------------- ------------ ---------
  alpaca                               13.2     51280
  arxiv_math                            7.1     50488
  dolly                                11.9     10684
  evol                                 23.9     26530
  evol_code                              25     41090
  gpt4_teacher                         15.4     88933
  lamini                               20.7   1826928
  self_instruct                        20.9     77840
  super_natural_instructions           20.9     77840
  t0                                   32.4     80427
:::

# Logit extraction with API access to probabilities {#sec:prob-extraction}

In this section we offer another approach to extracting log probabilities when the API offers access to the probabilities of the top 2 most likely words. At a high level, to find the probability of a word in the original distribution, we first find a logit bias that makes that word most likely. We then use the change in probability of the most likely word to compute the normalizing constant of the original distribution, and use that to find the probability of the word of interest.

Formally, we can extract the log probability of word $\log p(v) = f(v) - \log Z$ as follows: First, find a logit bias $b_v$ that makes word $v$ more probable than highest probability word $v^*$. Use the logit bias $b_v$ and change in probability $\Delta = \log p(v^*) - \log p(v^*; b_v)$ of the highest probability word after adding the logit bias to word $v \ne v^*$ to solve for the normalizing constant: $$\begin{align*}
\Delta &= (\log f(v^*) - \log Z) - (\log f(v^*) - \log (Z + \exp(b_v)))\\
&= \log (Z + \exp(b_v)) - \log Z\\
\exp(\Delta) &= \frac{Z + \exp(b_v)}{Z}\\
&= 1 + \frac{\exp(b_v)}{Z}\\
Z&= \frac{\exp(b_v)}{\exp(\Delta) - 1}\\
\log Z &= b_v - \log(\exp(\Delta)-1)
\end{align*}$$ With this, we can solve for the unnormalized log probability of the word $f(v)$: $$\begin{align*}
\log p(v;b_v) &= f(v) + b_v - \log (Z + \exp(b_v))\\
f(v) &= \log p(v;b_v) + \log (Z + \exp(b_v)) - b_v,
\end{align*}$$ yielding $\log p(v) = f(v) - \log Z$.

This allows us to extract log probabilities for each word with one call to find the probability of the most likely word, and one call for each other word with a large enough logit bias.

# Initial explorations with iterative refinement

A natural extension to this approach could be the iterative refinement approach proposed in vec2text [@morris2023vec2text]. We parameterize an encoder-decoder that takes three inputs:

- the model output probability vector for an unknown prompt ($v$) in [4](#sec:method){reference-type="ref+Label" reference="sec:method"})

- a 'hypothesis' sequence, $\hat{x}_{1}, ..., \hat{x}_{T}$

- the model output probability vector $p(\hat{x}_{1}, ..., \hat{x}_{T})$

and train it via language modeling on the true prompt $x \mid p(x) = v$. For training, we sample outputs from a checkpoint of our conditional LM ([4](#sec:method){reference-type="ref+label" reference="sec:method"}) to use as hypotheses. We train the model on outputs from Llama-2 (7B) for $100$ epochs using the same hyperparameters outlined in [6](#sec:experimental_design){reference-type="ref+Label" reference="sec:experimental_design"}. This model is able to achieve a one-step BLEU score of $58.7$ on Instructions-2M, essentially recovering the original model's BLEU performance of $59.2$. However, we see no increase in BLEU score after applying multiple steps of correction; after 5 steps, our model achieves a BLEU score of $56.43$.

<figure id="fig:app_refinement_bleu" data-latex-placement="t">
<img src="figs/app_02_refinement_bleu.png" style="width:50.0%" />
<figcaption>BLEU scores across the <span class="math inline">100<sub>000</sub></span> training hypotheses for our iterative refinement experiment. Most training examples have a BLEU score below <span class="math inline">20</span>.</figcaption>
</figure>

[6](#fig:app_refinement_bleu){reference-type="ref+Label" reference="fig:app_refinement_bleu"} plots the BLEU scores in the hypotheses used to train the iterative refinement model. We note that these hypotheses do not cover a full spectrum of correctable texts up to a BLEU score of 100; this may make it difficult for the refinement model to learn to correct text at different 'distances' from the ground-truth text. Perhaps that iterative refinement also may be more difficult in the space of language model probability outputs than text embeddings, due to a lack of convexity; it is also plausible that a different architecture or set of hyperparameters may be needed to train a more powerful inverter using iterative refinement.

## Ablations {#sec:ablations}

::: table*
+----------------+-------+----------+-------------------+-------------------+
| Experiment     | LM    | Inverter | BLEU              | Token F1          |
+:===============+:======+:=========+:==================+:==================+
| LM Scale       | 117M  |          | $38.5_{\pm{1.5}}$ | $60.1_{\pm{1.3}}$ |
|                +-------+----------+-------------------+-------------------+
|                | 355M  | 60M      | $38.4_{\pm{1.5}}$ | $59.8_{\pm{1.3}}$ |
|                +-------+          +-------------------+-------------------+
|                | 774M  |          | $39.4_{\pm{1.5}}$ | $60.2_{\pm{1.3}}$ |
|                +-------+----------+-------------------+-------------------+
|                | 1558M |          | $39.2_{\pm{1.5}}$ | $60.0_{\pm{1.3}}$ |
+----------------+-------+----------+-------------------+-------------------+
| Inverter Scale |       | 60M      | $38.5_{\pm{1.5}}$ | $60.1_{\pm{1.3}}$ |
|                +-------+----------+-------------------+-------------------+
|                | 117M  | 220M     | $44.5_{\pm{1.6}}$ | $65.4_{\pm{1.2}}$ |
|                +-------+----------+-------------------+-------------------+
|                |       | 738M     | $47.8_{\pm{1.6}}$ | $67.5_{\pm{1.2}}$ |
+----------------+-------+----------+-------------------+-------------------+
| Baseline       | 117M  | 60M      | $38.5_{\pm{1.5}}$ | $60.1_{\pm{1.3}}$ |
+----------------+       |          +-------------------+-------------------+
| No softmax     |       |          | $29.9_{\pm{1.4}}$ | $51.1_{\pm{1.3}}$ |
+----------------+       |          +-------------------+-------------------+
| Projection     |       |          | $4.1_{\pm{0.2}}$  | $15.5_{\pm{0.5}}$ |
+----------------+       |          +-------------------+-------------------+
| Full precision |       |          | $39.7_{\pm{1.5}}$ | $61.3_{\pm{1.2}}$ |
+----------------+-------+----------+-------------------+-------------------+

  $k$     BLEU                Token F1               
  ------- ------------------- ------------------- -- --
  1       $4.6_{\pm{0.2}}$    $17.3_{\pm{0.5}}$      
  10      $4.6_{\pm{0.2}}$    $17.3_{\pm{0.5}}$      
  100     $8.0_{\pm{0.7}}$    $21.5_{\pm{0.9}}$      
  1000    $21.4_{\pm{1.3}}$   $39.2_{\pm{1.3}}$      
  10000   $30.7_{\pm{1.4}}$   $52.0_{\pm{1.3}}$      
  32000   $38.5_{\pm{1.5}}$   $60.1_{\pm{1.3}}$      

[]{#tab:model_ablations label="tab:model_ablations"}
:::

We perform a variety of ablations of our model-training in a reduced setting: $1M$ training examples from the dataset with a maximum sequence length of $16$, training for $40$ epochs. Ablation results are shown in [\[tab:model_ablations\]](#tab:model_ablations){reference-type="ref+Label" reference="tab:model_ablations"} (Left).

#### Parameterization.

We consider one alternative model architecture, an encoder-decoder with projection as in @morris2023vec2text. This model performs quite poorly, indicating that projecting the probability vector down to a smaller rank discards significant information. We also test an identical parameterization that conditions on the raw outputs of the language model instead of log-normalized probabilities to determine if un-normalized outputs contain more usable information than the probabilities. This removal also makes a difference: without applying the softmax to the inputs, we observe over a $20\%$ drop in BLEU.

Since the main experiments are conducted in 16-bit precision, we test training in full precision (32-bit) to see if the additional bits improve performance. Training on full precision inputs gains about $1$ BLEU point, indicating that we are not discarding significant information by storing probability vectors at half precision.

#### Scaling inverter.

We train inverter models of varying size to see the effect of model scale on inversion performance. We note that the number of parameters in the inverter has a very large impact; with larger inverter models performing significantly better: under ablation settings, with the same number of training steps, the T5-large inverter achieves $24\%$ higher BLEU score than T5-small. This finding indicates that we may more accurately invert language models simply by scaling our system.

#### Reducing input dimensionality.

When stored on disk in 32-bit precision, 10 million probability vectors for a vocabulary of size of $32,000$ take up 1.28 TB. Is it necessary to retain the full dimensionality of these input vectors? Surprisingly, [\[tab:model_ablations\]](#tab:model_ablations){reference-type="ref+Label" reference="tab:model_ablations"} (Right) indicates that the majority of the probability vector is required to achieve good inversion performance. Even though the top 1000 predicted tokens contain $98\%$ of the probability mass on average, training and evaluating with only the top $1000$ tokens reduces performance by $45\%$.

# Personal information recovery experiment

We performed a small experiment to measure our system's performance at recovering entities from prompts. To do this, we created a dataset of prompts that include personal information from Wikibio and Synthbio. We extracted the entities themselves from the tabular portion of the bio datasets and inserted entities into manually-crafted template strings based on Instructions-2M. We release this dataset publicly to aid future research into PII reconstruction.

We consider our model's ability to reconstruct specific entities from prompts that have a high likelihood of containing personal information, such as names, dates, and nationalities. To test this, we generate a synthetic dataset of prompts that contain these attributes. We edit prompts from Instructions-2M with private attributes sourced from Wikibio [@lebret2016wikibio] and Synthbio [@yuan2022synthbio][^11]. We invert these prompts using both our LLAMA 7B and LLAMA-chat 7B models and measure accuracy at reconstructing private entities across categories.

Results are displayed in [\[tab:privacy\]](#tab:privacy){reference-type="ref+Label" reference="tab:privacy"}. Our models are far better at reconstructing some private entities than others: countries and nationalities are particularly successful, while individual dates and years are typically lost during the inversion process. Future work might consider more wide-ranging training data for better performance, since Instructions-2M includes only a narrow distribution of personal information in its prompts.

::: table*
+---------+----------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+
|         |          | Country           | Nationality       | Day               | Month             | Year             | First Name       | Last Name        |
+:========+:=========+==================:+==================:+==================:+==================:+=================:+=================:+=================:+
| 7b      | synthbio | $87.2_{\pm{1.5}}$ | $64.5_{\pm{2.4}}$ | $9.0_{\pm{1.6}}$  | $15.0_{\pm{3.3}}$ | $1.0_{\pm{0.4}}$ | $5.9_{\pm{1.0}}$ | $1.4_{\pm{0.5}}$ |
|         +----------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+
|         | wikibio  | $75.7_{\pm{1.5}}$ | $34.2_{\pm{2.1}}$ | $13.8_{\pm{1.7}}$ | $17.7_{\pm{3.4}}$ | $1.0_{\pm{0.4}}$ | $3.3_{\pm{0.8}}$ | $1.4_{\pm{0.5}}$ |
+---------+----------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+
| 7b-chat | synthbio | $84.2_{\pm{1.6}}$ | $64.8_{\pm{2.4}}$ | $7.4_{\pm{1.5}}$  | $15.8_{\pm{3.3}}$ | $2.0_{\pm{0.5}}$ | $5.6_{\pm{0.8}}$ | $1.8_{\pm{0.5}}$ |
|         +----------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+
|         | wikibio  | $75.7_{\pm{1.6}}$ | $32.2_{\pm{1.7}}$ | $12.5_{\pm{1.7}}$ | $7.7_{\pm{2.3}}$  | $1.4_{\pm{0.4}}$ | $3.6_{\pm{0.7}}$ | $1.2_{\pm{0.4}}$ |
+---------+----------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+

[]{#tab:privacy label="tab:privacy"}
:::

# Private prompts dataset {#app:private-prompt-examples}

::: table*
+---+-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | field       | prompt                                                                                                                     | value          | reconstruction                                                                                               | correct |
+:==+:============+:===========================================================================================================================+:===============+:=============================================================================================================+========:+
|   | country     | State the capital city of Uzbekistan.                                                                                      | Uzbekistan     | State the capital city of Uzbekistan.                                                                        | True    |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | first_name  | Decide if the given name is male or female. output \"male\" or \"female\". Aung                                            | Aung           | Calculate the average hexadecimal value of the given string. Bao                                             | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | full_name   | From the dialogue, can we infer that Andrejs Kisins likes dogs?                                                            | Andrejs Kisins | From the dialogue, can we infer that André likes dogs?                                                       | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | last_name   | If Qahtani needs to buy 3 loaves of bread at the store, and each loaf costs \$2, how much money will Sally spend in total? | Qahtani        | If Sally buys 2 bags of candy and 3 bags of chips, how much money will she spend in total?                   | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | month       | Published November Please remove spaces between words.                                                                     | November       | Displaying 1 to 12 of 12 Please remove spaces between words.                                                 | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | nationality | What challenges did the Qatari independence movement face?                                                                 | Qatari         | What challenges did the Quakerism movement face?                                                             | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | year        | Meet Bessy Boot 1889 What is the correctly punctuated version of this sentence?                                            | 1889           | Meet Betty in the 123 What is the correctly punctuated version of this sentence?                             | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | country     | List the countries that border Iran.                                                                                       | Iran           | List the countries that border Iran.                                                                         | True    |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | day         | Task: Find out what day of the week is it on 01. 01                                                                        | 01             | Convert the following date from mm/dd/yyyy to iso 8601 format. 01/01/2018                                    | True    |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | first_name  | While walking through the park, raoul noticed something unusual. What did they notice?                                     | raoul          | As they walked through the park, Ray spotted something unusual. What was Ray looking for?                    | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | full_name   | Given that jack bruton failed his driving test twice. Does it follow that they are a bad driver? Yes, no, or maybe?        | jack bruton    | Given that Jack failed his driving test. Does it follow that Jack is not good at driving. Yes, no, or maybe? | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | last_name   | Decide if the given name is male or female. output \"male\" or \"female\". frederiksen                                     | frederiksen    | Detect the gender of the person based on his/her name. output \"male\" or \"female\". christian doe          | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | month       | Registration feb 21:15 Make this lower case                                                                                | feb            | Registration 28 February 2011 20:39 Make this lower case                                                     | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | nationality | Can you name a famous egyptian musician who blends traditional egyptian music with other genres?                           | egyptian       | Can you name a famous Egyptian musician who specializes in traditional music from different genres?          | False   |
|   +-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
|   | year        | Registration 1918 21:15 Make this lower case                                                                               | 1918           | Registration 2 August 2005 18:13 Make this lower case                                                        | False   |
+---+-------------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------------------------------------------------------------------------------------------------------------+---------+
:::

[^1]: Code for reproducing all experiments is available at [github.com/jxmorris12/vec2text](https://github.com/jxmorris12/vec2text). Our dataset of prompts will be provided upon paper publication.

[^2]: We perform synonym swaps using GPT-4. More information on this experiment is given in [15](#app:synonym_swap){reference-type="ref+Label" reference="app:synonym_swap"}

[^3]: https://huggingface.co/datasets/databricks/databricks-dolly-15k

[^4]: https://huggingface.co/datasets/anon8231489123/ShareGPTVicunaunfiltered

[^5]: https://huggingface.co/datasets/lmsys/chatbotarenaconversations

[^6]: https://huggingface.co/datasets/MadVoyager/stablediffusioninstructionaldataset

[^7]: https://github.com/teknium1/GPTeacher

[^8]: We explore variants of this projection through ablation experiments in [18.1](#sec:ablations){reference-type="ref+Label" reference="sec:ablations"}.

[^9]: We also provide an algorithm for logit extraction with an API that returns the top 2 log probabilities in Appendix [17](#sec:prob-extraction){reference-type="ref" reference="sec:prob-extraction"}.

[^10]: Of course, T5 knows Wikipedia well, and correctly states the year the incorrectly predicted book was published.

[^11]: More details along with sample prompts are available in [20](#app:private-prompt-examples){reference-type="ref+Label" reference="app:private-prompt-examples"}.
